@Chapter{Introduction}This chapter is intended to clarify why Word Manager has beendeveloped and what some of its more striking properties are. It doesso by presenting the problem Word Manager was designed to solve,and showing how other existing systems fall short in solving it.Section 1 introduces the task Word Manager was devised for, andproperties required to fulfil it properly. Section 2 presents arepresentative selection of existing systems that might be used forthis task. Section 3 evaluates the strong and weak points of eachsystem, thus paving the way for the exposition of Word Manager inthe next chapters. @Section{Lexical and Morphological Knowledge in NLP} In this section, we first outline the problem of linking wordforms toinformation required by NLP-systems (section 1.1). Then we specifywhich terms we will use for various phenomena in this book, and howthey are related (section 1.2). Finally, we present the criteria bywhich a system managing lexical and morphological knowledge shouldin our view be evaluated (section 1.3).@SubSection{The Problem} There is a large variety of @Index{Natural Language Processing (NLP)systems}Natural Language Processing (NLP) systems, ranging incomplexity from spelling checkers and hyphenation programs vianatural language interfaces and text classification programs totext-to-speech and machine translation systems. Most of them have awritten text as their input from which a certain type of informationis to be extracted. Others involve text generation, where the writtentext is the output. In all these cases, graphic words have to be linkedto the information they incorporate. The information associated witha word depends on the type of NLP-system, ranging from(idiosyncratic) hyphenation positions, via subject fieldspecifications, to translation. According to the needs of individualsystems, this information is encoded in different formats. The maindepository of this information is the dictionary. A first observation to be made concerning the dictionaries of allthese systems, is that describing every graphic word separately(full-form dictionary) leads to a vast amount of redundancy. If horseand horses are described independently, in the best of possibleworlds their description will be identical, except for the informationon number. However, we are not always in the best of possibleworlds, but in one where people make mistakes, so that not only theeffort, but also the likelihood of errors is doubled. The samesituation occurs when the information has to be updated.Furthermore, the information is incomplete since the fact that thetwo belong together is omitted. This deficiency is aggravated by thefact that the relation is common to almost all English nouns. Similarexamples could of course be given for verbs or other word classes. The solution to this abuse is obvious: horse is described once in thedictionary, without number specification, and a rule relates it to thesingular and plural forms. The task of linking a text word to theinformation associated with it is divided into two parts: one part iscovered by a morphological rule component that links the text wordto a @Index{lexeme}lexeme. The other part is covered by thedictionary proper, where further information is given for the lexeme.A similar situation arises for words like horselike. On the one hand,the description of horselike will contain quite a lot of informationthat is the same as for horse, in fact its description is incompletewithout a reference to horse. On the other hand, it is questionablewhether we want to have horselike in the dictionary in the firstplace, since its information is predictable from the description ofhorse and the process that produces adjectives from nouns by adding-like. Again, the solution is straightforward. Processes ofwordformation are encoded in rules, thus enabling the system tocover newly coined words and to link words to their origin andoff-spring.Having distributed the task of linking graphic words to theirdescriptions over a morphological rule system and a dictionary, werecognize another level of redundancy. All NLP-systems need adictionary and a morphological rule system, and their developmentand maintenance is notoriously expensive. Furthermore, they areusually not considered to be the central component of the system, sothat the zest for work on their development is often lacking. Althoughpart of the information in the dictionary is application-specific, theinformation linking the entries via morphological rules to graphicwords is common to all systems, and in this area, annoyinginconsistencies between the corresponding parts of dictionaries ofdifferent applications are most bothersome. Again, there is anobvious way to counteract redundancy here: having a single systemthat provides all knowledge needed to link graphic words to theirdescription, managed centrally, and available to the various@Index{client application} application systems.We are by no means the first to acknowledge the need to avoid thetwo levels of redundancy described above. In fact, @Index{reusabilityof lexical resources}reusability of lexical resources has been one ofthe main concerns of the computational linguistic community sincethe mid-1980’s. There are two different angles to approach theproblem, and they have led to completely different types of systems.One approach starts from the dictionary, leading to the developmentof a @Index{LDB (Lexical Database)}Lexical Database (LDB). The otherconcentrates on the morphological rules, resulting in a@Index{FMP (Formalism for Morphological Processing)}Formalism forMorphological Processing (FMP). Examples ofboth types of systems will be discussed in section 21.@SubSection{Terminological Issues}This section is meant to give an overview of the linguistic termsrelated to morphology and the dictionary we will use in this book.Rather than providing definitions for them, we will relate them toeach other and describe them informally. Our use of terms is fairlyclose to the tradition, as formulated in e.g. Matthews (1974).A @Index{wordform}wordform2 is a word as it appears in a text, e.g.horse, horses, horselike. A wordform is divided in@Index{formative}formatives, distributional segments, independentof their meaning. In principle, it would be possible to divide horses inthe formatives ho and rses (cf. hobby, nurses), but a division in horseand s makes more sense. The singular horse can be divided in horseand an empty formative. It is a theoretical issue, outside thecomputer system itself, how to properly divide a wordform informatives.An @Index{inflectional paradigm}inflectional paradigm is a sequenceof wordforms, having an element in common, and one or moreelements that are different, associated with grammatical roles. Thecommon element has a more or less invariable meaning, and usually amore or less constant form (suppletion as in the opposition go vs.went is an exception). The elements that are different adapt it to thevarious grammatical roles it can assume. Thus, [horse (singular),horses (plural)] is an inflectional paradigm.Lexical space can be divided in various ways. The division in@Index{lexeme}lexemes employs the principle that no two lexemesshare an inflectional paradigm, and no two inflectional paradigms areassociated with a single lexeme. Thus, match as ‘sports contest’ andas ‘once-only cigarette lighter’ belong to the same lexeme, but theverb match belongs to a different one. It is important to distinguishlexeme and inflectional paradigm: A lexeme is a quantity of lexicalknowledge, whereas an inflectional paradigm is a sequence ofwordforms with their grammatical roles.It is a theoretical issue, outside the scope of the system proper, todetermine the exact boundaries between lexemes. The verbs kneel andring both have two past tenses, but whereas kneeled and knelt areprobably best treated as equivalent alternatives, rang and ringedshould rather belong to different lexemes. The impact of the theoryand the responsibility of the linguist applying it is particularlyevident in the distinction between inflection and wordformation. Forthe comparative and for -ly-adverbs, both an inflectional analysisand an account of wordformation can and have been defended (cf.Matthews (1974)), with accompanying consequences for inflectionalparadigms and lexemes. A morphology system should allow bothanalyses in borderline cases, leaving the choice to the linguist. @SubSection{Criteria for Evaluation}In the evaluation of systems for the management of morphologicalknowledge, the most important criteria derive from the system’sfunctionality, as seen from a computational linguistic point of viewand from the point of view of database theory. Althoughimplementation-based criteria cannot be neglected, they depend to alarge degree on the functionality-based criteria given below, that inprinciple could be converted into software specification and designcriteria rather straightforwardly.A first set of criteria can be derived from considering the system asan @Index{FMP (Formalism for Morphological Processing)}FMP, i.e. as aformalism for (partial) linguistic analysis. They are based on Shieber(1985).@Item @Index{expressiveness}Expressiveness. If a linguist canencode all knowledge he wants to express in terms of the formalism,it is sufficiently expressive. To the extent that when this is not thecase, the expressiveness of the system is too low. @End-Item @Item @Index{linguistic felicity}Linguistic felicity. If the formalismallows the linguist to express knowledge in a natural way, i.e. in away close to how current linguistic theories would express it, thelinguistic felicity of the system is high. @End-Item @Item @Index{computational effectiveness}Computationaleffectiveness. If a computer can interpret the knowledge expressed inthe formalism in such a way that it can be represented economicallyand, above all, used efficiently, the computational effectiveness of asystem is high.@End-Item A second set of criteria emerges as a consequence oflooking at the system as an @Index{LDB Lexical Database}LDB, i.e. as adatabase system. They have been adapted from what Zehnder (1985)calls “characteristic properties” of database systems. @Item @Index{intelligibility of the data structuring}Intelligibility ofthe data structuring. If the structure of the data in the database issuch that the user can easily understand the entities he has to workwith, the intelligibility of the data structuring is high. For a databaseof morphological knowledge, three different kinds of user have to betaken into account: the linguist, who will formulate morphologicalrules and list exceptional cases; the@Index{lexicographer}lexicographer, who will describe lexemes onthe basis of the morphological rules provided by the@Index{linguist}linguist; and the @Index{client applicationprogrammer}programmer implementing a client application, i.e. anNLP-system using the knowledge in the database.@End-Item @Item @Index{redundancy control}Redundancy control. If the systemprohibits many types of redundant specifications by the user, andprovides support in detecting probable redundant specifications,redundancy control is high. There are different types of redundancy.An easy case to detect is accidental multiple specification of aformative or a lexeme. A more complicated case arises if a lexeme isrepresented twice as a result of different rule applications, e.g. ifhorselike is entered directly as well as being the result of applying aderivational rule adding -like to horse.@End-Item @Item @Index{consistency control}Consistency control. Whereasredundancy control deals with the prevention and detection ofredundant specification, consistency control does the same forcontradictory specifications. If contradictory specifications areexcluded a priori, and probable ones detected and presented to thedatabase manager, consistency control is high. As an example,consider the system’s behaviour when a formative that has been usedin wordformation is modified: if horselike has been formed by aderivational rule adding -like to horse, and the description of -like ischanged, at least the user’s attention must be drawn to the fact thatthe derivation of horselike might have to be adapted. Ideally, thesystem provides means for the @Index{propagation}propagation ofchanges.@End-Item @Item @Index{data independence}Data independence. If the knowledgestored in the database can be restructured without requiring manymodifications in the client applications using the knowledge, dataindependence is high.@End-Item @Item @Index{flexibility}Flexibility. If the knowledge stored in thedatabase can be adapted, with only minor modifications, for use insituations the database was not specifically designed for, thesystem’s flexibility is high. The flexibility of a system is closelylinked to its data independence. @End-Item @Item @Index{feasibility of different views}Feasibility of differentviews. If different @Index{interface}interfaces to the database can beimplemented so that each provides a different perspective on theknowledge represented in the database, feasibility of different viewsis high. The differences between the interfaces typically reflect theuse of different subsets of the knowledge.@End-Item @Item @Index{life expectancy of the data}Life expectancy of thedata. If the data in the database are likely to survive the hardwareand software used in its original implementation, life expectancy ofthe data is high. There are two aspects to this survival,@Index{portability}portability of the database system, and transferof the knowledge contained in the database. The former considers thesurvival of the entire system and the possibilities of implementing iton a new type of computer. The latter considers the survival of theknowledge alone and the possibilities of reusability in anothersystem.@End-Item @Section{Existing Approaches}As mentioned above, approaches to the problem of linking text wordsto dictionary information can be divided into @Index{LDB (LexicalDatabase) }Lexical Databases (LDB's) and @Index{FMP (Formalismsfor Morphological Processing)}Formalisms for MorphologicalProcessing (FPM's), according to their starting point. LDB’s start fromthe dictionary, whereas FMP’s start from the morphological rulesystem. The basic entity of an LDB is a lexeme, whilst FMP databasesare based on formatives. In principle, non-morphological knowledge inFMP’s can be associated with either lexemes or formatives, but thelatter type only occurs in experimental FMP’s, mainly for researchpurposes, because it is hard to realize.Most of the research on LDB’s is rather source-oriented thanproblem-oriented, in the sense that a machine-readable version of adictionary published for human use is taken as a basis and theresearch focusses on how much of the information contained in it canbe recoded automatically for use in an NLP-system. A typical exampleis the work on the grammar codes of @Index{LDOCE}LDOCE, reportedon by Boguraev & Briscoe (1989), among others. We think, however,that this interpretation of @Index{reusability of lexicalresources}reusability is not the most practical one. Reusability isbetter served by starting from the demand and trying to achieve it bymaking a good dictionary, than by starting from the data supplied andtrying to find a way to apply them at all costs. Thus, much effort hasbeen spent extracting information on semantic and syntactic classmembership from the definition of an item. Sometimes this has led toexcesses, where paging through the dictionary and manually codingthe information would have been more efficient than the methodsused to find a few further examples of a specific class. As anexample of a big LDB we will discuss the databases provided by Celexthat provide a reasonable compromise between reuse of existingsources and manual editing.As examples of FMP’s we will discuss two-level morphology andDATR. They are the formalisms most generally used as FMP’s at themoment, although DATR is strictly speaking not an FMP but aformalism for the specification of dictionaries to be used inunification-based systems. @SubSection{The Celex Lexical Databases}The Nijmegen-based Centre for Lexical Information(@Index{Celex}Celex) is a joint initiative of several researchinstitutes in the Netherlands, funded in part by the Dutch government.The description here is based on issues 1 to 5 of the Celex News thatappeared between December 1986 and August 1990.Celex offers LDB’s of Dutch, English, and German, accessible viacomputer networks. Fig. 1.1 represents the setup of the databases andlexicons.@Figure{ " Celex databases and lexicons." | "128" | 366 | 104 }The basic database is a database containing all available informationin a format optimized for the reduction of redundancy and designedfor internal update activities. It is expanded to the derived databasethat can be consulted by client applications. By means of a speciallydesigned user interface, Flex, users can define a particular subset ofthe database as their lexicon. This lexicon is a virtual lexiconbecause it only consists of a set of restrictions on the informationcontained in the master database. It can be downloaded as a physicallexicon. The division into virtual and physical lexicon allows the userto choose between fast creation and fast access. At the point wherethe users are tailoring the dictionary to their own specific needs, theusers may try various virtual lexicons, the best of which can bedownloaded and used in their own systems. Flex supports the creationof virtual lexicons by a series of menus. The menu choices aretranslated into SQL automatically so that the user need not know thestructure of the database, nor the syntax and semantics of SQL. Themaster database is implemented with the relational DBMS Oracle.The information associated with a lexeme in the database is quitediverse. It includes orthographic, phonological, morphological,syntactic, and frequency information. Morphological information is atree, hierarchically breaking down the lexeme’s citation form intofree and bound morphemes and a feature code for the inflectionalparadigm. An affix inventory is also provided.The format of the information is features, i.e. attribute-value pairs.A lexicon is a table where columns represent attributes, e.g.syntactic category, the rows represent the lexemes, e.g. boat, and thevalues are inserted at the intersections, e.g. ‘noun’ at theintersection of boat and ‘syntactic category’. Inflectional paradigmsare represented by a feature linking every wordform unambiguouslyto a lexeme. Special care has been taken to ensure that information isrepresented in a way that guarantees multifunctionality andpolytheoretic usability.The information in the database is taken from variousmachine-readable dictionaries and large corpora. Of themorphological information, a draft version was obtained by using amorphological parser. The results were corrected manually.@SubSection{Two-Level Morphology}@Index{Two-Level Morphology}The two-level model is a formalism for morphological processing,described originally by Koskenniemi (1983). Its development was inpart inspired by Martin Kay and Ronald Kaplan. Koskenniemi applied itto Finnish, a morphologically rich language where a single lexememay encompass thousands of distinct wordforms. By showing that hissystem can handle such a complex morphological system, hedemonstrated its expressive power. A description of the encoding offragments of several other languages can be found in Karttunen(1983). Since 1983, many people have worked with the system,encoding fragments of morphology, reimplementing the formalism,and proposing various modifications. An overview of thesedevelopments, with numerous references, is given by Domenig (1989).Here, we will restrict ourselves to a brief outline of the originalsystem.@Figure{"Two-level Morphology. " | "129" |  415 | 32 } The basic structure of the system can be represented schematicallyas in Fig. 1.2 (after Kataja & Koskenniemi (1988)). @Index{two-levelrules}Two level rules, implemented as finite-state transducers,connect the surface form (text word) with the corresponding lexicalform. The lexical form of a wordform is a concatenation offormatives built up according to the specifications of the lexiconsystem.The lexicon system can be considered as a mapping from formativesto lexical forms of full-fledged wordforms. It should be kept in mind,however, that formatives are specified within the lexicon systemitself and do not exist ‘before’ in any sense, as suggested by Fig. 1.2.The specification of a formative consists of three parts: the stringthat enters the lexical form; the continuation class code; and anarbitrary set of features associated with the formative. Thecontinuation class code indicates which formatives may follow theone being specified. It refers to a continuation class, groupingtogether one or more sublexicons, as specified in the continuationssection of the dictionary. Each formative belongs to a singlesublexicon. Formatives in the same sublexicon have exactly the samemorphological distribution to their left. Formatives with the samecontinuation class have exactly the same morphological distributionto their right. An example for a small fragment of Englishmorphology, from Karttunen & Wittenburg (1983), is given below.3@Verbatim Continuations		( /N = N )		( /V = P3 PS PP PR I AG AB )		( C1 = C1 )		( C2 = C2 )		( P3 = P3 )		( PS = PS )		( PP = PP )		( PR = PR )		( I = I )		( AG = AG )		( AB = AB )		( Root = Root )		( # = )	END	LEXICON Root		believe		/V	"";		die		/V	"";		church		/N	"";		kiss		/V	""	LEXICON N		0		C1	"N SG";		+s		C2	"N PL"	LEXICON C1		0		#	"";		's		#	" GEN"	LEXICON C2		0		#	"";		'		#	" GEN"	LEXICON P3		+s		#	"V PRES SG 3RD"	LEXICON PS		+ed		#	"V PAST"	LEXICON PP		+ed		#	"V PAST PRT"	LEXICON PR		+ing		#	"V PROG"	LEXICON I		0		#	"V"	LEXICON AG		+er		/N	"AG "	LEXICON AB		+able		#	"VERB ABL"@End-Verbatim Stems do not have a special status different from affixes. Addingprefixes requires a division of the roots into appropriate sublexiconsto formulate continuation classes for them. There is no differencebetween the inflectional paradigm and derivations distinguishing thetypes of relation believed and believer have to believe. Because of theequal status of all formatives, even the set of wordforms containingbelieve is not distinguished as a class from the set of wordformscontaining +s from lexicon N, or the set of wordforms containing +erfrom lexicon AG.The differences between the lexical form and the surface form of awordform allow certain generalizations of the procedures in thelexicon system to be made. In the trivial case, lexical form andsurface form are equal. @Index{two-level rules}Two level rules canspecify a context where the mapping involves a change. Eachtwo-level rule can be represented as a finite-state transducer. Allthese FST’s run through the lexical string and the surface string inparallel. In principle, it does not make any difference whether themapping is from lexical string to surface string or in the reversedirection. Schematically, this can be represented as in Fig. 1.3:@Figure{ "Mapping between lexical level and surface level." | "130" | 141 | 92 } The generalizations to be expressed are of two types.@Index{morphophonological generalizations}Morphonological changesare changes determined by phonology that can be derived from theorthographic string, supplemented only by information on thepronunciation that is not written otherwise. An example in English isepenthesis, the insertion of an e between certain stems and theending -s, e.g. the plural noun buses, and the third person singularverb pushes. Karttunen & Wittenburg (1983) write the following ruleto cover epenthesis:	+/e ´ { { c | s (h) } | S | y/i } _ sThey use the special symbol + to indicate a morpheme boundary. Srefers to the set {s, z, x}. The sequence y/i refers to y’s at lexicallevel that, by the application of another two-level rule, correspond toi at surface level, e.g. in happily, spies. The rule can be read as ‘a + atlexical level corresponds to an e at surface level, if and only if it ispreceded by one of ch, sh, s, z, x, or a y at lexical level correspondingto an i at surface level, and it is followed by an s’. By a defaultassumption, any special character at lexical level corresponds to 0(‘nothing’) at surface level, unless specified otherwise. Thus bus+sand cat+s at lexical level correspond to buses and cats at surfacelevel. In a way similar to morpheme boundaries, stress must bemarked in order to formulate a rule for consonant doubling relatingrefer+ing and travel+ing to referring and traveling, respectively.These two-level rules allow the generalization over -s and -es, andover -ring and -ing, that otherwise would have to be separateendings, with stems divided according to which form they take bydifferent continuation class codes.@Index{morphological changes}Morphological changes are differentfrom morphophonological ones in that they are idiosyncraticallyrestricted to specific lexemes and cannot be deduced otherwise thanby listing them. A typical example of a morphological change is@Index{ablaut}ablaut. In a rudimentary form, it occurs in Englishirregular verbs (e.g. sing - sang - sung). In German, it is a much morepervasive phenomenon and is graphically expressed by the@Index{umlaut}umlaut, as in a vs. ä. The non-predictability of umlautis illustrated by the nouns in the following table.@Verbatim Singular	PluralSchlag	Schläge	(‘blow’)Tag	Tage	(‘day’)Acker	Äcker	(‘field’)Anker	Anker	(‘anchor’)@End-Verbatim In order to trigger umlaut only in the correct places, making sure thatonly the a’s such as the one in Schlag become umlauted, and only inthe plural, not in the singular, both the umlautable vowel and theumlaut-creating suffix have to be marked. Emele (1988) does this bya capital A and the @Index{special character}special character %,respectively. Thus, lexical forms correspond to the surface forms ofthe nouns above as in the following table:4@Verbatim Lexical Form	Surface Form	Lexical Form	Surface FormschlAg+	schlag	schlAg+%e	schlägetag+	tag	tag+%e	tageAcker+	acker	Acker+%	äckeranker+	anker	anker+%	anker@End-Verbatim The two-level rule bringing about the mapping according to this table can then be written as:	@Verbatim A/ä ´ _.* +/0 %/0@End-Verbatim An A corresponds to ä if and only if it is followed by a morpheme boundary + and the special character %, both corresponding to zero at surface level, with any sequence of characters between A and +. Otherwise, a default rule takes care of the correspondence between A and a. The treatment of umlaut in this way saves the generalization over umlauted stem and non-umlauted stem that would be represented as totally unrelated formatives otherwise.Morphological abstractions are by no means rare and each one induces one or more special characters to be used as triggers for a two-level rule. Whereas special characters such as morpheme boundary and stress markers correspond more or less to common linguistic practice, triggers for processes like ablaut are not usually represented in the string but rather by features associated with the formatives. The effect of implementing a number of morphological processes in this way, is that the formative representation is cluttered with special characters, making it hard to read, as illustrated by the following fragment of the Finnish system from Koskenniemi (1983).5	@Verbatim LEXICON S0		0		K	"NOM SG";		§		R	"NOM SG"	LEXICON S1		$+n		K	"GEN SG";		$+n§		R	"GEN SG";		+n		P1	"NOM SG/PL / GEN SG";		+nA		P	"ESS SG";		!+A		P	"PTV SG";		$+ksi		K	"TRA SG";		$+kse		P1	"TRA SG";		$+ssA		P	"INE SG";		$+stA		P	"ELA SG";		3+:n		P	"ILL SG";		4+h:n		P	"ILL SG";		5+seen		P	"ILL SG";		$+llA		P	"ADE SG";		$+ltA		P	"ABL SG";		$+lle		P	"ALL SG";		$+ttA		P	" ABE SG";		$+t		K	"NOM PL";		%+en		P	"GEN PL"@End-Verbatim @SubSection{DATR}@Index{DATR}DATR is a formal language intended to facilitate the representationof lexical information. As opposed to two-level morphology, it is notspecifically geared towards morphological processing. As describedin Evans & Gazdar (1990), it has been applied to various naturallanguages, as well as to propositional logic and other formallanguages.The basic structure of DATR is a network. Lexemes and rules arerepresented as nodes without a principled difference between thetwo. Each node is a feature bundle, a set of attribute value pairs. Theattributes are structured hierarchically. The highest level may beattributes like morphology or semantics. The node for jump mighthave a feature to indicate the value of <morph <present <tense<singular <third>>>>>. By a notational convention, the internalstructure of the attribute is not expressed. The value of a featuremay be either a constant or a reference to another place where thevalue can be found.The network comes into existence through the references fromlexemes to rules and from more specific rules to more general rules.In a network with only morphological information, the entries (nodes)for cat and jump may be:@Verbatim Cat:	<> == Noun	<root> == cat.Jump:	<> == Verb	<root> == jump.@End-Verbatim Strings starting with a capital are node names. The entry for cat canbe read as ‘All properties of Cat are derived from the node Noun,except for its root which is cat’. The node for noun will then specifythe following: @Verbatim Noun:	<sing> == "<root>"	<plur> == ("<root>" s).@End-Verbatim This means that the singular of a noun is the root specified in thenode from which the reference to Noun started, and the plural is theconcatenation of this root and s. The node for Verb is slightly morecomplex:@Verbatim Verb:	<present tense> == "root"	<present tense sing third> == ("<root>" s)	<present participle> == ("<root>" ing)	<past> == ("<root>" ed).@End-Verbatim At first sight, this node seems to allow both jump and jumps as thirdperson singular present of jump. However, it has been predefined inthe system that the longest, i.e. most specific, path always haspriority over less specific ones. Therefore, the first featurestatement above should actually be read as ‘The present tense of averb is the root of that verb, unless specified more specificallyelsewhere’, and similarly for all other features. This is one aspect ofthe @Index{default}default mechanism of DATR.Another aspect of the default mechanism comes into play when weenter an irregular verb like fall. Although it is irregular in the past,fall is regular otherwise and this can be expressed in the entry asfollows:@Verbatim Fall:	<> == Verb	<root> == fall	<past tense> == fell	<past participle> == fallen.@End-Verbatim Again, the most specific path has priority, which in this case meansthat *falled is never arrived at because Fall contains more specificvalues. Since quite a few verbs in English have past participles in-en, we could generalize, expressing this so-called ‘sub-regularity’with a node of its own:@Verbatim EN_vb:	<> == Verb	<past participle> == ("<root>" en).@End-Verbatim According to this node, EN_verbs are normal verbs, except for theirpast participle. Thus, by making fall an EN_verb, its past participlewill be fallen and everything else is inherited from Verb:@Verbatim Fall:	<> == EN_vb	<root> == fall	<past tense> == fell.@End-Verbatim An important difference to the two-level model is that affixes arenot represented as formatives but introduced as values of features.Whereas two-level morphology groups together stems and affixes asformatives, DATR groups together lexemes and rules as nodes. Anexample of the lexeme node itself having the function of ageneralizing rule can be observed in the case of alternation in theinflectional paradigm. The verb kneel has as its past either knelt orkneeled. This can be expressed as follows:@Verbatim Kneel:	<> == Verb	<root> == kneel.Kneel1:	<> == Kneel	<past> == knelt.Kneel2:	<> == Kneel	<past> == kneeled.@End-Verbatim Note that without Kneel2, kneeled will not be generated because theregular form is overridden in Kneel1. In this configuration, syntacticand semantic information can be included in the more general nodeKneel, avoiding repetition.The default mechanism permits DATR to express statements of thekind e.g., ‘the present tense in English verbs is the root except for thethird person singular’ more elegantly than two-level morphology.Another consequence of the default mechanism is that in DATR thestring has to be encoded in features, whereas in two-levelmorphology, features required to trigger rules must be encoded in thestring. Problems for DATR are thus to be expected where two-levelmorphology uses the string as a basis for generalizations intwo-level rules. The problem is most prominent in what we called@Index{morphophonological generalizations}morphonologicalgeneralizations, such as epenthesis.Suppose we want to add the noun bus and the verb push to thedatabase. The most natural way to express in DATR that they have-es instead of -s is to make this a subregularity, in the same way asfor the past participle of fall:@Verbatim Bus:	<> == ES_nn	<root> == bus.Push:	<> == ES_vb	<root> == push.ES_nn:	<> == Noun	<plur> == ("<root>" es).ES_vb:	<> == Verb	<present tense sing third> == ("<root>" es).@End-Verbatim There are at least three objections to be raised against this way ofdescribing the data. First, -es is treated here as a new ending, givingrise to new conjugation and declension classes although it is moreaccurately described as a variant of -s. Secondly, the dependence ofthe -s/-es alternation on the string to which it is attached isobscured. In a special feature, referring to a new node, information isrepeated that can be derived straightforwardly from the string.Finally, the alternation’s independence from the syntactic category isnot expressed, giving rise to an additional type of redundancy, usingES_noun and ES_verb for a single piece of information. Instead ofsaying that the plural of ES_nouns and the third person singular ofthe present of ES_verbs are -es, we would like to say that any ending-s is changed to -es for these classes of verbs and nouns.For the treatment of umlaut, a morphologically determinedalternation in the classification which we introduced in section 2.2,Reinhard & Gibbon (1991) adopt a strategy where the string is splitup into various parts. Thus, an item like Schlag (‘blow’), mentionedabove, would be divided into Schl+a+g. Probably, it would be possibleto treat epenthesis in a similar way, dividing bus into bu+s, and pushinto pu+sh. It is hard to assess, however, to what extent thisapproach would counter the objections raised above because of thecomplexity of the network it involves.@Section{Evaluation}In this section, the three systems described in section 2 will besubjected to the evaluation criteria presented in section 1.3. Thesection will be structured on the basis of criteria, rather than on thebasis of systems, to facilitate immediate comparison. In order toavoid excessive repetition, some criteria that appeal to very similarproperties of systems have been grouped together without changingthe order in which the criteria were first presented.@SubSection{Expressiveness and Linguistic Felicity}The criteria @Index{expressiveness}expressiveness and@Index{linguistic felicity }linguistic felicity have been groupedtogether because they represent two ways of looking at the samerange of phenomena. The former addresses whether something can beexpressed at all in a system, the latter whether it can be expressedin a way fairly close to common linguistic practice. The nature ofCelex LDBsystem presumes that data have been implemented already.Therefore,there remains nothing to be expressed in a linguisticallyfelicitous way. The points that will be considered here are theapplicability of the system to different languages (section 3.1.1), thedistinction between dictionary entry knowledge and grammarknowledge(section 3.1.2), the representation of inflection andwordformation (section 3.1.3), and the expression of generalizations(section 3.1.4).@SubSubSection{Applicability to Different Languages}For Celex, whether any language can be covered in a database isdetermined exclusively by the availability of computerized(machine-readable dictionaries, corpus) and human (encoders)resources, and independent of inherent properties of the languagebecause the rules interpreting the codes made available in thedatabase are included in the client application.Both two-level morphology and DATR have been applied to a largerange of languages. Koskenniemi (1983) presents an implementationof Finnish in two-level morphology, a language where the number offorms in an inflectional paradigm is too big to be listed for everylexeme. Although we do not know of any implementation of Finnish inDATR, there is no reason to assume that it will involve seriousdifficulties because, as in two-level morphology, every lexeme isaccompanied by a code rather than by its full paradigm.Non-concatenative morphology constitutes a special challenge toFMP’s. A well-known example is the binyan system of semiticlanguages. Kataja & Koskenniemi (1988) propose a two-levelimplementation of the binyan system of Ancient Akkadian and Cahill(1989) ventures a DATR implementation of Arabic verbal inflection.Although by no means complete in the coverage of the respectivelanguages, these implementations show that in principle it ispossible to cover non-concatenative phenomena in both systems.@SubSubSection{Dictionary Entry Knowledge and Grammar Knowledge}Among linguists and lexicologists, there is much debate on the exactdistribution of tasks between the dictionary and the grammar. Oncloser inspection, however, most of the discussion centres around thequestion of what the place of morphological rules should be inrelation to the syntactic component of a system and its lexicon. Forus, the question of distinguishing rule knowledge from entryknowledge is more important.In Celex, the distinction is very clear-cut. Dictionary entryknowledge is represented in the database and rules should be made byclient applications. A disadvantage of this approach that should notbe underestimated is that each client application will have to coverthe full rule component itself. This means that Celex only provides apartial solution to the problem described in section 1.1.In two-level morphology, there is a distinction between informationencoded in the lexicon system, and information covered by two-levelrules. However, this distinction does not coincide with thedistinction between entry knowledge and rule knowledge since bothcomponents contain rule knowledge. The lexicon system containsformatives and rules to concatenate them. The two-level rules areadjustment rules applying to the output of the lexicon system. Thus,although the distinction made by two-level morphology correspondsto a distinction often made in linguistics, the main linguisticdistinction is not represented at all.In DATR, there is no distinction of any kind imposed by the systembecause all information is represented in nodes and links betweenthem. It is left to the user’s discretion to keep nodes in the networkrepresenting entry knowledge separate from those representing ruleknowledge. That this task is non-trivial is illustrated by the use ofdifferent nodes for a single lexeme in the case of alternation in theinflectional paradigm.@SubSubSection{The Representation of Inflection and Wordformation}In linguistics, the question whether inflection and wordformation areany different is open to discussion. An overview of argumentspertaining to this question is given by Scalise (1984). Nevertheless,even among those who reject the theoretical difference, it is quitecommon to use the distinction informally. One of the maindifferences that is usually assumed, even in articles like Williams(1981) that reject the theoretical foundation of the distinction, isthat inflection is paradigmatic and wordformation is not.For the purpose of solving the problem presented in section 1.1,distinguishing inflection from wordformation and representing itsparadigmatic nature, besides being supported by a substantial part oflinguistic literature, is well-motivated on practical grounds. In therepresentation of wordformation, the structure of a word and itsrelation to other words should be encoded, as well as the rulesinvolved. By including wordformation rules, the system is notimmediately impaired by the first newly coined word it comesacross.In Celex dictionaries, the @Index{inflectional paradigm}inflectionalparadigm is encoded as a feature on individual wordforms pointing tothe lexeme. The interpretation of the feature is left to the clientapplications. The internal structure of a lexeme resulting from@Index{wordformation}wordformation rules is indicated by adestructuring tree. The dependencies linking such a lexeme to otherlexemes and formatives in the database are implicit only. Althoughrules have been used to achieve the destructuring, they are notavailable to client applications, so that each client requires its ownrule component to be written. Furthermore, the set of rules has beenconceived as a tool to facilitate manual hard-coding of the structureof existing words, rather than as a body of wordformation rulescovering new coinages as well as existing words.In two-level morphology, inflection and wordformation are notdistinguished. Bypassing the lexeme, the system builds wordformsout of formatives by concatenating formatives and adjusting thestrings ensuing from concatenation. Endings belonging to the sameinflectional paradigm will usually be found in the same sublexiconbut this is not guaranteed in any way and, more often than not, thesame sublexicon will contain other formatives, e.g. derivationalaffixes, as well. Due to the absence of the concept lexeme,wordformation cannot be represented as a relation between lexemes.However, if a wordform involves wordformation, its structure and itsrelation to formatives is represented, as well as the rule upon whichit was built.In DATR, the lexeme is the basic entity rather than the wordform. Alexeme corresponds to a specially marked node in the network, andthe wordforms of a lexeme's inflectional paradigm can be generatedby traversing the network starting at the lexeme node. A problemcase is alternation within a paradigm: for kneel, knelt, and kneeledwe specified a lexeme node and two subnodes for the alternative pasttense forms in section 2.3. This solution is unsatisfactory becausethe formalism will not represent the references from the lexemenode to the subnodes in the desired way but only those in the reversedirection. This means that it is not possible to generate theinflectional paradigm of the lexeme in such cases, i.e. it is notpossible to represent the concept of lexeme adequately.Since we have not found any implementation of wordformation inDATR, our evaluation will be slightly speculative in this respect. Weassume that it is possible to link a lexeme node to other lexemenodes to express morphological relatedness. Along this link, alsocertain types of information can be inherited, e.g. on syntacticargument structure. In order to encode the recursive destructuring ofa lexeme, it should be linked to its immediate constituents only. Thisinvolves creating nodes for affixes and other bound morphemes,specifying in some way or other that they have a different status tolexemes. We do not see any possibility of representing the rulesinvolved in wordformation. Apparently, the designers of DATRconsidered wordformation a task of the client applications. @SubSubSection{Generalizations}Two types of generalizations are meant here. On the one hand, thereare @Index{morphonological generalizations}morphophonological and@Index{morphological generalizations}morphological generalizations,reflecting the interaction of morphological rules with the writingand pronunciation system and with particular sets of items thatcannot be characterized in terms of spelling or pronunciation,respectively. On the other hand, there are@Index{subregularities}subregularities on a cline from general ruleto individual exception and @Index{syncretism}syncretism where asingle form is used at various places of the paradigm. Celex does not express any of these generalizations. However, sinceall wordforms are there in the database, it would in principle bepossible for a client application to inductively derive them from thedatabase.Two-level morphology has a very elegant way of expressingmorphophonological generalizations in two-level rules. Theformalism is similar to the ones usual in phonology. The applicationof the same formalism to morphological generalizations is rathernon-standard. The use of special characters in the string, instead offeatures, to trigger the relevant two-level rules is particularlyawkward.Subregularity can be expressed by combining sublexicons in variousways to constitute continuation classes. However, in the absence of adefault inheritance mechanism, the amount of duplication involveddoes not enhance elegance. For the same reason, syncretism cannot beexpressed elegantly. Either separate wordforms have to be built forfirst and second person singular, and first, second, and third personplural of the present tense of English verbs, or the full informationwill not be available since there will only be one form with a featuremeaning something like ‘present except third person singular’.DATR has a very elegant way of expressing subregularities of variousdegrees and syncretism. By the default inheritance mechanism,subregularities are intermediate nodes and any specification of afeature is interpreted as conditional, subject to modification by morespecific attributes or lower nodes.The expression of morphophonological and morphologicalgeneralizations, however, suffers from the representation of theparts of the string of a wordform as values of features and theabsence of a dynamic rule system. Morphophonologicalgeneralizations can actually not be expressed as such. Instead of ananalysis as properties of the writing or pronunciation system, theyare represented as properties of the individual lexemes, i.e. asdifferent conjugation or declension classes. There is no principleddifference to morphological generalizations. The solution for umlaut,as an example of the latter, proposed by Reinhard & Gibbon (1991)shows the disadvantages of a network structure with multipleinheritance that rapidly tends to become incomprehensible due tounexpected, complex interactions of the information from variousnodes.@SubSection{Computational Effectiveness}@Index{computational effectiveness}Computational effectivenessrelates first of all to the algorithm used in a system. For a systemlike Celex, using commercial database software as a basis, thecriterion is less relevant. The people that developed Celex did notdevelop the algorithm. The internal management, updating andcompilation of databases, are hidden from the user. In the access tothe databases, the user can give priority to fast creation of a view orfast access to the data in his personalized subset of the database.FMP systems are much more open to inspection in this respect.Two-level morphology seems to guarantee @Index{computationaltractability}computational tractability by its compilation into finitestate automata. Barton, Berwick & Ristad (1987), however,demonstrate that the system is NP-hard6 by reducing the SAT7problem to a set of two-level rules. If unrestricted use of zeros isallowed, they even show that the problem of FSA-intersection8 isreducible to the two-level model, making it PSPACE-hard. If aproblem is NP-hard, it requires exponential processing time withrespect to the length of the input for any solution algorithm on acomputer in the worst case, i.e. with the most difficult input.NP-hard problems are computationally intractable. If the problem isPSPACE-hard, the worst case performance of the best possiblealgorithm requires polynomial space with respect to the input length.An example of a PSPACE-hard problem is chess on a board ofunrestricted size.  Still, none of the problems linked to intractability have actuallyoccurred in work on two-level morphology and, as Koskenniemi &Church (1988) point out, they are unlikely to appear. Although zerosare necessary at surface level, the reduction of FSA-intersectionmakes use of them in a way that can easily be excluded withoutaffecting their use in the morphology of natural languages. Thetechnique applied in the reduction of SAT is similar to the one used inthe rendering of vowel harmony. However, whereas SAT crucially usesan unrestricted number of such processes, one for each propositionconstant in the input, Koskenniemi & Church (1988) claim not onlythat no more than two simultaneous vowel harmony processes havebeen attested for any natural language, but they also demonstratethat it is almost impossible for more than two such processes toappear simultaneously.Even though two-level morphology may be computationallyintractable in principle, tractability will be maintained for anynatural language use. The conclusion we can draw from thesecomplexity results is that two-level morphology as a language theoryis not sufficiently restrictive, rather than that its formalism iscomputationally not efficient. Natural language has more constraintson its morphology than two-level morphology imposes.The publications on DATR are more recent and we are not aware of anyformal discussion on the system’s complexity. Evans & Gazdar (1990)claim it is computationally tractable but there is reason to becautious about this claim. They also show that stronglycontext-sensitive languages can be handled by DATR, e.g. the languageconsisting of all strings XX, with X ranging over {a,b}*. According toBarton, Berwick & Ristad (1987), the problem of context-sensitivelanguage recognition is PSPACE-hard. This may well give rise to aconclusion similar to the one for two-level morphology.@SubSection{Intelligibility of the Data Structuring}@Index{intelligibility of the data structuring}The users that have to understand the data structuring are linguists,lexicographers, and client application programmers.The job of the linguists and lexicographers making Celex databases ishidden from inspection because only their product is exposed. Theclient application programmer has a well-documented user interfaceat his disposal to create a virtual lexicon and import it as a physicallexicon. The format of the physical lexicon is straightforwardlycomprehensible but it should be noted that for each client applicationa linguist will have to write morphological rules.Two-level morphology has a single ‘user interface’, the text filescontaining the lexicon system and two-level rules. For the linguist,the special characters make difficult reading. For the lexicographer,an additional difficulty is the absence of a clear distinction betweenlinguistic and lexicographical knowledge. In order to know how hisediting of the file affects the working of the program, he shouldactually be a linguist as well. For the client application programmer,the same problem arises but more seriously since the files are muchbigger by the time he has to start working with them. It seems as iftwo-level morphology was designed more for small-scale projectswhere the three tasks are fulfilled by a single person.With DATR, the situation is very similar. The linguist’s understandingof data structuring is hampered by the network structure. Even if thesystem is computationally tractable, tractability of humanprocessing of networks is doubtful. With the growth of the network,the complexity of keeping track of all interactions which ensue fromthe multiple default inheritance increases rapidly. Experience hasshown that modifiability decreases dramatically in such a system assoon as it reaches a certain size which is well below the sizerequired for the task under consideration here. This is even moreacute for the poor lexicographer who has to work with it and also forthe client application programmer.@SubSection{Redundancy and Consistency}There are so many aspects to @Index{redundancy control}redundancyand @Index{consistency control}consistency control that it is notfeasible here to give a complete overview. Instead, we have selectedsome issues pertaining to them to illustrate the differences betweenthe approaches. As for redundancy, we have looked at accidentaldouble entries and the emergence of a double entry fromwordformation. As for consistency, we have looked at the possibilityof propagation of changes, and we have looked for support in thediscovery of unused, dangling formatives.In the development of the Celex LDB, an internal software packagehas been devised to discover redundancies and inconsistencies in themaster database. As far as we understand, this package cannot beused during the construction of a database, but only in order toanalyse a completed database. Celex News does not specify thefunctions available in the package. Once a physical lexicon has beenextracted from the database, no more support is provided. The files of a two-level morphology database are normal text files.Only the functions available in the text editor in use can be applied totrace redundancies and inconsistencies. The absence of any means toexpress dependencies in wordformation, means that the only tool willbe a search function or, for the propagation of changes, a search andreplace function.Although in DATR the nature of the files is the same as in two-levelmorphology, the situation with respect to redundancy and consistencycontrol is slightly different due to the network structure involvedand the lexeme-based instead of the formative-based approach. Ininflection, dangling formatives are inherently excluded becauseformatives can only be specified as belonging to a lexeme or a classof lexemes. If wordformation is implemented along the lines sketchedin section 3.1.3, however, dangling formatives may come intoexistence, viz. bound morphemes not receiving any incoming referencefrom a lexeme.The expression of dependencies by references to other nodes seems toopen the way for all kinds of redundancy checks and propagation ofchanges. The semantics of the multiple inheritance, however,complicates the interpretation of any duplication found. What lookslike a redundant feature specification may well be an intentionallyadded feature interacting with inheritance. In the treatment of thealternation of the past tense of kneel in section 2.3, deleting one ofthe nodes kneel1 or kneel2 may make the other one superfluous, in thesense that it can simply be deleted as well but this depends on whichone is deleted in the first place and how the remaining one interactswith other nodes in the network. In the same way, propagation ofchanges could be envisaged by following the dependencies. Note,however, that incoming references of a node are not explicitlyrepresented. They have to be retrieved by the text editor’s searchfunction. Moreover, it is not obvious how far one should go in trailingthe dependencies through the network. In principle, one can only besure that consistency has been restored if every single relation in thenetwork has been checked. Here again human intractability of thenetwork structure stands out clearly.@SubSection{Other Database Properties}Since the remaining criteria derived from database properties aretightly interrelated, we will discuss them here together.@Index{data independence}Data independence addresses thesensitivity of the interface with client applications to changes in theunderlying data structure. The access to Celex via the user interfaceis independent of any changes in the underlying structure of the data.The interface acts as a buffer so that a modified data structure willonly result in a different translation of interface commands, withoutaffecting the interaction of clients with the interface. Such a bufferis lacking in two-level morphology and DATR. In two-levelmorphology, some level of data independence can be reached byrestricting the information accompanying the formatives to a lexemeidentifier. In DATR, changes for instance in the hierarchy of featurescannot be prevented from affecting the entire network structure,which in turn modifies the access questions to be asked by clientapplications to obtain the same bit of information.@Index{flexibility }Flexibility addresses the possibility of using thedata in several ways. Celex has made an effort to achieve a high levelof theory-independence and applicability to a variety of uses. Intwo-level morphology, the linguist may proceed in the same way asfor data independence to ensure as much flexibility as possible. Evans& Gazdar (1990) state that DATR’s value lists may be made to complywith any formalism. However this supports flexibility of the system,rather than flexibility of the dictionaries produced by the system,because once a formalism has been determined, flexibility ends.@Index{feasibility of different views}Different views on the data areprovided by the virtual lexicons in Celex LDB’s. Two-level morphologyhas sacrificed this facility to optimization of performance of asingle task. It is highly dedicated to the recognition and generation ofwordforms, and it does not provide views on inflectional paradigms,affixes of a particular type (e.g. derivational suffixes attaching toverbs), etc.. If the relevant information is encoded in features withthe formatives, as suggested above, a user interface could be writtenusing them to produce different views. In DATR, collecting wordformsbelonging to a single lexeme is relatively easy, except in the case ofalternation. There is no provision for looking at formatives. Inprinciple, a user interface could be devised using the featurestructure to create all kinds of partial views, as long as theyrepresent nodes in the feature hierarchy tree.The @Index{life expectancy of the data}life expectancy of the data, inthe sense of knowledge transfer, depends to a large extent on theflexibility of the system and the feasibility of different views. ForCelex, neither of these should constitute a big problem. For the twoFMP systems, more problems are to be expected, as can be deducedfrom the discussion above. At least portability of both is quite high.Both are implemented in standard languages (Pascal, Lisp, Prolog),and attention has been paid to either avoiding non-standard functions,as in Koskenniemi’s Pascal implementation of two-level morphology,or providing adaptation files for various dialects, as in Evans’sProlog implementation of DATR.@SubSection{Conclusion}The way @Index{Celex}Celex, @Index{two-level morphology}two-levelmorphology, and @Index{DATR}DATR have been evaluated here is unfair tothe systems involved. The unfairness arises from the fact that theyhave not been considered in their natural environment, taking intoaccount their designers’ aims, but instead in an environment wechose independently. This environment, however, is the problemdescribed in section 1.1, a real life problem, requiring an adequatesolution. All three systems under consideration offer patches of an adequatesolution, but all in all, each of them has too many drawbacks to beacceptable as such.Celex offers a nice user interface for client applications, with all theadvantages of an underlying database system, but leaves rule writingto individual client applications. Two-level morphology includesmorphological rules, and has a very elegant way of handlingadjustment rules, but it does not represent lexemes properly, and thetreatment of morphological generalizations tends to clutter theformative string with special characters. DATR represents thelexeme much better and handles different degrees of irregularity inan elegant way, but it is not well-equipped to treat adjustment rulesand its network structure tends to become humanly intractable. BothFMP systems lack the advantages of a database to adapt them forlarger than toy-size dictionaries. None of the three systems providesan adequate solution to wordformation.Word Manager is based on two-level morphology to some extent, butsubstantial changes have been applied, introducing properties of adatabase system, the concept of lexeme, alongside formatives, and aspecial wordformation component.@Chapter{The Word Manager Approach}@Label{ "Chapter 2" }In this chapter, an overview of the Word Manager system (WM) isgiven. In section 1, the components of WM, their connection, and themode of use they were designed for are presented. In section 2, someconcepts that are essential in understanding and using thedescription in the following chapters are discussed. @Section{Global Structure}Word Manager provides an environment for the building ofdictionaries with morphological information, to be used by anyNLP-system. The stages of the construction of such a dictionary andits further processing are represented schematically in Fig. 2.1together with the people involved in the work.@Figure{ "Construction and use of WM-dictionaries. " | "131" | 385 | 407 }   The @Index{linguist}linguist starts working with an empty database.It contains initialized windows, i.e. slots for encoding various typesof information. His job is to formulate rules for all regular processesof inflection and wordformation of a particular language, withexamples of their application, as well as a description of irregularprocesses, with a list of all cases they apply to. This is themorphological rule database. An example of such a database is the onefor Italian described by Bopp (1992). A similarly complete databasefor German is currently under development. Most of the rest of thisbook will be devoted to the details of the linguist’s task.The morphological rule database is passed on to the@Index{lexicographer}lexicographer. The tasks of theWM-lexicographer can be subsumed under the heading of associatinglexical items with the rules in the database. Often, dictionariespublished as a book contain a section with inflection tables. Codes inthe entries refer to these tables. The task of representing inflectionin WM is fairly similar to representing it in a traditional dictionarywith inflection tables. Setting aside the representation of inflection, there are twoimportant differences between the job of the WM-lexicographer andthat of a traditional lexicographer. First, traditional lexicographyconcentrates to a large extent on assigning definitions to lexicalitems. This task is cancelled in WM because WM-dictionaries do notcontain definitions. Secondly, traditional lexicography is much lessrigorous in its representation of word structure which arises from@Index{wordformation}wordformation.From an entry in a traditional dictionary, it is often not clearwhether the item described is the result of a wordformation processand if so, which rule has applied and to which elements it has applied.In the reverse direction, lexical items derived from the itemdescribed are almost never referred to in a consistent way.Sometimes, derived items are described as run-on entries of an entrythey are related to, as far as this does not interrupt the alphabeticalorder, but this is a measure of economy (space), rather thanlinguistically motivated.An exception is Dubois et al. (1971), Dictionnaire du françaiscontemporain. Here a single entry groups together derivationallyrelated items such as code, coder, codage, décoder, décodage. Aproblem with this strategy is created by the book-form of thedictionary. In order to find décoder, one has to know that it is derivedultimately from code. Moreover, there is a problem with compounds,since in order to be consistent, compounds like tire-bouchon(‘corkscrew’) and chasse-neige (‘snow clearer’) should actually bedescribed in two places. In fact, they are described under boucher(‘block’) and chasser (‘chase’), respectively, which is ratherinconsistent.The WM-lexicographer should give an explicit analysis in immediateconstituents for each derived item. This is achieved by associating itwith a rule of the rule database and specifying the elements on whichthe rule has worked as far as they are not mentioned in the rulealready. For an item like self-determination, the lexicographer has toexpress that it consists of two parts, self and determination (unlesshe decides to treat it as unsegmented which is unlikely). Whether selfis a prefix or the first part of a compound is a decision that mighthave been taken by the linguist, but otherwise the lexicographer hasto decide. If determination does not yet occur in the database, it hasstill to be analyzed, e.g. by associating it with a rule of ationsuffixation, with determine as input and if determine does not yetexist, it has to be associated with the correct inflection rule. As aresult, all wordformation relations of a formative or a lexical itemare retrievable on the basis of their structure. That structure-basedretrievability is preferable to the alternative of string-basedretrievability offered by other dictionaries to various extents, can beconfirmed by anyone who has the experience of looking for all wordswith un, and having to go through all words with under- one by onein order not to miss out on items like underived.The morphological dictionary is made available to @Index{clientapplication}client applications. In principle, any NLP-system thatneeds one or more morphological dictionaries can use the onesprovided by WM. In order to bring about the connection and adapt theformat, a programmer will be necessary. For non-morphologicalinformation, such as pronunciation or translation, the clients willneed linguists and lexicographers. They can fully concentrate onapplication- and theory-specific information, without botheringabout morphology.@Figure{ "Word Manager and client applications." | "132" | 400 | 295 } In Fig. 2.2, the connections between the various parts of WM amongthemselves and with client applications are represented. The centralpart of WM is the @Index{server}server, represented by the circle inthe middle. It mediates between @Index{WM-interface}interfaces -represented by rectangles - and databases. A pilot implementation ofthe WM-server runs on an Apple Macintosh, but since the server hasbeen implemented more or less in pure CLOS (Common Lisp ObjectSystem), it is virtually machine-independent. The server and theclient applications are meant to run as processes in a network. Theyare typically not installed at the same location, but linked by a local,metropolitan, or even wide-area network. The interfaces each provide a specific view on one or more databases.Two of them are privileged, in the sense that they may modifydatabases. The @Index{CMKS (Conceptual Morphological KnowledgeSpecification environment)}CMKS (Conceptual MorphologicalKnowledge Specification environment) is the interface for thelinguist. It allows the creation of new databases, and thespecification, modification and deletion of all kinds of information inthe databases. The @Index{lexicographer’ interface }lexicographer'sinterface allows adding, modifying, and deleting entries only. Therules, as they were specified in the CMKS, are available only toassociate entries with them. The interface provides severalfacilities to support the lexicographer in the specification of theseassociations.Each @Index{client application}client application will have its own interface to theserver, tailor-made so as to comply with specific requirements ofthe client. For a primitive spelling checker, the interface will simplyask the server whether strings occur as wordforms in the database ornot. If this is not the case, the spelling checker interface can ask theWM-server to analyze the string with the help of the regularwordformation rules in the database. With this information, thespelling checker can return relevant messages to its (human) user. A slightly more complicated situation arises when the client programrequires additional information, e.g. the phonological information of atext-to-speech converter. Now, the client application interface notonly has to ask the WM-server to analyze a string but it also has toassociate extra information with the answer returned by WM. In thecase of a machine translation program, the extra informationcontains the translation, i.e. a reference to one or more entries ofanother WM-dictionary. Thus, the machine translation programinterface has to keep track of the links between pairs ofWM-dictionaries, as well as the syntactic and semantic informationassociated with entries of both dictionaries.In the philosophy of WM, it is acknowledged that creating a dictionaryis a process that never ends in a stable, perfect result. Even when adictionary has been released, regular @Index{updates ofWM-dictionaries}updates will take place, adding entries, andcorrecting information provided with the entries for example. If theclient application is directly connected to the server asking itsquestions to WM at runtime, the modifications are accommodatedautomatically. In principle, the answer to a given question maychange from one minute to the next, always representing the mostrecent state of the dictionary. An alternative is for a clientapplication to download a WM-dictionary. Instantaneous, automaticupdates are replaced by less frequent, periodic updates of a largerpart of the dictionary, and in the interval between updates, theinformation is guaranteed to remain stable. In both cases,system-specific information will be kept distinct fromWM-information pertaining to the entries.The WM proper consists of the server and the two privilegedinterfaces: CMKS and lexicographer’s interface. The CMKS allows thelinguist to work with a comfortable formalism, because it introducesa meta-level that abstracts away from the runtime formalism. In the@Index{compilation}compilation step, the contents of the database asspecified by the linguist are transformed into an internal format.This has two important advantages. First, compilation permits anoptimization of the way data are represented internally, byautomatically choosing from among various possibilities oftransforming a particular database into the internal format, thusguaranteeing optimal runtime efficiency without affecting the waythe information is visible through each of the interfaces. Secondly,during compilation every rule specified in the WM-database isexecuted so that many of the possible syntactic and semantic errorsthat might have been made in rule specification can be spotted beforethe database, as produced by the linguist, is made available to thelexicographer. As a consequence, the linguist must include@Index{hard-coded entries}hard-coded entries as examples so thateach rule can be fired. Violations of the syntax of theCMKS-formalism are relatively easy to find. As to semantic errors,compliance with a number of @Index{context-dependentrequirement}context-dependent requirements is checked duringcompilation. Violation of these requirements implies that theformalism has been used in a way that does not make sense, althoughit is correct from a strictly syntactic point of view. Compilation willgenerate error messages if violations are discovered. A number ofless rigid conditions are also checked during compilation becausetheir non-observance usually, though not necessarily, signals anerror. The compiler issues warning messages if these conditions arenot obeyed.In the development phase of a morphological rule database by thelinguist, compilation plays an important role in error detection. Thecompilation of small databases such as the ones described inchapters 3 and 4, takes only a few seconds. As databases grow,compilation time rises steeply because the time required by some ofthe tasks of the compiler grows exponentially with the amount ofdata. Full compilation of a complete database such as the onedescribed by Bopp (1992) for Italian, takes some 10 minutes on afairly fast machine9. In order to allow the linguist to workefficiently, WM offers an incremental compiler. This compiler firstchecks what has been modified in the database, then accommodatesthese modifications in the existing compilation with as few changesas possible. @Index{incremental compilation}Incremental compilationof a small change to a complete database will often take only a fewseconds. This permits the linguist to compile frequently withoutwasting too much time and thus to detect errors at an early stage.Moreover, a cyclic construction process for a WM-database becomesfeasible, consisting of a specification phase, incrementalcompilation and a testing phase. Specification results in a databasewhich becomes operational by compilation. The @Index{operationaldatabase }operational database is tested, giving rise to extensionsand correction in the next specification phase. @Section{Some Basic Word Manager concepts}In this section, some concepts are discussed that are either toogeneral or too detailed to fit into the description of the CMKSformalism in the following chapters. Section 2.1 introduces thedocument window and other types of windows in the CMKS, and givesa global overview of the distribution of information betweenwindows. Section 2.2 details which character sets can be used atvarious places in the system. It also contains some remarks on therepresentation of examples in the description of theCMKS-formalism. Finally, section 2.3 gives some important details onWM-database management.@SubSection{Windows}@Index{WM-window}@label{"WM-approach-windows"} The CMKS is organized as a hierarchy of windows. A window offers aview on a certain part of the database. Three types of windows can bedistinguished on the basis of how their contents can be modified:document windows; tree windows; and text windows. Each databasehas a single @Index{document window}document window. It is the topof the hierarchy and cannot be edited from within the CMKS. From thedocument window, other windows on the database can be opened. Treewindows can be changed by a tree editor. They contain nodes, orderedhierarchically in a tree structure. Each node refers to a text windowthat can be opened from within the tree window. Text windows can bemodified by a text editor.@Figure{ "Document window" | "133" | 329 | 216 }.Fig. 2.3 represents the document window of a database calledItalian-1. The title bar of the window contains the name of thedatabase. Below this bar, there are three groups of buttons, thesecond one of which is labeled Word Manager, and the third one PhraseManager. @Index{Phrase Manager}Phrase Manager (PM) is anextension of WM, currently under development. WM has eight windowbuttons, and two window buttons are outside both WM and PM. Most ofthe WM window names are abbreviated in the document window. Theirfunctions can be described as follows:@Item lex char is the @Index{lexical character set window}lexicalcharacter set window. It lists all characters that are used for therepresentation of strings in the database.@End-Item @Item surf char is the @Index{surface character set window}surfacecharacter set window. It lists all characters that are used in thestring representation of the output of the rules. The surfacecharacter set is a subset of the lexical character set.@End-Item @Item feat dom is the @Index{feature domains window}featuredomains window. It lists all features used in the database. A featureis an attribute-value pair, e.g. cat=noun.@End-Item @Item feat dep is the @Index{feature dependencies window}featuredependencies window. It states relations that hold between features,such as implications.@End-Item @Item inflection is the @Index{inflection window}inflection window.It contains rules and formatives covering inflection.@End-Item @Item wordform is the @Index{wordformationwindow}wordformation window. It contains rules governingwordformation, and formatives used by these rules, as far as they donot occur in inflection independently.@End-Item @Item spelling is the @Index{spelling rule window}spelling rulewindow. It contains rules that modify the string of formatives in aspecified context.@End-Item @Item test is a text window not used by WM. It is meant to be usedfor test purposes. @End-Item The inflection and wordformation windows are @Index{treewindow}tree windows. All other windows are @Index{text window}s.The two windows that can be opened with the buttons above theWM-field are the following: @Item browser: When a database has been compiled, the@Index{browser}browser offers views on a great variety of relations betweenlexemes, wordforms, formatives, and rules of all types.@End-Item @Item messages: When compilation has been completed successfully,or when problems arise during compilations, relevant messages willbe sent to the @Index{messages window}messages window.@End-Item @SubSection{Characters and White Space}Formative strings in a WM-database are represented by characterstaken from the set of @Index{system characters}system characters.This set excludes the @Index{reserved characters}reservedcharacters used by WM-syntax in the description of strings. Thereserved character set of WM consists of the following characters:10@Verbatim " [ ] ^ . * ? | ( ) \ / { }@End-Verbatim The system character set includes signs, characters with diacriticmarks, and characters used in Scandinavian languages, besides themore normal letters and digits. Examples are:@Verbatim $ & @ = % ƒ (etc.)à á â ä ã ç (etc.)æ ø  Æ Ø Å@End-Verbatim As far as they do not belong to the first 128 characters of ASCII,they are transformed internally in such a way that@Index{portability}portability between different machines isguaranteed. A @Index{lexical character set}lexical character setspecifies a subset of the system character set, used in therepresentation of strings in a particular database. Any character inthe lexical character set that is not a member of the surfacecharacter set is called a @Index{special character}special character. Strings used as rule names or attributes and values of features are@Index{WM-symbol}WM-symbols. The WM-symbol is a restrictedvariant of the Common Lisp (CL) symbol. It consists of a sequence of@Index{alphabetic character}alphabetic characters. The followingcharacters belong to the set of alphabetic characters:@Verbatim a b c d e f g h i j k l m n o p q r s t u v w x y zA B C D E F G H I J K L M N O P Q R S T U V W X Y Z0 1 2 3 4 5 6 7 8 9+ - * @ $ % ^ & _ \ < > ~ [ ]@End-Verbatim Thus, characters with diacritic marks are not permitted in rulenames or features. An additional condition, inherited fromCL-symbols, is that a WM-symbol may not consist entirely of digits.Thus, the feature for first person may be (person 1st) or (person _1),but not (person 1).The morphological rules in a WM-database reflect an analysis oflanguage data. Although the CMKS-formalism is quite readable, inmost cases, the data and their analysis underlying a rule are notdirectly represented. Thus, another linguist, or even the same linguisthalf a year after writing a rule, will usually see what is meant by therule but sometimes will not understand why the rule has beenformulated in this way. Therefore, documentation is often helpful. Inmany places, WM offers the possibility of including a@Index{comment}comment. Any line not used for specification can beused for comments. The comment starts with ; and ends at the end ofthe line. Everywhere where the WM-syntax asks for a new line, it ispossible to start a comment with a ; separated from the specificationtext by a space (cf. the syntax description in the Appendix11).In principle, only alphabetic characters, spaces, tabs, and full stopsare allowed in comments. The reason is that comments aredisregarded completely by the system so that the transformationapplied to system characters in order to guarantee portability, doesnot see comments. Therefore, no error message will appear if, forinstance, a WM-rule is commented, even if it contains non- alphabeticcharacters, but on another machine, the commented rule may appearmutilated.From among @Index{white-space characters}white-space characters,<space>, <tab>, and <newline> are used by WM-syntax, and they arecontrastive in meaning. Since there is no maximum number ofcharacters on a line, the meaningful use of <newline> does not causeany difficulties or confusion. For purposes of clarity of layout, anynumber of <newline>'s is allowed where a comment may occur, i.e. aline without text technically counts as a comment line. Confusionmay arise in the distinction between <space> and <tab>, because <tab>is not always realized by an equal amount of white space. In order tominimize the problem, it has been made impossible to enter twoconsecutive <space>'s in WM, and if a <tab> would produce less whitespace than the equivalence of three <space>'s, the systemautomatically inserts a second <tab>.In the chapters 3, 4, and 5, many examples of WM expressions will begiven. With these examples, it is not always possible or desirable torepresent the expression in the same way as it appears on the screen.On the one hand, the distinction between <tab> and <space> should berendered unambiguously. On the other hand, the unambiguous use of<newline> cannot be maintained in the same way because a bookimposes a maximum on the number of characters on a line. Therefore,the following conventions will be used: @Item A WM <space> is always represented as a <space> (" ").@End-Item   @Item A WM <tab> is always represented as " » ", except at thebeginning of a line, where it is represented as "» ". @End-Item @ItemA WM <newline> is always represented by a new line.@End-Item @Item A <space> in the book always represents a WM <space>, exceptwhere it is followed by ». @End-Item  @Item When a <newline> in the book does not represent a WM<newline>, it is followed by an indent of one inch. These extra<newline>'s are inserted when the line would otherwise be too long tofit between the margins. The position in the expression where theyare inserted has no meaning in WM but an attempt has been made toput them in places where they do not hamper intelligibility. Thisusually implies that a <space> precedes the newline plus indent.Otherwise, the sign Æ signals the absence of a <space> before anewline plus indent. @End-Item @SubSection{Creating, Modifying, and Saving Databases}WM is available in two versions. One of these corresponds to Fig. 2.2,with a server on a separate machine and interfaces connecting withthe server over a network. The other version consists of a server anda CMKS-interface on a single machine. Since no other interfaces canconnect to the server, this version is only relevant for thedevelopment stage of a database before the dictionary is added.From the @Index{server}server, databases can be opened, closed, andsaved. In regular use of the network version, all databases will bepermanently open. The 'close' option will not be normally used. The'open', 'close', and 'save' commands are also available in the@Index{CMKS (Conceptual Morphological Knowledge Specificationenvironment)}CMKS but their meaning is relative to the server. In theCMKS, a database can be opened from the server only so that it is aprecondition that the database is already open on the server. Closingdatabases in the CMKS closes the link to the database on the server.Saving a database in the CMKS sends the new state of the database tothe server. It stays in primary memory on the server, where it existsalongside the older version of the database. Only the 'save' commandof the server will save the changes to secondary memory,substituting the modified version of the database for the previousone. Other @Index{WM-interface}interfaces besides the CMKS have 'open'and 'close' commands at their disposal but apart from thelexicographer's interface, they cannot save a database to the server.The development of a database on the CMKS starts with the creationof a new database. A new database has a document window, andsubwindows which are controlled by the document window. Some ofthese subwindows are initialized to certain contents, the rest areempty. From the CMKS, editing, compiling, and testing of the databasecan be done by a variety of commands. The @Index{lexicographer'sinterface}lexicographer's interface allows testing and a restrictedform of editing, affecting entries only, not rules. Via otherinterfaces, only querying of databases is possible.@Chapter{Inflection}In this chapter, those parts of WM-grammar that are related toinflection will be described. As we mentioned in the preface, we willstart each time with a fragment of natural language and describe thechoices that have to be made in devising a database for it. Thechapter consists of two sections, each corresponding to a database.Together they cover everything a linguist has to know in order towork with WM, except for the implementation of wordformation. Thefollowing WM-windows are covered: lexical and surface character set(except character sequence ordering), spelling rules, and inflection.The first section, on Italian nouns, presents the elements of aWM-database on the basis of a minimal set of language data. Thesecond section, on Dutch verbs, tries to give a taste of what a moresophisticated database would look like. Without introducing manynew WM- features, it is shown how a considerably larger set of datacan be covered and organized. The set of data has been chosen with aview to presenting interesting organizational questions, to beanswered without boring the reader with an excessive amount ofdata.Each section is divided into subsections that are described in threesteps. First the set of data of the language is presented. Then theways they can be approached from a WM point of view are described.Finally, one or more of the approaches are implemented, resulting in adatabase.@Section{Italian Nouns}@Label{ "chapter 3.1." }In this section, a fragment of Italian nominal morphology ispresented, as well as the WM-mechanism to handle it. The section isdivided into two parts. In the first subsection, some regular nominalparadigms are presented, as well as the basics of the WM characterset and inflection windows. By the end, an elementary WM databasehas been created. The second subsection presents some regular Italianspelling strategies, and introduces WM spelling rules and specialcharacters.As a source for the Italian data, we used Dardano & Trifone (1985). Bynot taking into account more complicated cases, we deliberatelyrestricted the scope of the database linguistically. We havegratefully used Bopp (1992)'s description of a full WM-database butbecause our purpose is describing WM, rather than Italian, oursolutions sometimes diverge from his.@SubSection{Regular Cases}@SubSubSection{The Data}In Italian, nominal wordforms are in general specified for number andgender. Gender is an inherent property of the lexemes, whereasnumber is an inflectional category. Hence, the paradigm of an Italiannoun consists of two forms, the singular and the plural. In the simplecases that we will consider first, the nominal wordform can be splitup into a stem and an ending expressing number. The following areexamples of the main paradigms found in Italian:  @Verbatim strad-a        strad-e        ('street')  giorn-o        giorn-i        ('day')  chiav-e        chiav-i        ('key')@End-Verbatim The first paradigm contains feminine nouns, the second (mainly)masculine nouns. In the third, both genders are represented equally,chiave is feminine, cuore ('heart', plural cuori) is masculine.@SubSubSection{The Treatment}In order to account for these paradigms in WM, we have to list theparadigms, the stems, the affixes and the links between them. Thestatements we will make are of the following kind:  @Item strad is a female noun stem @End-Item @Item a is a suffix to a noun stem, making it a singular noun@End-Item @ItemThere is a class of nouns, say N1, having a singular in aand a plural in e. @End-Item @Itemstrad belongs to class N1.@End-Item The most natural way of describing the paradigm involves mentioningthe suffixes explicitly. In this way, the link between the suffixes andthe paradigm is expressed in the rule window automatically. Therelation between stems and the paradigm they belong to is alsoexpressed by including them in the same window. Thus the rulewindow holds a central position in the description, containing theparadigm and the information about the links. Elsewhere, all materialthat is used in the rule window has to be listed in@Index{declaration}declarations12, sorted according to type. Thereare separate windows not only for the declaration of stems andaffixes, but also for the building blocks used to describe their formand properties, i.e. characters and features.The @Index{IRule window}rule window consists of at least threeparts, citation forms, wordforms, and entries.13 The@Index{citation-forms}citation forms correspond to the@Index{headword}headwords under which the lexeme is described in atraditional dictionary, e.g. strada.14 The form taken as a citationform is usually determined by tradition. The form is entered here as aformula matching the class of stems, and the affix that is used, e.g. 'anoun stem from the a/e-class, and the suffix a'. In the@Index{wordform}wordforms section, the different forms and theirqualifications are given. In our example, the statements of thissection can be interpreted as 'a noun stem from the a/e-class, andthe suffix a form a singular noun and a noun stem from the a/e-class,and the suffix e form the corresponding plural noun'. Finally, the@Index{entry}entries section is a list of all stems that theparadigm applies to. For each entry, specific features may be added.For strada, this may be 'cat = noun, gender = feminine'. As we will seebelow, WM provides ways to express the generalization that all nounsin this class have these features.The @Index{declaration}declarations of the material used in the rulewindow are of four types, each having their own window. Charactersand features are declared in windows immediately dominated by thedocument window, and stems and affixes are declared in windowsdominated by the inflection window. Characters are declared twice,in the @Index{surface}surface @Index{character setwindow}character set and @Index{lexical character setwindow}lexical character set windows, each containing a list of thecharacters in alphabetical order. For the data covered in this section,the difference between the two lists is not relevant. The@Index{feature domains window}feature domains window contains alist of all attributes with their possible values.Stems and affixes are declared in formative windows of differenttypes. The main difference is that stems constitute an open class,whilst the class of affixes is closed. For stems, names as used in therules are listed as a kind of class identifiers so that the systemknows they exist. Windows where open class elements are declaredare called @Index{underspecified formative window}underspecifiedformative windows. Affixes can be listed exhaustively because theyform a closed class. Each affix is assigned features, expressing theinformation it contributes to the wordform it occurs in. In ourexample, a will be assigned the feature 'number = singular', and e willhave two entries, one with 'number = plural' and one with 'number =singular'. Windows where closed class elements are declared arecalled @Index{fully specified formative window}fully specifiedformative windows.From the above description we can derive three rule windows and twoformative windows, covering the three inflection classes, the stem,and the affixes. They are to be dominated by the @Index{inflectionwindow}inflection window. The three rules are closely related, and itis natural to group them together when we later define rules, e.g. forverbal inflection. It makes sense to collect the declaration of allaffixes in the present rules into a single formative window. Affixesfor verbal inflection, however, should rather be stated in a separatewindow, not directly related to the rules for noun inflection. In viewof these considerations, the inflection window is divided intoinflection units. An @Index{inflection unit}inflection unit is a groupof rules with a common denominator, associated with a set offormatives.In our example, we could create an inflection unit for nouns.Inflection units are not bound to syntactic category, however, and ifwe like, we could also divide the nouns according to gender. In thatcase, we would have two inflection units, each consisting of two rulewindows, and two formative windows. The rule for the e/i- class hasto be duplicated since it operates on masculine as well as femininenouns. Splitting up the nouns into two inflection units does not implythat we have to abandon the 'cat = noun' generalization, for we mayspecify as many intermediate levels as we want, thus creating a treeof arbitrary depth. The tree has a single root, its leaves are the ruleand formative windows, and somewhere in between is the level ofinflection units.Every node in the tree is a window having a name and contents. Thecontents of the leaf node windows is what we have described above.Non-terminal nodes are @Index{comment window}comment windows.They are usually empty, but any contents will be disregarded by WM.The name of a @Index{naming system}window describes thepath from the root to that window. For every node, the name consistsof the name of the node it is dominated by, its mother, and thefurther specification with respect to the mother node,differentiating it from its sister nodes.From the root to the inflection unit level, the further specification isa feature or a set of features. In the node name, root is omitted. Thus,in the second alternative for inflection units sketched above, thenodes are called cat = noun, gender = masculine and cat = noun, gender= feminine. From the inflection unit level to the leaves, the rulenodes are specified by a (part of a) rule name, and the formatives byfeatures. In the name of a rule window, the path from the root to theinflection unit is omitted.The features specified on nodes in the tree are not only used in thename of the nodes, but also on wordforms defined in the leaves. Allwordforms defined in rule windows dominated by the node cat = nounwill inherit the feature cat = noun. Thus only the features inherent ina lexeme that are not mentioned in the path have to be specified inthe entries section of the rule window. The two alternative ways ofstructuring the rules for Italian nouns into inflection units we haveintroduced above, both have their advantages and disadvantages. If wetake two inflection units, specified for gender, the rule for thee/i-class has to be stated twice because it applies to nouns of eithergender. The value of gender is inherited from the name of theinflection unit that the rule window belongs to. If we assume onlyone inflection unit for nouns, there will be a single rule for the e/i-class, but gender has to be specified explicitly for each individualentry.Sometimes, although it is clear that a division in several branches isjustified, there are no straightforward features to describe thedivision. In our example, this applies to the formative windows. Inorder to overcome this problem, a special attribute has been createdto collect all specifications that should not be inherited by theentries. This attribute is @Index{ICat}ICat, where I is an abbreviationof inflection.@SubSubSection{The Implementation}In order to use WM, at least the following windows have to bespecified:  @Itemsurface character set@End-Item  @Itemlexical character set@End-Item @Iteminflection@End-Item @Itemfeature domains@End-Item The @Index{surface character set window} @Index{lexical characterset window} character windows consist of two parts, headed by thekeywords character-sort-order and sequence-sort-order. In theformer, all characters are listed in alphabetical order. Otherpossibilities offered for these windows will be explained later whenwe need them. When opened for the first time, the windows look as inFig. 3.1. Since in our example we do not have other characters thanthe ones listed here, we do not have to change the windows. @Figure{ "Default instantiation of character set windows." | "134" | 398 | 389 }The @Index{inflection window}inflection window will contain a treeof windows, the terminal nodes of which are the rule and formativewindows. When opened for the first time, the inflection windowcontains the node root. Nodes can be added by means of a @Index{treeeditor}tree editor. Commands can be given by pulling down the editmenu from the system menu bar. The New Son and New Brothercommands create a new node with the specific relation to a nodeselected in the tree. They open a dialog box where apartial@Index{naming system} name is to be entered,enclosed in brackets. The full name is the complete path from theroot or, for rule windows, the complete path from the inflection unit.A feature is entered as e.g. (cat noun). Rules have names such as(RIRule a/e), where @Index{RIRule (regular infection rule}RIRulestands for regular inflection rule (other types of rules will beexplained later). Formative windows are specified as e.g. (ICat stem).All nodes in the tree should have a unique full name. Because for rulenodes the path from the root to the inflection unit is not mentioned inthe name, we cannot, if we have inflection units specified for gender,call both rules for the e/i- class RIRule e/i. Rather we shouldmention the difference between them in some way, e.g.@Index{RIRule(regular inflection rule} RIRule fem-e/i and RIRule masc-e/i. We endup with an inflection window as in Fig. 3.2 for the strategy involvingtwo inflection units.                @Figure{ " An  inflection window." | "135" | 274 | 205 }@Index{inflection window}Once the nodes have been created, the corresponding windows can beopened by double-clicking on the node in the tree. The rules andformatives are entered as normal text. The formative window forstems starts with the keyword underspecified IFormatives. Then thestem classes are introduced. The stem strad belongs to the a/e-class,represented as _ » (ICat a/e). Note that the difference between <tab>and <space> is essential for WM-syntax (cf. the discussion in chapter2, section 2.2), and that the text of each window should end with a<newline>. Thus our window will look like Fig. 3.3:                @Figure{ "An underspecified IFormative window." | "136" | 388 | 108 } @Index{underspecified IFormative window}When the window is reopened after having been closed, WM will havemarked the keywords underspecified IFormatives, producing a moreperspicuous layout.The formative window for affixes starts with the keyword fullyspecified IFormatives, followed by a list of affixes. Every affix islisted by lexical form, surface form, and information it contains, e.g."a" "a" » (ICat a)(number singular). In this example, the information issplit into syntactic information and an identifier, a feature added tomake the feature list unique among all feature specifications ofaffixes in the inflection unit. An example window is Fig. 3.4:                        @Figure{" A fully specified IFormative window." | "167" | 368 | 138 } @Index{fully specified IFormative window}The rule window starts with the keyword@Index{citation-forms}citation forms, after which the citation formsare described by means of a formula referring to the place where theelements have been declared. For nouns like strada, the followingformula can be used:@Verbatim (ICat stem.a/e) »   (ICat suffix.a)@End-Verbatim The dot between stem and a/e represents a path specification, henceit refers to ICat = a/e within the ICat = stem window. The plural formof the keyword may be surprising at first sight, since every entrynormally has a single citation form. By the way the formula isinterpreted, however, the possibility of multiple citation forms isinherent. The formula gives a number of conditions, and refers to theclass of forms matching all of them. The above formula thus definesas citation forms for an a/e-stem the stem followed by thosesuffixes that have the feature (ICat a). If an analogous formula isused for e/i-nouns, chiave will get two citation forms, because twosuffixes e have been declared in the relevant formative window. Thesecond citation form can be eliminated by further specifying theformula, producing e.g.@Verbatim (ICat stem.fem-e/i) »   (ICat suffix.e)(number singular)@End-Verbatim The wordform section starts with the keyword@Index{wordform}wordforms15, followed by a list of formulaereferring to the wordforms. The formulae referring to stems andaffixes are syntactically identical to the one used in the citationform. In principle, each formula can be written so as to contain onlythe minimal amount of information required to identify the correctset of formatives. This strategy has a serious disadvantage, however.The question is what the minimal amount of information thatexcludes all other formatives is or, more particularly, whether agiven feature in the specification can be left out without affectingthe set of formatives selected. This can only be answered by lookingat what other formatives exist, and how they have been specified.Adding a new formative, or changing the description of an existingone, may thus influence the answer. If, for instance, this strategywere applied to the feminine nouns inflection unit at a point where itonly contains a/e-nouns, the plural suffix -e could be specified aseither (ICat suffix.e) or (number plural). After adding the e/i-nouns,however, both of these possible formulae would have becomeambiguous. Therefore, it is better to specify the full information, i.e.both features, from the beginning, even if it is over-specific, in orderto avoid unwanted ambiguities later on.In the @Index{entry}entry section, each entry consists of akeyword entry and on a new line starting with <tab> the lexical andsurface forms of the stem. If @Index{individually addedfeature}lexeme-specific features are added, they follow thekeyword entry, and are separated from it by a <tab>. Thus, dependingon our choice where to represent gender, an entry for strada will lookeither something like:@Verbatim entry »   (gender feminine)»   "strad" "strad"@End-Verbatim or if gender is included in the inflection unit name, it will have thefollowing shape:@Verbatim entry»   "strad" "strad"@End-Verbatim Since every rule must be applied to a hard-coded entry at least once,a rule window normally contains at least one entry.16 In our examplethe window could look like Fig. 3.5:                   @Figure{ "An RIRule window." | "137" | 354 | 173 }.@Index{RIRule window}The @Index{feature domains window}feature domains window shouldcontain a declaration of all features used in the database. Thisdeclaration can be generated by WM automatically as a side effect ofchecking the syntax. The @Index{syntax checker}syntax checkerdiscovers syntactic errors, and presents a list of features notdeclared yet, asking whether they should be added in the featuredomains window.When the rules, formatives, and entries have been specified, thedatabase can be @Index{compilation} compiled. The compiler willsignal any syntactic or semantic error it discovers, and send an errormessage to the messages window. As an option, the user may let thecompiler generate the citation forms of the hard-coded entries in themessages window. After successful compilation, the user has variousbrowsing tools at his disposal to test the rule specification chosen,by inspecting its effects on the hard-coded entries. For an individuallexeme, the@Index{ lexeme browser}lexeme browser is the mostpractical tool. Fig. 3.6 shows a lexeme browser view of strada.                @Figure{ "The lexeme browser." | "138" | 400 | 304 } @SubSection{Some Complications with c and g}@SubSubSection{The Data}Although in Italian the relation between spelling and pronunciation ismuch more regular than in English, there are a few cases ofincongruence. The letters c and g are used to represent two differentsounds. When they are followed by a consonant or one of a, o, or u,they are pronounced like c and g in the English words cat and gorespectively. When followed by e or i, they are affricatives,pronounced approximately as ch and j in the words church and jugrespectively. In order to spell a ch or j sound before a, o, or u, an i isinserted between c/g and a/o/u. In order to spell a k or g sound beforee or i, an h is inserted between c/g and e/i. Thus in the followingexamples, the first sounds of the Italian words are the same as thefirst sounds of the English translations.  @Verbatim cultura        culture  Cina           China  cioccolato     chocolate  chilometro     kilometre@End-Verbatim These spelling particularities interact with the plural formation ofnouns of the a/e and o/i classes. The following two cases are directconsequences of general Italian spelling rules relating to c and g: @Item If in the singular the a or o ending is preceded by c or g, an hshould be inserted in the plural, to preserve the sound. @End-Item@Item If in the singular the a or o ending is preceded by ci or gi, the iis not needed in the plural to get the same sound.@End-Item These rules are illustrated by the following paradigms:@Verbatim   amica          amiche         ('girl-friend')  fungo          funghi         ('mushroom')  spiaggia       spiagge        ('beach')  bacio          baci           ('kiss')@End-Verbatim Although these regular interactions are the rule, exceptions exist aswell. Thus we find the following paradigms:  @Verbatim allergia       allergie       ('allergy')  camicia        camicie        ('shirt')  amico          amici          ('friend')@End-Verbatim In the case of allergia, there is an obvious explanation for themaintenance of the i: it is stressed, hence it has another functionbesides influencing the preceding g. As a rule, a stressed i isretained. In camicia, the second i is unstressed, yet it is retained.This is the case for nouns of the a/e-class where ci/gi is preceded bya vowel.17 Finally, amico is simply a lexically determined exception.@SubSubSection{The Treatment}A simple way to incorporate the above data is to create new RIRules,for classes of nouns whose singular / plural alternation is a/he-,o/hi-, ia/e-, and io/i. However, such a representation would notreflect what is actually happening here because, rather than being theresult of new plural formation rules, these alternations are theresult of the interaction of regular plural formation rules andindependent, general spelling strategies of Italian. Word Managerallows a direct simulation of this interaction. Without altering theinflection rules as formulated in section 1.1, spelling rules can beformulated to take care of the insertion of h and the deletion of i inthe appropriate positions. Various strategies are conceivable, threeof which we will discuss here.A first strategy is to focus on pronunciation. After all, Italianspelling is subject to rules, and if we manage to formulate theserules as WM @Index{spelling rules }spelling rules working on apartially phonological representation, the correct spelling shouldcome out. Instead of c and g, the phonological representation contains@Index{special character}special characters reflecting the 'hard' and'soft' pronunciation, e.g. C and ç for c, and G and g for g, in caseswhere spelling alternation occurs.The characters C, ç, G and g should of course never appear on thesurface. We use the distinction between the lexical character set andthe surface character set to achieve this. Special characters are onlyincluded in the lexical character set and spelling rules musttransform them into surface characters. In this case, the spellingrules should do the following: @Verbatim  ˘ A C or G followed by e or i is changed into ch or gh   respectively. ˘ All other C's and G's are rewritten as c and g   respectively. ˘ A ç or g followed by e or i is changed into c or g   respectively. ˘ All other ç's and g's are rewritten as ci and gi   respectively.@End-Verbatim In order to trigger these rules, the lexical form of the differentclasses of regular stems should be entered as follows: amiC foramica, funG for fungo, spiagg for spiaggia, and baç for bacio.Exceptions of the types allergia, camicia, and amico can be handledstraightforwardly, by not using the special character in the lexicalform of their stem. The disadvantage of this strategy, thephonological strategy, is that regular cases require specialcharacters, whereas exceptions are represented in normal characters.If possible, we would like to alleviate the burden of the lexicographerand enhance the legibility of the dictionary by avoiding the use ofspecial characters in regular cases.The second strategy, therefore, is based on the premise that thealternations c/ch, ci/c, g/gh, and gi/g are regular. For this reason,lexemes that undergo these alternations should not be marked byspecial characters to trigger them. The alternations can be predictedfrom the way a stem is spelled, at least if morphological knowledgeis also taken into account. The regular generalizations can then beformulated as follows: @Verbatim  ˘ A noun of the a/e or o/i-class ending in -c or -g,   followed by a suffix -e or -i will have an -h-   inserted after the stem. ˘ A noun of the a/e or o/i-class ending in -ci or -gi,   followed by a suffix -e or -i will lose its final -i.@End-Verbatim Compared to the phonological strategy, special characters have beenreplaced by reference to morphological features. This has theadvantage of using information that is represented in the databaseanyway, instead of coding the same information in a different wayagain. In order to do so, WM spelling rules allow reference to featuresin addition to reference to strings.A further difference between the generalizations of the phonologicalapproach, and the ones formulated here, is that the former applyindependently of each other, whereas the latter have to be ordered towork properly. The insertion of h's must precede the deletion of i's,because otherwise the appropriate contexts for h- insertion cannotbe distinguished anymore. Therefore, WM spelling rules are ordered.For the exceptions, general spelling rules have to be blocked. Themost straightforward way to do so is by the use of specialcharacters. What has to be expressed in the cases of allergia,camicia, and amico can be rendered as follows:  @Verbatim ˘ A stressed i will always be realized as an i. ˘ A noun stem of the a/e-class ending in -ci or -gi   preceded by a vowel, followed by the suffix -e will   not be changed. ˘ The c of amico (and a few other nouns) will always be   realized as c, never as ch.@End-Verbatim The case for allergia is obvious. We need phonological information,not normally represented in the string, to formulate a generalexception to the rule. Here a special character, e.g. í, iswell-motivated, because it does not primarily convey the information'I am not affected by i- deletion', i.e. information exclusivelydependent on the description, but rather 'I am stressed', i.e. additionallinguistic information. Thus the stem of allergia will be allergí. Aspelling rule, to be ordered after i-deletion, has to rewrite the í to i.The case for special characters for the camicia-class is moresuspect. Representing the stem in its lexical form as camicí isill-motivated for two reasons. First, the i is not stressed, it onlyhappens to behave similarly to stressed i's as far as spelling rulesare concerned. Second, the class to which camicia belongs can bedescribed entirely in terms of surface string and morphologicalfeatures. This second observation can be put to use in the followingway. If we formulate a spelling rule changing the second i into í inthe contexts specified by string and feature conditions, for theduration of the activity of i-deletion, both lexical and surfacerepresentation will be camici. The unnatural representation camicíwill never be visible to the human users of the database, but onlysystem-internally, to block i-deletion.In the case of amico, the motivation to use a special character is of aquite different nature. In using e.g. C to block h-insertion, C does nothave any further meaning than 'I am exceptional'. However, sincethere is no way to characterize the class to which amico belongsother than by listing its members, we are forced to use a specialcharacter.There is a third possible strategy to use spelling rules for thealternations discussed here, besides the 'phonological approach' andthe 'general approach', as we will call the second strategy. Since itbrings the @Index{local spelling rules}spelling rules to a less general, more local level, we willcall it the 'local approach'. If this approach is pushed to its extremes,every spelling rule in the system is connected to a specific inflectionrule or a specific entry. The rules for general h-insertion andi-deletion will then be stated with the o/i and a/e-nouns separately.For stress-determined exceptions, there are two possibilities: eitherthey are marked by a special character í, and there are two rules forrewriting í, in the o/i and a/e-classes, respectively; or eachindividual case is covered by a spelling rule restoring the i after ithas been deleted. For the camicia-class, the simplest solution is arule only applying to a/e-nouns, and ordered before i-deletion tochange the final i into í. For the amico-class, h-insertion can beundone at an individual level.Obviously, in the above description, the local approach has beenpushed too far. Somewhere between the entirely general and theexclusively local approach, an optimal point has to be chosen. As abasic principle, general processes should be encoded in generalspelling rules, and exceptions to general processes at the level ofgeneralization where they apply. Therefore, h-insertion andi-deletion, which are not restricted to nouns but apply to verbs andadjectives as well, are typical examples of processes to be coveredby general spelling rules. Stress-determined exceptions are fullyindependent of the category of the word, and therefore they have tobe covered by a general rule as well. The camicia-class, however, isrestricted to a single inflection rule, and the amico-class consists ofentries that have to be listed individually anyway. In consequence,they should ideally be covered by inflection-class-specific andentry- specific local spelling rules, respectively.Sometimes, however, other considerations come into play to distortthis ideal order. Local spelling rules are meant to correct the effectsof general spelling rules. Therefore they are ordered after generalspelling rules. But for the camicia-class, the crucial rule has toprecede i-deletion, otherwise there is no i left to preserve. Theoriginal generalization can only be encoded according to the generalapproach. If it is to be a local spelling rule, the action it performs isi-reconstruc tion. This is dangerous because it does not encode theoriginal generalization, but encodes another one that can be renderedas follows: @ItemA noun stem of the a/e-class that after application of generalspelling rules ends in -c or -g preceded by a vowel, when followed bythe suffix -e, will be provided with an -i at the end.@End-Item Another type of consideration is relevant to the amico- class. Sincethe members of this class must be listed, the preferred option is toencode the exceptional behaviour in @Index{entry-specific spellingrules}entry-specific spelling rules. A disadvantage of this solutionmay be that only the linguist is able to write entry-specific spellingrules. If it turns out that the class has not been listed exhaustivelyby the @Index{linguist}linguist, the@Index{lexicographer}lexicographer has to ask the linguist to changethe database by specifying a new hard-coded entry with theexceptional spelling rule, each time he comes across a new lexemehaving this property.Depending on practical working conditions, it might be preferable tochoose an alternative that allows the lexicographer to add newinstances without the linguist's intervention. There are severalpossibilities. First, a new RIRule could be created where the onlydifference with the existing RIRule for the o/i-class would be thepresence of a rule-specific spelling rule. Thus the lexicographercould assign a new entry of the amico- class, e.g. medico ('doctor') tothis special RIRule, to produce the correct plural medici. The problemwith this solution is that linguistically the analysis can hardly bedefended. Secondly, the spelling rule can be made rule- specific,applying to all o/i-nouns and rewriting the special character C to cafter h-insertion has taken place with stems ending in c. In this case,the lexicographer would have to enter mediC. Finally, thelexicographer's interface could be adapted so as to permitlexicographers to write entry-specific spelling rules. Technically,this presents no problem, since an interface can in principle beequiped with access to any entity managed by the system. Theinterface can also help the lexicographer to specify the spelling rule,for instance by showing the forms that are input to the spellingrules, prompting for a corrected string, and inserting it in the rightposition.It is not our aim here to make definitive decisions on the besttreatment of these phenomena. Rather, we hope that our discussionhas shown what choices there are and what kind of arguments may beinvoked to make the choice. In the section below, we will assume thati-deletion, h- insertion, and stress-determined i-preservation aregeneral phenomena. For the camicia- and amico-classes, twoalternatives will be described so that we can show all types ofspelling rules.@SubSubSection{The Implementation}For the inclusion of the c/g-cases described above, the databasewhich has resulted from the regular cases has to be changed in tworespects: spelling rules have to be added, and the special charactersthey use have to be declared.We use í as a variant of i and it should be declared as such in the@Index{lexical character set window}lexical character set window.Up till this point, we used both character set windows only to listthe letters a…z in alphabetical order, each of them on a new line, asgenerated by default by the system. In fact, these windows allow twolevels of ordering. The @Index{character sort order}primary sortorder is the order of sets of characters separated by newlines. Untilnow all these sets consisted of a single character. By putting í on thesame line as i, it is defined as a variant, equivalent in terms ofalphabetical order. Between two variants a space has to be inserted.The order in which the two variants are entered within the line is thesecondary sort order. Only when two forms are entirely equal withrespect to the primary sort order is the secondary sort order invokedto decide which one comes first.18 The lexical character set windowwill now look like Fig. 3.7:                @Figure{ "Lexical character set with a special character." | "139" | 226 | 369 }There are two independent classifications of spelling rules. One isbased on the kind of process they apply to, inflection orwordformation. This influences the name of the spelling rule,@Index{ISRule}ISRule or @Index{WFSRule}WFSRule. As a consequence,if the same rule applies to both inflection and wordformation, it hasto be formulated twice. The other classification is based on thescope, general, rule- specific, or entry-specific (the latter two areboth subsumed under the term local). This influences the place wherespelling rules are stated. @Index{general spelling rules }Generalspelling rules are in the spelling rule window, @Index{local spellingrules}local spelling rules in their respective rule window (e.g. the RIRule they apply to,or the RIRule that applies to the entry they apply to).A general spelling rule consists of a name and a body. The name isarbitrary, the only condition being that every @Index{spelling rulename}name is unique. It is preferable to choose a mnemonic name, e.g.(ISRule h-insertion)The @Index{spelling rule body}body of a spelling rule consists of aseries of match- and-maps appearing on a new line and separatedfrom each other by a <tab>. Each@Index{match-and-map}match-and-map describes an element to bechanged or the context of this change. The element is determined by astring-match-and-map and/or a set of features. Elements that onlyrestrict the context of a change may be characterized by astring-match, by a feature set, or by a combination of both. Forelements that are changed, the string-match-and-map part is ofcourse obligatory. Here it is important to see the differentinterpretation by the system of <@Index{tab}tab> and<@Index{space}space>@Index{white-space character}. Whereas <tab>separates descriptions of different elements, <space> separates thestring and the feature characterization of the same element.The @Index{string-match-and-map}string-match-and-map is includedin double quotes. It consists of a match part and a map part. In thematch part, a set of strings is selected by a formula, the syntax ofwhich is fairly similar to the one of @Index{regular expressionoperators}regular expressions. The sign '|' is used as @Index{or(disjunction}@Index{disjunction (or)}or where the scope may beindicated by brackets. For single characters the disjunction may beabbreviated to a string of the alternative characters included insquare brackets. The question mark is used to indicate@Index{optionality}optionality. In the following examples theseoperators are used in expressions and the set of strings referred toby each expression is given.@Verbatim "London|Manchester" {London, Manchester}"(Man|Win|Chi)chester" {Manchester, Winchester, Chichester} "Rom[ae]"{Roma, Rome} "Milano?" {Milano, Milan} "(West-|East-)?Sussex"{West-Sussex, East-Sussex, Sussex} @End-Verbatim Reference to an(in principle) infinite set of strings is achieved by means ofwildcards, stars, and negation. They only have a meaning when thedomain is fixed in some way. The @Index{wildcard}wildcard, '.', canrefer to any single character declared in the lexical character set.The @Index{star}star, '*', refers to a sequence of zero, one, or moretimes the preceding character or bracketed expression. In normalpractice it is only used together with the wildcard, referring to asubstring of arbitrary length. @Index{not (negation)}@Index{negation(not)}Not is indicated by '^' as the first character in square brackets.Examples of these are given below:@Verbatim   "foo."                 All 4-letter words starting withfoo  "poly.*"               All words starting with poly  ".*ity"                All words ending in ity  "poly.*[^ity]"         All words starting with poly andnot                         ending in i, t, or y@End-Verbatim  @Verbatim  "poly.*[^i][^t][^y]"   All words starting with poly andnot                         ending in ity@End-Verbatim An additional possibility of negation is provided, where ^ has scopeover the whole string. An example of its use is: @Verbatim  ^".*ity"               All words not ending in ity @End-VerbatimIn order to select all formatives ending in c or g, followed by aformative e or i, we need a formula like the following:@Verbatim ".*[cg]" »   "[ei]"@End-Verbatim Features can be used to restrict the domain of the first formative tonoun stems of the a/e or o/i-classes, and of the second one to pluralsuffixes. In describing the feature set, a slightly different subset ofregular operations is available, viz. and, or, and not. @Index{and(conjunction)}@Index{conjunction (and)}And is expressed by simplejuxtaposition, e.g. (cat noun)(ICat stem) selects all noun stems. Anabbreviation is possible if the attributes are the same, e.g. (ICatstem.a/e) selects a/e-stems. @Index{or(disjunction)}@Index{disjuncition (or)}Or is expressed by '|', e.g. (ICatstem.a/e)|(ICat stem.o/i) selects a/e and o/i-stems. @Index{not(negation)}@Index{negation (not)}Not is expressed by '^', e.g. (ICat stem)^(ICat e/i) selectsall stems except the ones of the e/i-class.We have chosen not to use brackets to delimit the scope of thevarious operators on features. Since brackets are already in use inthe representation of simple features, easy readability of featureexpressions would be jeopardized. Instead, a strict hierarchy ofpriorities between the operators has been imposed. The hierarchy hasbeen chosen such, that everything can be expressed and what occursmore frequently is expressed more naturally. The |-operator hasglobal scope, i.e. the lowest priority. Thus, in order to refer to nounstems of the a/e or the o/i-class, we have to use the followingformula:@Verbatim (cat noun)(ICat stem.a/e)|(cat noun)(ICat stem.o/i)@End-Verbatim At first sight, this may seem uneconomical, because if | were chosento have higher priority than and, we could have written the following:@Verbatim (cat noun)(ICat stem.a/e)|(ICat stem.o/i)@End-Verbatim However, in that case it would not be possible to refer to those nounstems as well as to e.g. verb stems of the first conjugation (verbs in-are) in a single formula. Now we can do so in the following way:@Verbatim (cat noun)(ICat stem.a/e)|(cat noun)(ICat stem.o/i)|(catverb)(ICat first-conjugation)@End-Verbatim The ^-operator has intermediate priority between and and |. Thus, theformula@Verbatim (gender masculine)(ICat stem)^(ICat e/i)@End-Verbatim selects the masculine stems not belonging to the e/i- class. The^-operator always excludes part of a set that has been definedexplicitly before. Therefore, in order to refer to all categories exceptnouns, one cannot use the formula ^(cat noun). Instead, one has to usea disjunction (cat verb)|(cat adjective)|(cat… . Furthermore, anegation cannot be embedded in another negation. In the formula@Verbatim (cat noun)^(gender masculine)^(ICat suffix)@End-Verbatim the negations are coordinated, referring to nominal items that areneither masculine nor a suffix.The example string-match we ended up with above can besupplemented with features in the following way, to select theenvironment of h-insertion:@Verbatim ".*[cg]" (cat noun)(ICat stem.a/e)|(cat noun)(ICatstem.o/i)»   "[ei]" (ICat suffix)(number plural)@End-Verbatim The mapping part of the @Index{match-and-map}match-and map is thepart of the string after the special character '/'. At least one of thematch-and-maps in a spelling rule should contain a mapping part,otherwise the rule would not change anything. It consists ofconstants, i.e. surface characters that are taken literally, andreferences to parts of the original string. In order to refer to parts ofthe original string, brackets are used to segment the string match.Any substring of the string match included in brackets is a segment.Segments are numbered from 1 upwards, and they can be accessed inthe mapping part by \1, \2, etc. Thus h-insertion is performed by thestring map "(.*[cg])/\1h". For i-deletion, we need a string-match-and-map like "(.*[cg])i/\1", with appropriate feature andsuffix specifications. Since the i in the formula is not referred to inthe map-part of the formula, it need not be included in brackets. Thefunction of segmenting the string-match is attributed to brackets inaddition to their scope-delimiting function. Since embedded bracketsare not allowed, we sometimes end up with more segment divisionsthan are actually used in the mapping part, as in the followingexample, changing some English country names into their Frenchcounterparts: @Verbatim  "(Austr|Som)(ali)a/\1\2e"     {Australia, Somalia} ﬁ                                {Australie, Somalie}@End-Verbatim If we take the formulation of the general rules from section 1.2.2 andtranslate it in WM syntax literally, we get the following:@Verbatim "(.*[cg])/\1h" (cat noun)(ICat stem.a/e)|(cat noun)(ICatstem.o/i) »   "[ei]" (ICat suffix)"(.*[cg])i/\1" (cat noun)(ICat stem.a/e)|(cat noun)(ICatstem.o/i)) »   "[ei]" (ICat suffix)@End-Verbatim These formulae contain various redundancies. A first redundancy isthat the suffix is indicated by a string as well as by a feature set,whereas one of them is enough: either "[ei]" or (number plural). Sinceit is not the plural as such but the particular string of the suffix thatcauses the spelling change, the characterization by means of a stringis to be preferred linguistically. From the point of view ofperformance, the characterization by means of a feature is preferablebecause feature restrictions can be checked more efficiently thanstring match restrictions.The organizationally most important way to reduce redundancy is bycreating a @Index{spelling rule group}spelling rule group. A spellingrule group consists of a list of spelling rules preceded by a set offeatures that apply to all formative selecting formulae in the rules.The spelling rules are indented to indicate that they belong to thegroup. The features can only be those that are used to qualifyinflection units. The set of features must distinguish the group fromall other spelling rule groups. In our example (cat noun) could befactored out in this way, to produce the following spelling rule group:@Verbatim (cat noun)»  (ISRule h-insertion)»  "(.*[cg])/\1h" (ICat stem.a/e)|(ICat stem.o/i)»"[ei]"»  (ISRule i-deletion)»  "(.*[cg])i/\1" (ICat stem.a/e)|(ICat stem.o/i)»"[ei]"@End-Verbatim For stress-determined exceptions, the following rule has to bewritten to rewrite the special character at the end, without anycontextual restriction.@Verbatim (ISRule stressed-i-conversion)"(.*)í(.*)/\1i\2"@End-Verbatim Note that the character í is not allowed inside a rule name because itis not an @Index{alphabetic character}alphabetic character. Contraryto the string representation, a rule name may only contain alphabeticcharacters, i.e. letters, digits, and some special characters like '-'(cf. section 2.2 of Chapter 2).If the rule for camicia is grouped together with the general rules,after a similar reduction of redundancy, it will have the followingform:@Verbatim »  (ISRule i-preservation)»  "(.*[aeiou][cg])i/\1í" (ICat stem.a/e) »   "e"@End-Verbatim The "e" at the end of the formula could be left out without anyconsequences for the output in this case. The spelling rule windowwill now look like Fig. 3.8:                @Figure{ "Spelling rule window." | "140" | 399 | 180 }@Index{spelling rule window}@Index{local spelling rules}Local spelling rules are stated in theRIRule window where they apply, instead of in the spelling rulewindow. @Index{rule-specific spelling rules}Rule-specific spellingrules are entered in the rule specification, @Index{entry-specificspelling rules }Entry-specific spelling rules in the entryspecification. Both are introduced by the keyword ISRules. It isfollowed by spelling rule bodies which are without an explicit name.If there is more than one local spelling rule in the same RIRule orentry, each spelling rule body starts on a new line. The syntax ofspelling rule bodies is the same as for general spelling rules.@Index{spelling rule name}Names for local spelling rules are providedby the system itself during compilation.In the RIRule specification, the ISRules constitute an optional sectionbetween the wordforms and the entry specifications. If thecamicia-class is treated by a rule- specific ISRule, the ISRulessection of the RIRule for a/e-nouns will be the following:@Verbatim ISRules"(.*[aeiou][cg])/\1i" »   "e"@End-Verbatim This i-reconstruction rule crucially relies on the assumption thatevery a/e-noun stem ending in vowel-c/g originally not followed by ihas been changed by a general spelling rule inserting an h at its end.If for amico and similar nouns a solution is chosen where they aretreated in a separate RIRule, the RIRule window will look like Fig.3.9:                        @Figure{ "RIRule with specific ISRule." | "141" | 348 | 215 }@Index{RIRule window} @Index{rule-specific spelling rule}If it is solved by @Index{entry-specific spellingrules}entry-specific spelling rules, the entry for amico can bespecified as follows:@Verbatim entry»   "amic" "amic"»   ISRules»   "(amic)h/\1"@End-Verbatim The explicit string specification in the ISRule is not absolutelynecessary, but since we know that other cases will (should) notarise, it is clearer from the human reader's point of view to state therule in this way.Before compiling the database, stems should be entered so that everyspelling rule is used at least once. In entering the stems that thespelling rules apply to in the RIRule windows, all possible surfaceforms should be listed. In the examples of the simple cases, e.g.strad, there is only one surface form identical to the lexical form.For a stem containing a special character, e.g. allergí, the lexical andsurface forms are different. For a stem like fung, there are twosurface forms that are both listed. Thus, the @Index{entry}entriesfor allergia, fungo, and bacio will look like the following:@Verbatim entry»   "allergí" "allergi"entry»   "fung" "fung" "fungh"entry»   "baci" "baci" "bac"@End-Verbatim The order of the surface forms does not have any significance. Duringcompilation, it is checked whether each form that is generated by therules corresponds to a possible form declared in the entry. Aftercompilation, the same browsing facilities are available as illustratedfor strada in section 1.1.3. An interesting option in this context isthe possibility one has to inspect in which way the spelling rulesmodify formatives to produce a wordform. In Fig. 3.10, it isillustrated how this process can be traced for amici. It can be seenhow the ISRule h-insertion adds an h which is deleted again by anentry specific spelling rule, for which the system has generated aname.                 @Figure{ "Lexeme browser tracing spelling rules." | "155" | 415 | 391 }@Index{lexeme browser}@Index{spelling rules}@Section{Dutch Verbs}In this section, a fragment of Dutch verbal morphology is presented,and it is shown how the WM-mechanism as it has been presented inthe previous section can handle it with very few extensions.The section is divided in three parts. The first subsection presentssome regular weak verbs. Although the data as such do not presentnew problems, the amount of data raises some organizationalquestions. The solutions provided here can be applied to much moreinflecting languages (e.g. French, Italian) without any conceptualmodification. The second subsection presents some more difficultspelling strategies. One of them involves consonant-doubling, theother one requires two equivalent output strings to be generated. Forthe latter we extend the mechanism slightly. The last subsectionintroduces verbs with stem vowel changes and other irregularities,and presents several alternative strategies to handle them.As a source for the Dutch data, we used van Sterkenburg & Pijnenburg(1984), especially the table of irregular verbs, as well as one of theauthors's native intuition.@SubSection{Weak Verbs}@SubSubSection{The Data}Although Dutch verbs have considerably fewer different forms thanverbs in Romance languages, they have enough forms to warrant adescription in paradigms, unlike English or Scandinavian verbs. Thefollowing table gives verb forms of vergen ('require') and ontmoeten('meet'), and their syntactic meaning:@Verbatim    verg        ontmoet        1st or 2nd person  singularpresent                        indicative  or  imperativesingular   verg-t      ontmoet        2nd or 3rd person  singularpresent                        indicative  or  imperativeplural   verg-en    ontmoet-en    plural present indicative  orinfinitive  verg-de    ontmoet-te    singular past indicative  verg-den   ontmoet-ten   plural past indicative  verg-end   ontmoet-end   present participle  verg-ende  ontmoet-ende  present participle  ge-verg-d  ontmoet       past participle@End-Verbatim The alternation between the two forms of the present participle isessentially free, although considerations of euphony have someinfluence. For the 2nd person singular present indicative, however,distribution of the two competing forms is strictly rule-governed. Ifthe subject precedes the verb, the form with the t-ending is taken, ifsubject and verb are inverted, the other one is taken.For stems ending in -t, two t's are reduced to a single one in thepresent indicative, imperative, and past participle, but not in thepast indicative. For stems in -d, -dt is maintained in the presentindicative and imperative, e.g. brandt from branden ('burn'), and -dd-in the past indicative, e.g. brandde. In the past participle, however,there is only one d, e.g. gebrand.In the past indicative and past participle, the choice between t and dis dependent on the last phoneme of the stem. If it is voiceless, i.e. ifthe stem ends in p, t, k, f, s, ch, or x, the ending starts with t,otherwise it starts with d.In the past participle, there is a morpheme ge- which can be realizedas a prefix, an infix, or not at all. The choice between the threedepends essentially on the morphological structure of the verb. Asimple verb has ge- as a prefix. Verbs that consist of a stem and aprefix, even if the structure can only be traced etymologically, haveone of the other realizations. If the elements are linked very closely,no prefix occurs. Often, the structure is not recognized as suchcontemporarily, e.g. ont-moeten, does not have a counterpart *moetenin the relevant sense (but cf. English meet). The infix realizationoccurs with verbs having a detachable prefix, e.g. uitwerken ('workout') has uit-ge-werk-t. These verbs have been formed bywordformation rules and will not be treated here.19For semantic reasons, some verbs have fewer forms than the oneslisted above. Weather verbs, e.g. dooien ('thaw'), lack first and secondperson forms, and imperative.@SubSubSection{The Treatment}The main difference with what we have seen so far is the number offorms and meanings we have to deal with. Nouns have only oneinflectional category, so that the organization of the@Index{paradigm}paradigm is trivial. Dutch verbs are specified for thefollowing @Index{inflectional categories}inflectional categories: @Verbatim  mode:          indicative, imperative, infinitive, participle  tense:         present, past  number:        singular, plural  person:        first, second, third@End-Verbatim In grouping together forms of the paradigm, two perspectives areimportant. On the one hand, forms can be grouped together ingeneration, i.e. a single formula in a RIRule window can result inseveral forms of the paradigm, if it matches more than one affix inthe corresponding fully specified IFormative window. On the otherhand, paradigmatic forms are listed in a particular order whenaccessed via the interface. In principle, these two perspectives areindependent.In listing and grouping the forms, a compromise between formalsimilarity (formal grouping) and similarity in meaning (logicalgrouping) of the forms must be adopted. In traditional descriptivegrammars, inflectional categories are usually hierarchically orderedin the same way as they are listed above. All indicative formsprecede forms of other modes and within the indicative, presentprecedes past etc.. In a tabular arrangement, two categories can betaken at the same time, e.g. mode vertically and tense horizontally. InWM, the fact that the order accessed via the interface does notdepend on the formulae generating the forms, yields a lot of freedomin formulating the formulae. One has to choose a position somewherebetween only concentrating on formal similarity and disregardingformal similarity altogether. With respect to the Dutch verbalparadigms above, an example of extreme formal grouping would be togroup together plural present indicative, infinitive, and presentparticiple, the former two being identical in form, and the latterderivable by adding d or de. An example of extreme logical grouping isgrouping together past and present participle, although their formsare not related.An important point to be kept in mind is that in the representation ofthe forms above, some implicit grouping is already there. Thus, theplural of the present and the whole past of the indicative have notbeen specified for person, because there is no difference in form.This kind of '@Index{syncretism}syncretism' is a commonphenomenon, occurring even in highly inflected languages such asItalian (singular subjunctive) and Portuguese (2nd and 3rd personplural throughout the paradigm). In WM, syncretism may berepresented as underspecification or the specification may be spelledout in the formulae and formatives.Formulae in RIRule windows allow specification by features as wellas by form (represented as a value of ICat). Still, it is rathercomplicated to implement in WM either of the two extremesmentioned above. The derivation of the present participle from theinfinitive (e.g. vergend from vergen) is difficult because the modefeature of vergen will clash with the mode of the participial suffix.Deriving both participles by a single formula is difficult because onehas the prefix and the other one does not. Although these problemsare not insurmountable, we will not pursue these approaches herebecause the problems encountered in doing so needlessly complicatethe treatment.In order to reflect the traditional treatment of paradigms,inflectional categories have to be divided into two groups. One ofthem includes the features organizing the tables of a traditionalgrammar, usually mode and tense. In WM, they are represented in theformulae generating the wordforms. The other group includes thefeatures differentiating the forms within a cell of the table, usuallyperson and number. In WM, they are only represented in thespecification of the suffixes, which pass them on to the wordformsgenerated by the formulae.WM also offers the possibility of entirely separating the formulaethat generate wordforms from the grouping of paradigms. A section@Index{paradigm section}paradigms can optionally be included in theRIRule window between the sections for wordforms and entries. Inthe paradigms section, feature specifications are listed. They grouptogether the forms sharing these features, among the ones generatedalready by formulae of the wordforms section.If all the grouping of forms is left to the paradigm section, theformulae in the wordforms section can be reduced considerably. Inthe case of ontmoeten, the only specification required to generate thewordforms is the following: @ItemTake the stem and put a suffix after it.@End-Item For the vergen-type of verbs, this is not enough, because there is asuffix, the past participle -d, that does not produce a wordform whenfollowing the stem, unless the stem is preceded by the prefix ge-.Therefore, we need two statements: @ItemTake the stem, and put a suffix, not being the past   participle suffix, after it.@End-Item @ItemTake the stem, put the prefix in front of it, and the   past participle suffix after it.@End-Item The negation in the first statement cannot be expressed directly inthe formula. We have chosen not to implement @Index{negation(not)}@Index{not (negation)}negation here in order to avoidinterpretation problems and ambiguity. Therefore, there are two waysof formulating the statements in the WM-formalism. Either a seriesof positive statements replaces the negative one, or an extra featureis introduced. In the former case, the traditional paradigm treatmentas described above will emerge. In the latter case, the new feature,meaning "I am not a past participle formative", is assigned to allsuffixes except the past participle suffix in the IFormative window,and used in the formula generating wordforms in the RIRule window.The paradigm of the Dutch verb as presented above contains twocases of @Index{alternation in paradigm}alternation of forms, whichare different in an essential respect, however. The two forms of thepresent participle are in free variation, whereas the two forms of the2nd person singular present indicative are in complementarydistribution. For the present participle, WM will generate twoequivalent forms, either by two RIRule formulae or by a RIRuleformula matching two affixes listed in the fully specifiedIFormative. For the 2nd person singular present indicative, thedistributional difference has to be encoded in a feature. Since it isinformation that is externally relevant and not confined to theorganization of the database, we should avoid coding it as values ofICat. Rather, a new feature, e.g. inversion (yes/no), has to be appealedto. In the same way that most forms are unspecified for person, allbut the 2nd person singular present will be unspecified for inversion.The reduction of double t to single t in certain forms of the paradigmis typically within the domain of @Index{general spellingrules}general spelling rules. As can be seen in the paradigm ofontmoeten above, the rule is restricted to stems ending in t andendings consisting of only t. The reduction of double d to single d isrestricted to the past participle and can be handled in a similar way.The choice between t and d in the endings of the past indicative andpast participles is less typically within the domain of spelling rules.Rather than an instance of spelling strategy, it is a genuinedifference, also reflected in pronunciation. Still, being predictablefrom spelling, a spelling rule treatment of the alternation ispossible. The alternative, creating different RIRules, is lessattractive because it results in redundancy. Since it is easier todelimit the contexts where t occurs, adopting d as the basis is thebest approach. The forms of the paradigm where the alternation playsa role can be characterized collectively by (tense past), and thestems by those ending in p, t, k, f, s, ch, or x.The different realization of ge- in the past participle cannot beaccounted for by spelling rules. Minimal pairs occur such as thefollowing:@Verbatim   Infinitive     Past Participle  bedelen        gebedeld       ('beg')  bedelen        bedeeld20       ('endow')@End-Verbatim Although the two infinitives differ in stress, the reason for thedifference in past participle is rather the morphological structure.Therefore, the best solution in this case is to create two RIRules. Thetwo windows will be the same except for the name and the formulagenerating the past participle.For the @Index{deletion}deletion of certain specific forms, as isrequired for the verb dooien ('thaw'), a special clause is added to theentry, specifying which forms do not occur. This specification can bedone by features, with the same possibilities for conjunction,disjunction, and negation as in matching constraints of spellingrules.21@SubSubSection{The Implementation}A new language will in general give rise to a new database. In theory,however, WM does not require this. It allows the splitting of the treeinto branches for different languages. Other components, such as thecharacter sets and spelling rules, cannot be separated so drastically,but of course a feature like (language Italian) can be created forspelling rule groups. In order to exclude any interaction, however, wewill assume here that a new database is created for Dutch.To begin with, the character sets are defined as usual, i.e. as theywere originally initialized.Then we start structuring the inflection window. For the data wehave seen so far, there is no reason to have more than a singleinflection unit (cat verb). Because we decided to create two RIRulesfor the different realizations of ge-, we will create two nodes(RIRule ge- prefix) and (RIRule no-ge). For the declaration of theformatives we will create three nodes (ICat stem), (ICat prefix), and(ICat suffix).The @Index{formative window}formative windows, in Fig. 3.11 -3.13, do not contain anything unfamiliar to those who have readsection 1 of this chapter. Note that they anticipate spelling rules insome cases. As a value for person, 1 is illegal, because a value mustbe a @Index{WM-symbol}WM-symbol, and numbers are notWM-symbols (cf. section 2.2 of chapter 2). Therefore first has beenchosen.22                @Figure{ "The window (ICat stem)." | "142" | 342 | 86 }                @Figure{ "The window (ICat prefix)." | "143" | 343 | 87 }                @Figure{ "The window (ICat suffix)." | "144" | 395 | 183 }The traditional citation form for Dutch verbs is the infinitive, whichwe will adopt in this example as well. For the wordforms section ofthe RIRule windows, two different strategies have been presentedabove. In an approach where the grouping of forms is left to thewordforms section, Fig. 3.14 represents the RIRule window for verbslike ontmoeten.                @Figure{ "RIRule window with paradigms determined by wordformssection." | "146" | 365 | 221 }@Index{RIRule window}If a @Index{paradigm section }paradigm section is included, theordering implicitly given by the wordforms formulae is disregardedcompletely. Thus, it would be wrong to add the following paradigmsection to the window represented in Fig. 3.14:@Verbatim paradigms(mode participle)@End-Verbatim In this way, the participles will be grouped together in one paradigm,but the other wordforms will not belong to any paradigm.23Therefore, a better solution is the following paradigm section:@Verbatim paradigms(mode ind)(tense pres)(mode ind)(tense past)(mode participle)(mode imperative)(mode infinitive)@End-Verbatim Obviously, this paradigms section repeats most informationcontained in the wordforms section so that, without loss ofinformation, the following, more economic wordforms section canreplace the one in Fig. 3.11:@Verbatim wordforms(ICat stem) »   (ICat suffix)@End-Verbatim For verbs having a ge-prefix in the past participle, this strategy canonly be pursued at the cost of introducing a new feature. Thus, in Fig.3.15, the feature (ICat non- papa) has been used to refer to allnon-past-participle suffixes. It must be added to them in the windowrepresented in Fig. 3.13.                @Figure{ "RIRule window with paradigms section." | "147" | 382 | 258 }@Index{RIRule window} In order to observe some of the effects of spelling rules that we willimplement, the following entries have been entered: ontmoet ('meet'),verg ('require'), werk ('work', past tense werkte), brand ('burn', pastparticiple gebrand).Three @Index{spelling rules}spelling rules have to be added, tworeducing double t and double d, and one changing past tense d to t. Allthree are restricted to verbs, referring explicitly to certain forms ofthe verbal paradigm, but general enough not to be linked to a specificRIRule. They can be grouped together in a spelling rule group with (catverb) as its heading. The first and second ones are straightforward:@Verbatim ".*t" (ICat stem) »   "t/" (ICat suffix)".*d" (ICat stem) »   "d/" (mode participle)(tense past)@End-Verbatim The third one is slightly more complicated. For the stem, the squarebracket notation is inappropriate because ch cannot be taken intoaccount. Apart from the non- abbreviating notation (p|t|k|f|s|ch|x) anotation such as ([ptkfsx]|ch) is possible. The ending has to be split upinto a d that is changed to t and the rest, i.e. e, en or nothing, that isnot affected. In order to prevent unexpected side effects, it is betterto characterize the strings as tightly as possible. Therefore, we willalso use the feature (tense past), and thus end up with the following:@Verbatim ".*([ptkfsx]|ch)" (ICat stem) »   "d(en|e)?/t\1" (tense past)24@End-Verbatim This rule should be ordered before double-t-reduction, otherwise thepast participle will not be caught by the latter.Finally, the @Index{deletion}deletion of specific forms for an entry isperformed by an extra clause in the entry specification. The entry fordooien, where first and second person forms do not exist will bespecified as follows:@Verbatim entry»   "dooi" "dooi"»   deleted-forms »   (person first)|(personsecond)|(mode  imperative)@End-Verbatim @SubSection{Vowel Length and Spelling Variants}@SubSubSection{The Data}Two properties of Dutch spelling that are very pervasive, yet ratherconfusing to the outsider, are the spelling strategy for long and shortvowels, and the non-strategy for the spelling of c and q in loanwords.Some vowels in Dutch, e.g. e, have two distinctive values, one of themshort and open (cf. English let), the other one longer and more closed(cf. English late). Within the same paradigm, vowel length does notchange. The spelling, however, does not suggest so: @Verbatim  leeg           legen25         ('empty')  leg            leggen         ('put in horizontal position')@End-Verbatim In a closed syllable, where the vowel is followed by two or moreconsonants or by a consonant and a word boundary, e is pronounced asa short vowel. In open syllables where the following consonant can bethought of as belonging to the next syllable (e.g. le-gen), e ispronounced as a long vowel. In order to achieve the opposite valuesfor the vowels, two strategies are used. In closed syllables, a long eis spelled as ee. An open syllable that should contain a short e isclosed by doubling the following consonant, thus changing thesyllabification (e.g. leg- gen).These spelling strategies are not confined to e nor to verbs. Thefollowing examples illustrate the phenomenon for nouns andadjectives with a, o, and u: @Verbatim  oog            ogen           ('eye')  vlag           vlaggen        ('flag')  vaag           vager          ('vague')  druk           drukker        ('busy')@End-Verbatim For i, the long variant is always spelled ie, but the short vowel stillcauses consonant doubling:@Verbatim   vier           vieren         ('celebrate')  zit            zitten         ('sit')@End-Verbatim There is also an unstressed variant of e, called schwa (cf. the firstvowel of America) that never causes any spelling change, e.g. thesecond e in the following example:  @Verbatim regel          regelen        ('settle')@End-Verbatim Although syllabification can be changed (reanalyzed) for affixes, it isalways maintained in compounds. The syllable boundary in a compoundcoincides with the boundary between the elements. Thus, oog+enbecomes o- gen, but oog+aandoening ('eye disease') remains oog-aandoening rather than becoming *o-gaandoening.In the spelling of foreign words containing c or q, it is more theabsence of a strategy that complicates the spelling. When c ispronounced k, it is sometimes written as k, and similarly for qu andkw. The official legislation dates back from 1947. It consists of alist of words, many of which have been assigned two spellings, a'preferred' one and an 'admitted' one. Consequently, for many words,two alternative spellings exist throughout the paradigm, e.g.:  @Verbatim controleren  or               kontroleren  ('check')  quantificeren  or             kwantificeren('quantify')@End-Verbatim There is a difference between c/k and qu/kw-alternation, in thesense that only some of the c's and k's are affected, but virtually allqu's. The last example above shows a c which is always retained, atleast in the official orthography. A case of irregular alternation of quis the following:@Verbatim   confisqueren or               konfiskeren('confiscate')@End-Verbatim This example brings us to the subject of consistency. At variouslevels, consistency issues come up. First of all, inside a word wheretwo c's and/or qu's occur. Only if the two instances are treated alike,the spelling is correct, e.g. @Verbatim  concurreren            consequent  *conkurreren           *consekwent  *koncurreren           *konsequent  konkurreren            konsekwent  ('compete')            ('consistent')@End-Verbatim Besides these blatant violations of consistency, there is a sense ofconsistency that prohibits, or at least strongly prefers avoiding,combinations of alternative spellings of one word in the same text,especially if they are close to each other. Even between differentwords a certain dependency holds. Most people would consider itstrange to find quartet and kontroleren close to each other, sinceboth are in a non-preferred spelling, but diverge from it in differentdirections.@SubSubSection{The Treatment}Both vowel length indication and spelling variants as discussed aboveare typical issues to be treated by @Index{general spellingrules}general spelling rules. They do not have any effect on speechand they are not sensitive to any morphological or syntactic propertyof the word in question.As to the representation of vowels, three classes of occurrences canbe distinguished: the ones that exhibit @Index{vowel doubling}voweldoubling in closed syllables, the ones that exhibit @Index{consonantdoubling}consonant doubling in otherwise open syllables, and the onesthat remain unchanged. Most occurrences belong to the last class, viz.vowels that are not in the last syllable of the stem (e.g. the first e inregelen), vowels followed by two or more consonants of the stem (e.g.werken), trigraphs and digraphs containing different vowels (e.g.ontmoeten), and schwa (e.g. the second e in regelen). The best way tobegin, then, is by representing the vowels of this class in the normalway, and by using spelling rules to treat the other classes.A safe, but rather inelegant solution is the introduction of ninespecial characters, e.g. a, h, w, and u for the long vowels, and A, E, I,O, and U for the short ones. The unmarked option is that they arerewritten as single characters, resulting in nine rules of the type abecomes a, and A becomes a. The marked option occurs when the stemthey are in is followed by a suffix starting with e. In that case, fourrules will rewrite the long vowels as double vowels, e.g. a becomesaa, and five rules will take care of doubling the consonant after shortvowels. This solution is inelegant because special characters areused where the context of the change can be described in terms ofsurface characters as well. Therefore, the same effect may berealized without the special characters. Only for e is there adifference between stressed and unstressed that cannot be observedin the string and warrants a special character.The most natural representation is to write the long vowels as doublevowels, e.g. aa, and to prevent the doubling of consonants followingshort vowels, e.g. leg rather than legg. For long vowels, aa will bereduced to a, and similarly for ee, oo, and uu, when they are followedby a single consonant of the stem and a suffix starting with e. Thesingle consonant condition is necessary to retain the double vowel ine.g. haast/haasten ('hurry'), and maai/maaien ('mow').For short vowels the situation is slightly more complicated. Insteadof knowing whether the vowel brings about consonant doubling, as wedid in the first approach, we have to check it. In order to avoid an u indigraphs such as au, ui, or uu, being recognized incorrectly as a shortvowel, the last three letters of the string should be specified as aconsonant, a vowel, and a consonant, where x counts as twoconsonants (cf. box/boxen ('box')). Since the only action performed bythe rule does not affect the vowel, there is no need to write separaterules for the individual vowels. In order to avoid the repeated use oflong disjunctions of characters to represent the concepts ofconsonant and vowel, WM allows their specification as a@Index{character subsets}subset of the lexical character set, with aname that can be referred to by spelling rules. Only for the schwashould a special rule be written. As noted above, this is a typicalcase to be treated by a special character, e.g. E26. One spelling rule isneeded to rewrite E to e at the end.In conclusion, we have the choice between a solution which involvesheavy use of special characters and one where their use is reduced toa minimum. In the former approach, we need nine special charactersand eighteen spelling rules. In the latter we need only one specialcharacter and six spelling rules. The latter approach is thus muchmore elegant, but more attention should be paid to the interaction ofrules and their precise formulation. This solution will be elaboratedin the next subsection.The spelling rules under consideration here are typical candidates fordoubling, in the sense that they apply to wordformation as well as toinflection. However, since they do not apply to compounding, thecorresponding WFSRules will have to restrict their scope by a featurewhich mentions the derivational character of the process.The simplest solution to the @Index{spelling alternations}alternativespelling c/k and qu/kw alternation problem is to consider thevariants as different words, each having their own entry. However,such an approach disregards the complete equality of the twovariants in all linguistic respects: phonology, inflection,wordformation, syntactic distribution, and meaning. In publisheddictionaries, the non-preferred variant has an entry only consistingof a reference to the other spelling.Clearly, the problem should be solved by spelling rules, but themachinery presented up till now is inadequate. What we need is twooutputs of the spelling rule component from a single input string,whereas every spelling rule that can be formulated with what hasbeen described yields a single output for each input string. However,in special cases, the behaviour of any spelling rule can be changed inthis respect by adding the keyword @Index{value}value at the end. Aspelling rule containing value, instead of overwriting its input, willcopy it and change only the copy. Both the input and the output areavailable for further rule applications. Thus, the output of a spellingrule containing value is a set of strings, rather than a single string.As mentioned above, c/k and qu/kw alternations are different in thatonly some of the c's and k's are affected, but almost all qu's.Therefore, a special character C will be used for the c/k-alternationcases, whereas for qu the default option is to treat only cases ofnon-alternation or irregular alternation in a special way (e.g.confisqueren vs. konfiskeren). For the rewriting of C, we need twospelling rules, one changing it to c in all contexts, and one changing itto k in all contexts, and the first rule should be followed by value. Forqu, we need a single spelling rule changing it to kw and at the sametime maintaining qu in a copy, by means of value.Most of the @Index{consistency}consistency issues fall outside theWM- domain. Only when more than one alternation is to apply to thesame word can consistency conditions be expressed in WM. An idealsolution would be to mark every wordform containing one or more Cor qu with two alternative symbols, e.g. #L and #N, for 'learned' and'native' spelling. These special characters would be added to the endof the string by two spelling rules, the first having value, producinge.g. ConCurreren#L and ConCurreren#N. Subsequent spelling ruleswould then rewrite all C's and qu's as c and qu when followed by #L,and as k and kw when followed by #N, and would delete the specialcharacters #L and #N afterwards. An elegant implementation of thisidea presupposes a @Index{recursive application of spellingrules}recursive application of spelling rules, one of which wouldmean 'if the string ends in #L, rewrite the first C to c, and apply thisrule again to the rest of the string, until the rest does not contain C'sanymore'. In WM, strictly sequential application of spelling rules hasbeen chosen, and recursion such as discussed above is not possible.This enhances intelligibility of the interactions of spelling rulesbecause it is easy to visualize the string after each spelling ruleapplication, but requires a less elegant solution in the rare cases likethe one at issue here.We have two possibilities for these consistency cases in WM: eitherto write a general spelling rule for each combination, or to leave thetask of rewriting the strings to entry-specific spelling rules. Forrelatively frequent combinations, the former solution can beenvisaged, otherwise the latter solution can be taken. Probably, allcombinations, except perhaps two C's, are rare enough to warrant anindividual spelling rule. The same solution can be used forconfisqueren / konfiskeren. Whichever solution is chosen, the generalrules have to be restricted such that they only apply to wordformswhere a single C or qu occurs.@SubSubSection{The Implementation}With respect to the database described in section 2.1, it is mainly thespelling rule window that needs extension. Special characters andcharacter subsets that are used have to be defined in the lexicalcharacter set window, and relevant entries in the inflection window.The rules for double vowel reduction are quite straightforward. Foreach double vowel a rule of the following type has to be written:@Verbatim "(.*)aa([bcdfgklmnpqrstvwz])/\1a\2" (ICat stem) »   "e.*"(ICat suffix)@End-Verbatim The list of consonants following aa cannot be replaced by a wildcard,because of the exceptions, e.g. maai - maaien ('mow'). There will be afair number of spelling rules referring to all consonants. The aboverepresentation is not very practical, for several reasons. It makes therule hard to read, and it is easy to make mistakes in its specification.Furthermore, if other spelling rules require special characters asvariants of a consonant, these special characters must be added tothe list individually in each disjunction.Therefore, WM offers the possibility of defining named@Index{character subsets}character subsets. This feature of WM issimilar to the corresponding feature of @Index{two-levelmorphology}two-level morphology, but WM allows mnemonic namesinstead of just single characters.27 In the lexical character setwindow, a special section character-subsets can be added at the endof the window. Each line contains a subset definition, which for theconsonants in rules like the above can look like the following:@Verbatim character-subsetsCons »   {bcdfgklmnpqrstvwz}@End-Verbatim If the name is referred to in a spelling rule, it is always enclosed incurly brackets. Thus, the spelling rule for double a reduction can bereformulated as follows:@Verbatim "(.*)aa({Cons})/\1a\2" (ICat stem) » "e.*" (ICat suffix)@End-Verbatim For short vowels, only one rule is needed. In the rule, the last threecharacters of the stem should be specified as a consonant, a vowel,and a consonant. The first of the two consonants may also be h, as inhak - hakken ('chop'), or j, as in jen - jennen ('badger'). In order torender this, we could define a new character subset, e.g. Cons+hj, butsince we have already defined Cons, it is also possible to use thestring [{Cons}hj]. A string in curly brackets is always interpreted asthe name of a character subset. It is expanded into the charactersubset it stands for, enclosed in square brackets, unless the name isalready enclosed in square brackets. In that case, it is expanded inthe characters of the subset only. Thus, the rule for short vowels canbe formulated as follows:@Verbatim "(.*[{Cons}hj]{Vow})({Cons})/\1\2\2" (ICat stem) »"e.*"     (ICat suffix)@End-Verbatim It has been assumed here, that Vow has been declared as the name of{aeiou}. In the mapping part, the label of the last consonant isrepeated to bring about the doubling. In this way, any type of@Index{reduplication}reduplication can be handled. Obviously, the@Index{consonant doubling}consonant doubling rule should precede thevowel reduction rules, because otherwise the difference betweenlong and short vowels is no longer visible when consonant doublingshould apply.Finally, the schwa is always rewritten as e. This rule should be at theend, or at least after consonant doubling. The special character, e.g. E,should be declared in the lexical character set. New entries thatillustrate each of the rules and some of their interactions can beadded, e.g. praten ('talk', 3rd person singular present praat), besteden('spend', past participle besteed), belonen ('reward', past participlebeloond), duren ('last', 3rd person singular present duurt), tikken('tick (clock)', singular past tikte), regelen ('settle', stem regEl)For c/k and qu/kw@Index{spelling alternation} alternation, we willfirst consider rules that work on wordforms with a single C or qu.The @Index{value}value-facility can be used in the following way. TheC- rules change C into c, and C into k, where C is preserved after thefirst rule, to be input to the second one, by adding value at the end ofthe first rule. The qu-rule changes qu into kw, but preserves theoriginal qu as well, because of the presence of value. A first versionof the rules could be the following:@Verbatim (ISRule c/k-to-c)"(.*)C(.*)/\1c\2" value(ISRule c/k-to-k)"(.*)C(.*)/\1k\2"(ISRule qu/kw-alternation)"(.*)qu(.*)/\1kw\2" value@End-Verbatim In cases of multiple alternation, these rules will apply and take one Cand one qu, but it is not defined in the rule which ones. Furthermore,c/k-alternation and qu/kw- alternation are executed independently,producing consistency violations such as *konsequent. In order toprevent this, the context in the rules above has to be specified as notcontaining C or qu. A problem that we are confronted with inrendering this condition, is that the negation-operator cannot becombined with the star- operator freely. The closest we can get to'any string not containing C or qu' is ([^Cq]*), which excludes slightlytoo many strings. It can be argued that the rare words where q is notfollowed by u have to be dealt with in individual spelling rulesanyway. A more principled approach, however, is to recognize qu inone rule, changing q to a special character, e.g. Q, in this context, anddescribe the context in the rules with a single alternation as ([^CQ]*).The following rule system can be used:@Verbatim (ISRule qu-recognition)"([^q]*)qu([^q]*)/\1Qu\2"(ISRule c/k-to-c)"([^CQ]*)C([^CQ]*)/\1c\2" value(ISRule c/k-to-k)"([^CQ]*)C([^CQ]*)/\1k\2"(ISRule qu/kw-to-kw)"([^CQ]*)Qu([^CQ]*)/\1kw\2" value(ISRule qu/kw-to-qu)"([^CQ]*)Qu([^CQ]*)/\1qu\2"@End-Verbatim The less principled solution, where the context is ([^Cq]), saves twospelling rules, viz. qu-recognition and qu/kw-to-qu, and a specialcharacter.If general rules are written for two or more occurrences, two rulesfor each combination have to be written on the same model as thepairs above. For combinations of more than one qu, separatequ-recognition rules have to be written. Excluding these strings fromthe domain of the qu-recognition rule above is the purpose ofdescribing the context as ([^q]*), rather than ([.*]). Otherwise, one ofthe q's would be affected by this rule but, at least in theory, it cannotbe predicted which one. Writing general rules for all these quite rarecases is not only ugly, it also slows down@Index{compilation}compilation considerably because each generalspelling rule that is not restricted by features will be tested forapplicability to any lexeme during compilation. Therefore, localspelling rules are to be preferred.In @Index{local spelling rules}local spelling rules, value can be usedin exactly the same way as in general spelling rules. As an example,the entry for confisqueren is given below. Note that as much of thestring as possible has been specified and that the local spelling rulestake as their input the output of general spelling rules, including Qarising from qu- recognition.@Verbatim entry»   "Confisqueer" "confisqueer" "confisquer" "konfiskeer" "konfisker"»   ISRules»   "C(onfis)Qu(ee?r)/c\1qu\2" value»   "C(onfis)Qu(ee?r)/k\1k\2"@End-Verbatim @SubSection{Strong Verbs}@SubSubSection{The Data}Apart from the weak verbs discussed in section 2.1, Dutch also has aclass of so-called @Index{strong verbs}'strong' verbs. The mostsalient feature distinguishing them is the vowel change of theirstem. Below, the paradigm of the verbs scheppen ('create'), schenken('pour'), kijken ('look'), and lopen ('walk') are given, in the same orderas the paradigms of weak verbs above.  @Verbatim schep          schenk         kijk           loop  schept         schenkt        kijkt          loopt  scheppen       schenken       kijken         lopen  schiep         schonk         keek           liep  schiepen       schonken       keken          liepen  scheppend      schenkend      kijkend        lopend  scheppende     schenkende     kijkende       lopende  geschapen      geschonken     gekeken        gelopen@End-Verbatim Compared to weak verbs, the d past tense marker is missing in theending. Instead, there is a zero-ending in the singular past indicative,and -en in the plural past indicative and past participle. As to theoccurrence of the prefix ge- in the past participle, the same type ofalternationoccurs as we have seen for weak verbs. Thus, ontlopen('escape') and weglopen ('run away') have as their past participlesontlopen and weggelopen, respectively. Since this alternation hasbeen discussedin the presentation of weak verbs, we will ignore ithere.The vowel change is restricted to forms marked as past. In mostcases the past participle has the same vowel as the past indicative(e.g. schenken, kijken). Otherwise it may have the same vowel as thepresent (e.g. lopen) or a third vowel (e.g. scheppen). According to thevowel changes, Dutch strong verbs can be grouped in ca. 20 classes. Itis not possible to predict from the stem whether a verb is strong orweak, e.g. vergen and werken are weak, scheppen and schenken arestrong. Nor is it possible to predict the vowel change from the stem,e.g. scheppen has e - ie - aa, schenken has e - o - o.Apart from weak and strong verbs, there are various types of mixedand irregular verbs in Dutch. Examples are laden ('load'), zoeken ('lookfor'), and komen ('come'). @Verbatim  laad           zoek           kom  laadt          zoekt          komt  laden          zoeken         komen  laadde         zocht          kwam  laadden        zochten        kwamen  ladend         zoekend        komend  ladende        zoekende       komende  geladen        gezocht        gekomen@End-Verbatim Laden is a regular weak verb, except for the past participle ending.Zoeken has an irregular stem change where not only the vowel butalso the final consonant is affected. The endings are the regular onesfor weak verbs, except in the singular past indicative (zocht insteadof *zochte). Komen has an irregular stem change, viz. the insertion ofw in the past indicative. Furthermore, there is a vowel change in thepresent and in the past, hidden by spelling conventions. The regularalternations would be either kom - kommen and kwam - kwammen orkoom - komen and kwaam - kwamen. The endings are the regular onesfor strong verbs.Unsurprisingly, the most irregular Dutch verb is zijn ('be'). It hasseveral phonologically unrelated stems(@Index{suppletion}suppletion), and more than the usual eightdifferent forms: @Verbatim  ben        1st or (inverted) 2nd person singular present indicative  bent       2nd person singular present indicative (uninverted)  is         3rd person singular present indicative  zijn       plural present indicative or infinitive  was        singular past indicative  waren      plural past indicative  zijnd      present participle  zijnde     present participle  geweest    past participle  wees       imperative singular  weest      imperative plural@End-Verbatim Among strong verbs, a certain degree of regularity can be found. VanSterkenburg & Pijnenburg (1984, p. 1547-1549) lists about 150strong verbs that can be divided in ca. 20 groups according to thevowel change pattern. Kijken belongs to the biggest group (ca. 45verbs), lopen and scheppen are singletons. Mixed and irregular verbscan also be grouped together, e.g. there are some 15 verbs like laden.The fact that they can (and should) be listed entails that the classesof strong, mixed, and irregular verbs in Dutch are not productive. Ingeneral all newly coined verbs are weak. There is one type ofexception, however: verbs that are derived from strong, mixed orirregular verbs by affixation have the same paradigm as their base.@SubSubSection{The Treatment}In representing the verbs discussed above in a WM database, there arethree issues that deserve particular attention. First, the rules shouldhave a different status than regular and fully productive rules, butshould still allow for the extension to derived verbs. Second, theforms showing stem changes should be generated correctly and asefficiently and elegantly as possible. Finally, the groups of verbshaving certain similarities should be related.The first issue, the status of the rules, can be handledstraightforwardly by WM. Besides RIRules, WM has @Index{IIRule(irregular inflection rule)}IIRules (irregular inflection rules). Sinceirregular lexemes are a closed class, the IIRules are not presented asan option for the classification of new words to the lexicographerwho is filling the database, unless the new word is derived from alexeme in an IIRule. The rule character of IIRules allows theformulation of certain generalizations within the closed class, aswill be illustrated below.In organizing the @Index{inflection window}inflection window, thefirst decision to be made is the choice of which classes of verbs willbe grouped together with their endings in inflection units. This choicedepends on a trade-off between two types of generalization. On theone hand, one could opt for a mode of organization where therepetition of the same ending in two or more inflection units isavoided as much as possible. On this basis, the observation that the-t as plural imperative ending and as ending of the second personsingular present indicative occurs in every verbal paradigm could beused as an argument for creating a single @Index{inflectionunit}inflection unit for all Dutch verbs. On the other hand, one couldstress the differences of the endings for different lexemes, thusarguing for multiple inflection units and an individual ending forevery place in each paradigm. Pursuing this option would ultimatelylead to five inflection units for the Dutch verbs we have seen: one forweak verbs (e.g. werken), one for strong verbs (e.g. kijken), one forweak verbs with -en in the past participle (e.g. laden), one for strongverbs with -t in the past participle (e.g. zoeken), and one for zijn.The following seems to us a reasonable compromise: for the majorclasses of verbs, we secure a one-to-one correspondence betweenform and meaning of endings within inflection units, by acceptingsome repetition of endings across inflection units.28 The residue, wegroup together in a single unit. This approach results in threeinflection units: one for weak verbs, one for strong verbs, and one formixed verbs.The inflection unit for strong verbs consists of a single IIRule andcorresponding formative windows, since all strong verbs have thesame set of endings. The most prominent problem is the specificationof the stem vowel change. Stem vowel change, or@Index{ablaut}ablaut, is a non- concatenative process, which makesit difficult to be accounted for in any system for morphologicaldictionaries. In WM, the only facility provided to change a formativestring is the spelling rule. It may seem counterintuitive to treatablaut as a spelling phenomenon, but in WM any manipulation of thestring of a formative is considered as such.From the outset it is obvious that ablaut in Dutch, being restricted toa closed subclass of verbs, should be treated by @Index{local spellingrules}local spelling rules. The conceptually simplest solution is towrite entry-specific rules for each strong verb individually. Thedisadvantage of this solution is that it involves quite a lot ofredundancy. Four of the ca. 20 classes of verbs showing the samealternation pattern contain two thirds of the ca. 150 strong verbslisted by van Sterkenburg & Pijnenburg (1984). This generalization ismissed in a solution by entry-specific rules.One strategy to incorporate the generalizations is to designate a@Index{default}default vowel change for each stem vowel. The mostcommon pattern for -e- is the one illustrated by schenken. If thispattern is encoded in an inflection- rule specific spelling rule, onlyexceptions like scheppen have to be handled by entry-specificspelling rules. Strong verbs can be divided into twelve classesaccording to the stem vowel in the present tense. In principle, foreach of these classes a default pattern can be chosen, and twoinflection-rule-specific spelling rules can be written following themodel illustrated for schenken below: @Item If the last vowel or diphthong of a stem in this window is e,change it to o in the past tense of the indicative.@End-Item@ItemIf the last vowel or diphthong of a stem in this window is e, change itto o in the past participle.@End-Item The 24 similar statements for the 12 stem vowels can be reduced inseveral ways. First, if the past participle has the same vowel as thepresent, as in lopen, the relevant statement can be left out. Secondly,if the past participle has the same vowel as the past indicative, as inschenken, the two rules can be conflated by leaving out modespecification. Thirdly, if the only difference between two rules is thepresent stem vowel, they can be conflated by means of a disjunction.Thus, there is a relatively big group of strong verbs exhibiting thefollowing pattern: @Verbatim  present indicative          drink  past indicative             dronk  past participle             gedronken@End-Verbatim If all three of these reduction mechanisms are applied optimally, the24 statements can be reduced to 8, one of which will be: @ItemIf the last vowel or diphthong of a stem in this window is e or i,change it to o in the past.@End-Item The 8 statements cover over 80 % of strong verbs. One of the reasonswhy this is an important figure, is that@Index{inflection-rule-specific spellingrules}inflection-rule-specific and @Index{entry-specific spellingrules}entry-specific spelling rules behave differently with regard to@Index{wordformation}wordformation. There are many verbs derivedfrom lopen and all of them have the same vowel change pattern aslopen itself. Thus, ontlopen ('escape') has the past tense ontliep. Ifthe spelling rule causing the ablaut is part of the inflection rulespecification, it will cover ontlopen automatically. If it is part of theentry specification, it has to be repeated for each derived verb.Therefore, even if lopen is the only strong verb with an -oo-stem inthe present, it is worthwile encoding the vowel change in arule-specific rather than entry-specific spelling rule.In the case of strong verbs in Dutch, we are quite lucky in the sensethat the inflection-rule-specific spelling rules can be conflated intoa small number, and that their coverage is high. Since @Index{ablaut}ablaut is by no means a rare phenomenon in language and we will notalways be so lucky as to have such coverage with so few rules, wewill briefly consider some alternative strategies.First, there is a simple way of increasing coverage ofinflection-rule-specific spelling rules, which is done by way ofcreating a parallel IIRule. The only differences to the original ruleare its name, its choices of default vowel changes, and its entries. Inour example, we could create a second IIRule for strong verbs, wherethe alternation pattern of scheppen is chosen as a default fore-stems. By creating sufficiently many parallel IIRules, it is alwayspossible to avoid entry-specific spelling rules. Linguistically,however, the division of entries over IIRules becomes completelyarbitrary. Therefore, we will not pursue this approach.A second alternative strategy to decrease the number ofentry-specific rules would be to distribute knowledge between rulesand lexical strings. In rules applying to all strong verbs, it would beindicated that these verbs have a stem vowel change in the pastindicative and past participle. For each individual verb, the lexicalstring would indicate what the alternative stem vowels are. One wayof encoding the vowel change pattern in the lexical string is to use@Index{special character}special characters, similar to how weused them in other sections and to their use in two-level morphology.An alternative option offered by WM is to use string appendices. A@Index{string appendix}string appendix is a part of the lexical stringused as a feature, and separated from the main string by a boundarysymbol, e.g. #. The lexical string of scheppen would contain charactersequences like past-ie and part-aa, to indicate the particular vowelchange pattern, and the inflection-rule-specific spelling rules woulduse the string appendix in the following way: @ItemIn the past tense of the indicative, replace the last vowel ordiphthong by the one found after past-.@End-Item  @ItemIn the past participle, replace the last vowel or diphthong by the onefound after part-.@End-Item The advantages of this approach are that the number of spelling ruleswould be reduced to two, and their coverage increased to 100 %,independently of the complexity of the system of vowel changepatterns. A disadvantage is that lexical strings are very dissimilarfrom surface strings, making them harder to read. This is particularlyrelevant, since one of the main reasons for usinginflection-rule-specific spelling rules as much as possible is thatthe lexicographer will be freed of the complexity of entry spellingrules in wordformation. Furthermore, the generalizations onalternation patterns expressed in default rules are lost here. Theformer problem is solved in the lexicographer's interface, whichhides the string appendices, without losing their information. Thelatter disadvantage could be countered by applying thisknowledge-distributing approach only to cases where the defaultapproach does not work. For Dutch strong verbs, this would mean thatthe 8 default rules would be maintained, and twoknowledge-distribution rules would be added, to cover the remaining20 % of strong verbs. In this way, generalizations would be encoded,only exceptional verbs would have to be marked by string appendices,and the readability problem would be reduced.The fact that the phenomenon of @Index{ablaut}ablaut in strong verbshas been assigned to local spelling rules, entails that the input tothese rules is the lexical string as it has been affected by generalspelling rules, and the output is only modified by further local rules.As far as the process is covered by @Index{entry-specificrules}entry-specific rules, the interaction is simple. The set of inputstrings is small, and the output will not undergo further spellingrules. In other approaches, however, more complex interaction occurs.@Index{default rule}Default and @Index{string appendix}knowledge-distribution rules for ablaut introduce new vowels in thestring, and they will not be subject to the vowel shortening andconsonant doubling rules described in section 2.2. For consonantdoubling this is fine, because the cases where a short vowel isintroduced instead of a long vowel all behave exceptionally, as in thefollowing example: @Verbatim  present indicative   vergeten         ('forget')  past indicative singular              vergat    (shorta)  past indicative plural                vergaten  (longa)@End-Verbatim Where a short vowel replaces another short vowel, the input has beenaffected by consonant doubling already. For zwemmen ('swim'), a verbof the schenken-class, the past indicative will be zwem/zwemmenbefore vowel change, yielding the correct zwom/zwommen. For vowelshortening, the situation is different. The form keeken (pastindicative plural) will not be transformed into the correct keken bythe rules as they have been described up till now. Therefore, the bodyof vowel reduction rules has to be copied as@Index{inflection-rule-specific spellingrules}inflection-rule-specific rules applying after ablaut in thestrong verbs window.The input to the ablaut rules does not represent the abstractionsencoded in the lexical string any more. Thus, the input and outputstrings for the past indicative of lopen and scheppen are:  @Verbatim Input          Output  loop           liep  lopen          liepen  schep          schiep  scheppen       schiepen@End-Verbatim For lopen, the problem is purely a recognition problem. The input forthe vowel alternation rule has to be specified as containing either ooor o. If oo and o are simply included in a disjunction, interaction withthe o- class of verbs is to be feared. A better solution is to specifythat a single consonant follows the stem vowel. This entails aduplication of rules if there are verbs having the same vowel changepattern, but two consonants after the vowel so that the vowel isalways spelled oo.For scheppen, in addition to the recognition problem, there is theproblem of reducing the pp. It is difficult to make a generalization,because only consonants that have been added by the general rule ofconsonant doubling have to be deleted in these cases. One couldconsider writing separate rules of consonant reduction for eachconsonant, or correcting the string entry-specifically.A conceptually attractive solution to all these problems ofinteraction with general spelling rules would be to restrict the scopeof the general spelling rules that yield problems, so as not to includestrong verbs, and have copies of them as inflection-rule-specificspelling rules apply after ablaut. For the output of ablaut, we needcopies anyway, and restricting the scope of general rules wouldfacilitate input specification for the ablaut rules considerably.Komen is a strong verb with some idiosyncrasies. Because of itsendings, it belongs in the inflection unit for strong verbs.Entry-specific spelling rules can, depending on the basic form chosen,reduce oo to o, or mm to m, and change the o to wa in the pastindicative. In the default approach, the input to the latter rule may bedifferent, e.g. kiem/kiemen if komen is taken as basic, and thedefault for oo follows the model of lopen.In the third inflection unit, all the remaining verbs are collected.Their only common property is that their endings correspond neitherto the weak verbs, nor to the strong verbs when their full paradigm istaken into account. Some 15 verbs conjugate like laden, and they canbe arranged in one IIRule window. About the same number of verbsshow irregularities of various kinds. They are divided among IIRulesaccording to their endings.Sometimes, it is hard to determine the boundary between stem andending. A form like zocht could be analyzed as either an irregularalternant of the stem plus a zero ending, or a combination of zoch + t.Both analyses can be implemented, but we will adopt the latter,which has a stronger historical backing. There are a few other verbshaving this ending, if we assume that the underlying d is changed to tby a regular spelling rule that also applies to weak verbs. They can begrouped together in an IIRule window, with entry-specific spellingrules to bring about idiosyncratic changes of the stem.The verb zijn has a deviant set of endings as well as stem@Index{suppletion}suppletion. The endings warrant a separate IIRule,and suppletion is covered by entry-specific spelling rules. Inprinciple it would also be possible to group it together with otherverbs and change the endings in entry- specific spelling rules at thesame time as the stem, but this does not enhance perspicuity.@SubSubSection{The Implementation}In the previous section, several approaches to encoding rules forDutch strong and irregular verbs have been discussed, comparing theirrespective merits. In this section, for each problem a single strategywill be elaborated. In view of the arguments put forward in theprevious section, we have chosen approaches that have strong pointsin their favour, and allow for a demonstration of various possibilitiesoffered by WM. We do not commit ourselves to these choices in thesense that we claim they are necessarily the best for a fullimplementation of Dutch morphology.The inflection window contains a far more elaborate tree than wehave seen in other databases. We have chosen to divide verbs in three@Index{inflection units}inflection units, weak and strong verbs eachcharacterized by a single basic ending for every form, and oneinflection unit for the remaining verbs, as illustrated in Fig. 3.16:                @Figure{ "Inflection window." | "148" | 242 | 290 }@Index{inflection window}For strong verbs, we have chosen a division in an IIRule for verbswith only @Index{ablaut}ablaut and an IIRule for verbs displayingirregular alternations. The latter rule will be used for komen and, in amore complete database, a few other verbs. The interesting part ofthese IIRule windows is the ISRule specification. The strategy wewill describe here is to express default patterns for each vowel, andhandle the exceptional vowel change patterns by distribution ofknowledge between spelling rules and lexical strings. The@Index{default rule}default rule for e/i to o ablaut, as in schenken,can be formulated as follows:@Verbatim "(.*[{Cons}hj])(e|i)({Cons}*)/\1o\2" »   (tense past)@End-Verbatim For the oo-class, catching at the same time loop and lopen as input tothe rule changing the vowel to ie, requires a disjunction as in thefollowing rule:@Verbatim "(.*[{Cons}hj])(oo|o)({Cons})/\1ie\3" »   (tense past)(mode     ind)@End-Verbatim Here, interaction with the o-class has been avoided by specifyingthat the vowel is followed by a single consonant. If the oo-classcontained verbs the stem of which is followed by two consonants, e.g.(the imaginary verb) froosten, these verbs would require a separatedefault rule, with oo instead of the disjunction (oo|o), followed by atleast two consonants. For similar reasons, the e/i-class default rulecan be improved by specifying that the vowel is followed by at leasttwo consonants. If this is not the case in the stem already, as inzwemmen, stem zwem, the final consonant will have been doubled bya general spelling rule before this ISRule applies.In a knowledge-distribution approach to exceptions, we have thechoice between special characters or string appendices in the lexicalstring. Which of the two is preferred depends to a large extent on thebackground of the linguists working with the database. If they aremore accustomed to the use of lexical characters as in @Index{two-level morphology}two-level morphology, the use of @Index{specialcharacters}special characters in the string, e.g. sch-E-IE-AA-penwill be more natural to them. If they are more used to expressing thistype of information in features, string appendices are likely to bepreferred. We will elaborate on the @Index{string appendix}stringappendix option here.For scheppen we use the strings past-ie and part-a to mark its ablautbehaviour. The ISRules have to be able to identify ie and a as thestrings to be inserted instead of the last stem vowel. If the twofeatures are concatenated in a fixed order, e.g. first the pastindicative, and separated by a fixed symbol, e.g. +, we can describethe vowel for the past indicative as the string between past- and +.The appendix must be separated from the real stem by another specialcharacter, e.g. #. Since there are quite a few spelling rules affectingthe end of a stem, but none touching the beginning so far, the easiestsolution is to place the appendix in front of the real stem, producingpast- ie+part-a#schep as the lexical form of the stem of scheppen.The beginning of the real stem is still accessible to general spellingrules. The formula "(.*#)?s[^#]*" selects all formatives whose firstcharacter, apart from any string appendix, is s. The specialcharacters -, +, and # have to be declared in the lexical character set.A spelling rule ordered after the ones that use the string appendixhas to delete it for strings where it is not used. Thus three spellingrules like the following are needed:@Verbatim "past(.*)+.*#(.*[{Cons}hj])({Vow})([{Vow}j]?)({Cons}*)/Æ          \2\1\4" »  (tense past)(mode ind)".*part-(.*)#(.*[{Cons}hj])({Vow})([{Vow}j]?)({Cons}*)/Æ          \2\1\4" »  (tense past)(mode participle)".*#(.*)/\1"@End-Verbatim Some of the effects of general spelling rules have to be repeated orundone after vowel change, i.e. in @Index{local spelling rules}localspelling rules. The extent of these effects is fairly limited.@Index{double vowel reduction}Double vowel reduction, as in keek -keken, has to be repeated only for ee and oo, to cover the full set ofDutch strong verbs. The relevant spelling rule bodies have to becopied to the ISRules section of the IIRule. The problem caused by@Index{consonant doubling}consonant doubling in scheppen, before thevowel is changed to ie in the past indicative, is rare. Only two moreverbs in the list of van Sterkenburg & Pijnenburg (1984) require thiskind of adjustment. Therefore, the best solution is to use@Index{entry-specific spelling rules}entry-specific spelling rules.Thus the entry for scheppen will be:@Verbatim entry»   "past-ie+part-a#schep" "schep" "schepp" "schiep""schap"»   ISRules»   "(sch)(ie|a)(p)p/\1\2\3"@End-Verbatim In the IIRule for irregular strong verbs, such as komen, every entrywill have entry-specific spelling rules for the idiosyncratic stemchanges. For komen, the entry will be e.g.:@Verbatim entry»   "koom" "kom" "kwam"»   ISRules»   "koom/kom"»   "kom/kwam" »   (tense past)(mode ind)@End-Verbatim For the remaining verbs, it seems to us a good strategy to dividethem among different IIRules according to the set of endings, andtreat irregularities by entry- specific spelling rules. In each IIRule,it is specified which past indicative and past participle endings arechosen, by mentioning an ICat feature like (ICat weak), (ICat strong),or, for the d-ending in the past, (ICat middle). As illustrated in Fig.3.16, @Index{branching inflection unit}branching may continue belowthe level of the inflection unit to create intermediate IIRule-nodes.This enhances perspicuity, without affecting the system's behaviour.In a similar way, branching IFormative windows @Index{branchingIFormative windows }can be used when the number or diversity offormatives is too great to overview easily. An alternative way ofstructuring IFormatives is provided in IFormative groups. The conceptof @Index{IFormative group}IFormative group is similar to theconcept of spelling rule group, in the sense that a set of featurescommon to a list of items (here: suffixes) is taken on a separate lineat the beginning of the group, and the members of the group areindented. The advantage of using IFormative groups over branchingIFormative windows here, is that all suffixes belonging to theinflection unit can be kept in a single window. It should be noted that,unlike spelling rule groups, IFormative groups do not allow thepresence of ungrouped IFormatives in the same window. A fullyspecified IFormative window is either made up of IFormative groupscompletely, or it contains only ungrouped IFormatives. Thus, ourwindow for suffixes in this inflection unit is the one in Fig. 3.17:                @Figure{ " IFormative groups." | "149" | 398 | 371 }@Index{IFormative group}Finally, Fig. 3.18 represents one of the possible ways of treating theinflectional paradigm for zijn. Many alternatives exist, and the choicebetween them ultimately depends on which subregularities are givenpriority in view of the other lexemes in the dictionary. The treatmentillustrated in Fig. 3.18 presupposes a general spelling rule, in thespelling rule group for verbs, reducing the endings starting with -enof the present indicative, present participle, and infinitive bydeleting the first e, after certain vowels:@Verbatim (ISRule en-reduction)"(.*[aejo])" (ICat stem) »   "e(nd?e?)/\1"          (tense present)|(mode infinitive)        @End-Verbatim         @Figure{ "IIRule with suppletion." | "150" | 400 | 344 } @Index{suppletion}In the database as it now stands, there are so many entities (rules,entries, and formatives), that the @Index{lexeme browser}lexemebrowser is not necessarily the most practical tool provided by theinterface to test the specifications of the database. Besides thelexeme browser, the WM interface also offers a @Index{general entitybrowser}general entity browser. In this browser, each relationbetween two entities as specified in the database can be used to getfrom one entity to another one. Entities can be selected on the basisof their type and the features they have. Fig. 3.19 represents theretrieval of the IRules with (cat verb). If a particular IRule isselected from this list, such as (IIRule irregular) in Fig. 3.19, otherentities to which it is linked can be accessed by choosing from theAspects menu. From an IRule, the entries, IFormatives(underspecified or fully specified) and rule-specific ISRules it islinked to are accessible in this way.                @Figure{ "The General Entity Browser." | "151" | 390 | 265 }@Index{general entity browser}@Chapter{Wordformation}In this chapter, the parts of WM-grammar relating to wordformationare described. Together with the chapter on inflection, it coversalmost the full WM-syntax. Only certain possibilities related tospecific linguistic theories are left for the next chapter.The method of description followed here is essentially the same as inthe chapter on inflection. The first section, on English nouns andadjectives, presents the basics of wordformation rules on the basisof a relatively simple set of data. The second section, on Germannouns, presents some more complex problems, with the aim ofshowing how they can be solved in a WM- database.As in the chapter on inflection, each description is divided into threeparts: presentation of the data; approaches to the data from a WMpoint of view; and their implementation in a WM-database. Since thenature of the data does not suit a fruitful carving up into separatesubsections, they are presented in larger chunks.@Section{English Nouns and Adjectives}In this section, a fragment of English wordformation is presented,covering parts of both derivation and compounding. By restricting ourattention to nouns and adjectives, and in order to describewordformation as much as possible on its own, the interaction withinflection has been minimized. The main source for the datadiscussed here is Marchand (1969).@SubSection{The Data}Most adjectives have an antonym, a word having the opposite meaning.In some cases, the antonym is an independent form, e.g. good vs. bad,deep vs. shallow. In many cases, however, the antonym ismorphologically related, mostly it is a derivation with one of theprefixes in- or un-. Examples are: @Verbatim  aware          unaware  active         inactive@End-Verbatim For in- there are some assimilated variants, im- before m, b, or p, il-before l, and ir- before r. They are illustrated in the following pairs:  @Verbatim possible       impossible  legal          illegal  rational       irrational@End-Verbatim Nominalization of adjectives is possible with one of the suffixes-ness or -ity. The latter only applies to latinate stems and it oftencauses some changes to the form of the stem.@Verbatim   aware          awareness  rational       rationality  active         activity  possible       possibility@End-Verbatim A final -e of the stem disappears before -ity, and -able/-ible changesto -ability/-ibility. There is an interesting complication hererelating to the meaning of the noun. Most nominalizations ofadjectives by -ness or -ity have a meaning that can roughly bedescribed as 'the quality of being ADJ'. In this sense, the nouns do nothave a plural (e.g. *rationalities). From this generic sense, anindividualized sense has been derived, 'an instance of N'. The twosenses can be illustrated with activity:There was a lot of activity at the market place. He was charged withillegal activities on the black market.In the opposite direction, derivation of adjectives from nouns is alsopossible, e.g. with the suffixes -ful and -less: @Verbatim  faith          faithful  care           careless@End-Verbatim The output of one derivation rule may be input to another one, e.g.impossibility, unfaithfulness.In compounding, two stems are combined instead of a stem and anaffix. In English, the rightmost stem determines the syntacticcategory of the whole. Thus, colour-blind is an adjective. The spellingof English compounds is not very consistent. Colourblind,colour-blind, and colour blind all occur. Compounds can also be inputto derivation again, as in colour-blindness.@SubSection{The Treatment}@SubSubSection{The Prefixes un- and in-}In order to account for the wordformation processes outlined above inWM, we have to make statements like the following for un-: @Itemun- is a prefix@End-Item @Itemun- attaches to adjectives@End-Item @Iteman adjective with un- attached to it is a new adjective.@End-Item These statements are not sufficient however, because onlycertain   adjectives  may  enter  the  process   of   un-attachment.  In order to exclude un-good and un-deep,  weadd: @Itemthe adjectives that un- can attach to are: aware, ...@End-Item Just as we saw for inflection, so it is in @Index{WF-Rule}wordformation that the rule window carries the mainburden of description, although some variation is possible accordingto the strategy that is chosen. The rule window of wordformationconsists of two or three parts: the source; the target; and optionally,a list of entry constraints. For the description of derivation, thereare several different strategies. We will illustrate two of them inrelation to the example of unaware.In the @Index{source}source part, the elements of the new word arelisted: 'Take un- and an adjective'.29 In the @Index{target}targetsection, the new word is described on the basis of these elements:'Put the former element in front of the latter, to produce anadjective'. The @Index{entry constraint}entry constraints have thesame function as entry-lists in inflection windows. One of theseentry constraints will mean: 'For the adjective, aware may be taken,yielding the new word unaware'.As an alternative to this approach, generalizations can be made forrules which are identical except for their selection of wordformationformatives. In the source section, we say 'Take a prefix and anadjective'. In the target section: 'Put the former in front of the latterto produce an adjective'. In the entry constraints, we do not only haveto specify the adjective, but also the prefix, e.g. 'Take the prefix un-,and the adjective aware, yielding unaware'. In this way, un- and in-can be covered with the same rule. This solution means that we needfewer rule windows, but have to specify more in the entryconstraints. This method is especially suitable for many affixes thatbehave in the same way, and apply to only a few base-words. Sinceboth in- and un- apply fairly often, it may be argued that assigningthem a rule window each is preferable because it enhancesperspicuity. On the other hand, it should be remembered that onlyhard-coded entries are written as entry constraints. Thus, it mayalso be argued that maximal perspicuity is achieved by putting allprefixes that have the same source and target specification together.For in-, a number of spelling rules are needed to regulate theassimilation processes. @Index{WFS-Rule}Wordformation spellingrules (WFSRules) offer exactly the same possibilities as ISRules. Theonly differences are that their name has WFSRule instead of ISRule,and their scope is restricted to wordformation instead of inflection.Since the modifications of in- are regular rather than entry-specific,but restricted to certain prefixes (e.g. in- and con-, but not un-), thebest option is to encode them in WFRule-specific spelling rules.Every element used in a wordformation rule must be declared, similarto what we saw for inflection rules. Three types of elements aredistinguished. Besides @Index{underspecifiedWFFormatives}underspecified and @Index{fully specifiedWFFormatives}fully specified wordformation formatives(WFFormatives), similar to underspecified and fully specifiedIFormatives, there are elements taken from the inflection window.WFFormatives are declared in WFFormative windows. Fully specifiedWFFormatives, e.g. un-, are affixes, that attach to a stem that hasbeen declared in the inflection window already, e.g. aware.Underspecified WFFormatives are bound stems. They will bediscussed in Chapter 5.@SubSubSection{The Suffixes -ness and -ity}For -ness, the statements to be made are different from the onescovering un-, in the sense that more information should be given onthe result of the wordformation process: @Item-ness is a suffix@End-Item @Item-ness attaches to adjectives@End-Item  @Item an adjective with -ness attached to it is a noun that does nothave a plural@End-Item @Itemthe adjectives that -ness can attach to are: aware, …@End-Item The absence of a plural for nouns resulting from -ness can be treatedin two ways. First, we can divide English nouns in two classes, eachhaving their own inflection rule, one of which has no plural.Alternatively, we can @Index{deleted forms}delete the plural ofnouns that do not have one, retaining them together with countablenouns in a single inflection rule. The problem with the latter solutionis that for each individual noun formed by -ness- suffixation, theplural has to be deleted. Therefore, we will assume here thatseparate inflection rules exist for nouns having a plural and nouns nothaving one. This is a first illustration of how considerations ofwordformation can influence the choice of strategies in inflection.30For -ity, a number of additional problems arise. First, there are theadjustments to the spelling of the bases it attaches to. The loss ofthe final -e in the derivation of activity from active is a fairlygeneral phenomenon in affixation (cf. refusal, comparable). Since it isnot restricted to -ity, or even to suffixation to adjectives, coverageby a general WFSRule is well-motivated. The change of -ble into -bil-in the derivation of possibility, reflects the contrast in stress.Restricted to affixation by -ity, it can be handled by a WFRule-specific spelling rule.The main difficulty in describing -ity is that the resulting noun onlysometimes has a plural. There are several ways of treating thissituation. First, one could delete the plural in cases like rationality.This solution does not express the fact that the absence of a pluralfor rationality is actually regular, parallel to the absence of a pluralfor awareness. Furthermore, it ignores that activity has two separatemeanings, one of which is parallel to rationality and does not have aplural. A second possibility is to postulate two suffixes -ity, onederiving a noun with a plural, the other a noun without one. Thistreatment renders the ambiguity of activity and the absence of aplural for rationality, but the two readings of activity arerepresented as completely unrelated. It remains purely accidental inthis way that none of the nominalized adjectives in -ness has acorresponding countable noun in -ity. This can be achieved by a@Index{zero derivation}rule deriving the countable -ity from thenon-countable -ity. It can be described as follows: @ItemThis rule applies to nouns ending in -ity that do not have a plural. @End-Item @ItemThe result is a noun with the same string that does have a plural.@End-Item @ItemThe rule applies to activity, …@End-Item @SubSubSection{The Suffixes -less and -ful}In general, -less and -ful do not present further problems. The onlyinteresting point is that, in view of items like ox - oxen and child -children, there will be more than one inflection rule for Englishnouns, whatever the analysis adopted for nouns having a plural formas opposed to the ones without a plural. The source section of therules for -less and -ful should refer to nouns regardless of theirplural. It is not sufficient to be able to refer to inflection rules,because we do not want to write different rules for these suffixesattaching to nouns of each individual inflection class. Therefore, WMallows wildcards in the specification of the inflection rule in thewordformation rule, and features to restrict the elements, e.g. 'one ofthe source elements is a noun'.@SubSubSection{N-A Compounding}For @Index{compounding}compounding, the same description modelcan be used as for derivation. The main difference betweencompounding and derivation is that in compounding, two elements aretaken from the stock of words existing in the inflection window,instead of just one. Thus, the following describes N + A compounds: @Itema noun may be followed by an adjective@End-Item @Itemoptionally, there is a space or hyphen between the two@End-Item @Itemthe result is a new adjective@End-Item @Itemthe words that can be combined in this way are: colour + blind, …@End-Item The only problematic aspect is the @Index{linking element}linkingelement, that can be a space, a hyphen, or nothing. An easy solution isoffered, however, by spelling rules with @Index{value}value, takingone of the three, e.g. the hyphen, as basic, and generating the othertwo as parallel values. The hyphen must be declared as an extracharacter in both the lexical and the surface character set. The space,however, is a member of both sets by default.31If uncommon shapes of the linking element in a particularcombination are to be avoided, the linking element can be representedas a combination of one or more out of space, hyphen, or zero,affected by spelling rules in the way suggested by their names. Thus,for colour and blind the linking element will be spacehyphenzero inits lexical form. This strategy requires some straightforwardextensions in the formulation of spelling rules, which will not beelaborated on here.@SubSection{The Implementation}Before wordformation can be implemented, the correspondinginflection part of the database must be there. The@Index{wordformation window }wordformation window has a designin many respects similar to the inflection window. It is a tree ofwindows with a single root. The @Index{tree editor}tree editor is thesame and so is the system of @Index{partial naming system}partialnames. The inflection unit in the inflection window corresponds tothe @Index{wordformation unit }wordformation unit here, and insteadof RIRules and ICat, there are @Index{RWFRule (regularwordformation rule}RWFRules and @Index{WFCat}WFCat in thewordformation window. Thus, the wordformation window for ourEnglish database may look as in Fig. 4.1:                @Figure{ "Wordformation window." | "152" | 278 | 219 }@Index{wordformation window}One difference with the inflection window is the interaction of the@Index{partial naming system}partial name system with@Index{wordformation unit}wordformation units. In the inflectionwindow, the full name of a rule window is the path from theinflection unit to the terminal node, whereas the name of a formativewindow is the path from the root to the terminal node (see section1.1.3 of chapter 3). In the wordformation window, the full name ofboth rule windows and formative windows is the path from the rootto the terminal node. In the example window, there are two nodeslabeled (RWFRule suffix), and two nodes (WFCat suffix). In both cases,the full names are different so that there is no identificationproblem. This example also illustrates why the naming system hasbeen designed in this way. In a full database, there will be severalrule windows for suffixation, and in this way, they automaticallyhave a unique, conspicuous name.There are three types of windows in the wordformation tree:@Index{comment window}comment windows; rule windows; andformative windows. All non-terminal nodes are comment windows.Rule windows may be either RWFRules or IWFRules. Formativewindows may be fully specified or underspecified WFFormativewindows. As mentioned above, only the former will be discussed here,the latter being explained in chapter 5.The formative window for un- and in- belongs to the simplest type. Itcontains the keyword @Index{fully specified WFFormatives}fullyspecified WFFormatives, and a list of string associations. Just as forfully specified formative windows in the inflection window, a stringassociation is a lexical string in double quotes followed by thecorresponding surface string(s). For these prefixes, the window willlook like the following:                @Figure{ "Fully specified WFFormative window." | "153" | 404 | 109 }@Index{fully specified WFFormative window}A @Index{WFRule window }rule window consists of a @Index{source},a target, and entry constraints32. The source part starts with thekeyword source, followed by a characterization of the elements, withindexes associated with them for reference in the other parts. Un-may be characterized in terms of features, e.g.@Verbatim 1 »   (WFCat prefix.un)@End-Verbatim Unlike in inflection, however, there is a more direct way of accessingthe string which does not involve its being a value of WFCat.Therefore, a better characterization is the following:@Verbatim 1 »   "un" »   (WFCat prefix)@End-Verbatim The number is the index@Index{index}. For a rule with two elements, 1 and 2 mustbe used, but the order of assignment in the source is arbitrary. Thusthe index might have been 2 here, provided that the adjective hadbeen 1. The syntax of the string characterization is the same as thesyntax for the characterization of strings in spelling rules that arenot changed. Thus we could refer to un- and in- by means of thefollowing:@Verbatim 1 »   "[ui]n" »   (WFCat prefix)@End-Verbatim Note that it is irrelevant that in- has several surface variantsbecause it is the lexical string that is taken into account here. If allprefixes of the wordformation unit are combined in one rule, thestring characterization can be left out. The adjective is referred toby the RIRule applying to it, as well as the relevant features, e.g.@Verbatim (RIRule adjectives)»   2 »   (ICat stem)@End-Verbatim The generalization required for the WFRule for -less and -ful can beachieved by using @Index{wildcard}wildcards in the rule part.Wildcards can be introduced for only the name, e.g. (RIRule ?), or forthe type of inflection rule as well, i.e. (?IRule ?). In the latter case, awarning message is produced if the formula does not refer to bothRIRules and IIRules.33 Apart from wildcards, generalizationmechanisms include @Index{disjunction (or)}@Index{or(disjunction)}disjunction, e.g. (RIRule only- sg)|(RIRule sg-pl), and@Index{negation (not)}@Index{not (negation)}negation, e.g. (?IRule?)^(RIRule adjectives). If only-sg and sg-pl are the only rules fornouns in the database, and adjectives is the only rule not applying tonouns, these characterizations are equivalent to the formulation witha wildcard. Needless to say, however, an approach that does notdepend on accidental properties of the database is preferable becauseafter any change to the database, all these dependencies should bechecked again.For the feature specification, there are two possibilities. First, wecan state in the source part of the rule for -less and -ful that thesesuffixes apply to noun stems as in the following formula:@Verbatim (?IRule ?)»   1 »   (cat noun)(ICat stem)2 »   (WFCat suffix)@End-Verbatim Alternatively, we can state that the suffixation applies to stemswhose inflection is governed by a rule dominated by the node (catnoun) in the inflection tree, as in the following formula:@Verbatim (cat noun) »   (?IRule ?)»   1 »   (ICat stem)2 »   (WFCat suffix)@End-Verbatim Although equivalent here, in other circumstances only one of the twomethods may be the appropriate way of feature specification.The only thing special about the source section of a WFRule for@Index{compounding}compounding is that it is composed of threeelements, two of which are taken from the inflection part of thedatabase, the third one being the linking element.The @Index{zero derivation} WFRule deriving the countable nouns in-ity from their homographic non-countable counterparts will have asingle element in the source. This element is taken from theinflection part of the system because that is where the WFRulegenerating the non-countable nouns in -ity puts its result. Therefore,the source part of this WFRule cannot be restricted to nouns with-ity as a suffix, but only to nouns having -ity as the end of the stem:@Verbatim (RIRule only-sg)»   1 »   ".*ity" (ICat stem)@End-Verbatim There are good arguments, however, for leaving out the stringrestriction altogether and applying the rule to other non-countablenouns as well, e.g. wine, stone.The @Index{target}target part consists of the keyword targetfollowed by a description of the result of the rule in terms of theelements specified in the source part. The inflection rule that appliesto the result is quoted and the form of the new stem is given. In all ofour examples here, the form is the concatenation of the elements ofthe source.34 Thus, for the un-rule, the target will be:@Verbatim (RIRule adjectives)»   1 2 »   (ICat stem)@End-Verbatim @Index{entry constraint}Entry constraints have basically the samesyntax as WFRules, but they provide further specification so that foreach element in the rule there is exactly one match. Each entryconstraint consists of two parts, one restricting the source and onerestricting the target. The source constraint starts with the keywordsource- constraint. For elements taken from the inflection part of thedatabase, the inflection rule should be mentioned, either in full orwith wildcards. This rule specification may perform part of thespecialization, but feature or string specifications restricting thescope of the indexes are the main tools. For unaware, thespecialization can be:@Verbatim 1 »   "un"(?IRule ?)»   2 »   "aware"@End-Verbatim Of course, the specification of the prefix is only necessary if the rulegeneralizes over several prefixes. Otherwise it can be left out. Thespecification of the inflection rule with wildcard is unproblematic aslong as the string is unique. Even in cases like care, which may be anoun or a verb, there is no problem in the rule for -less, since thegeneral source description requires the input to be a noun. The targetconstraint consists of the keyword entry, followed by a <tab> and thestring of the new stem.Given the extensive discussion of spelling rules in Chapter 3, wesuppose that it is not necessary to explain the formulation ofWFSRules needed here. The @Index{WFRule-specificWFSRules}WFRule-specific WFSRules are inserted between the sourceand target specifications. Fig. 4.3 illustrates this for the WFRule forun- and in-prefixation.                @Figure{"RWFRule with local spelling rules." | "154" | 327 | 374 }@Index{RWFRule (regular wordformation rule} When WFSRules affect an element taken from the inflection part ofthe system, the @Index{spelling alternation}spelling variants of thiselement have to be entered as surface variants there. Thus, activ andpossibil must be specified as surface variants in the entries foractive and possible, respectively. In the formulation of the spellingrule changing -ble into -bil, it has to be taken into account thatfinal-e-deletion has already applied, so that the rule can beformulated as follows:@Verbatim "(.*[ai])bl/\1bil" »   "ity"@End-Verbatim Formulating spelling rules for the variation of the @Index{linkingelement}linking element in @Index{compounding}compounds requiresspecial care. The output of a WFRule is a lexeme. Colour-blind,together with its variants colourblind and colour blind, is a singlelexeme. For each lexeme, the stem has a single lexical form. If thestem is the result of a WFRule application, its lexical form is thestring given after the keyword entry in the entry-constraint. Itresults from application of the WFRule and all relevant@Index{WFSRule}WFSRules. Therefore, the spelling rules for thevariation of the linking element cannot be WFSRules. They can be@Index{ISRule}ISRules, however, because ISRules can produceseveral surface forms belonging to the same lexeme. For ISRules, theinformation that the hyphen is a linking-element is not accessibleanymore. They take as their input the formative colour-blind,delivered as an adjective stem by the WFRule for compounding.Therefore, the ISRules realizing the spelling variants can beformulated as follows:@Verbatim (ISRule linking-element-to-zero)"(.*)-(.*)/\1\2" value(ISRule linking-element-to-space)"(.*)-(.*)/\1 \2" value@End-Verbatim If problems arise from the ambiguity whether the hyphen is a linkingelement or not, its lexical string can be replaced by a specialcharacter, e.g. %, or a string like -hyph-. If the latter is chosen, thefollowing rules can be used:@Verbatim (ISRule linking-element-to-zero)"(.*)-hyph-(.*)/\1\2" value(ISRule linking-element-to-space)"(.*)-hyph-(.*)/\1 \2" value(ISRule linking-element-to-hyphen)"(.*)-hyph-(.*)/\1-\2"@End-Verbatim The connections between lexemes related by WFRules can beretrieved via the lexeme browser or the general entity browser. Inthe @Index{lexeme browser}lexeme browser, several options areavailable as alternatives for paradigms and wordforms illustrated inChapter 3. They can be chosen from a menu bar as in Fig. 4.4:                @Figure{ "Menu bar of the lexeme browser." | "155" | 403 | 176 } @Index{lexeme browser}By selecting @Index{generation history}Generation history from thismenu, all lexemes derived from the lexeme under consideration willbe listed, as in Fig. 4.5:                @Figure{ "Generation history of probable." | "156" | 403 | 180 }In this window, a lexeme from the list can be selected, and a newlexeme browser created. For the selected lexeme, e.g. probability,there is a @Index{creation history}Creation History. In the same wayas for ISRules, the action of @Index{WFSRule}WFSRules can bedisplayed by selecting a (the) target formative, as illustrated in Fig.4.6:                @Figure{ "Creation history of probability." | "157" | 403 | 391 }@Section{German Nouns}As an example of a somewhat more complex system ofwordformation, a fragment of German nominal morphology ispresented here. The fragment covers parts of suffixation andcompounding. It is shown how, setting out from the wordformationmechanism used for English, more intricate relationships and(partial) generalizations can be expressed, and how the organizationof the database is affected. The main source of the German data usedhere was Drosdowski (1984).@SubSection{The Data}In several respects, nominal inflection in German is morecomplicated than its English counterpart. In German, a noun isspecified for gender inherently, and inflected for number and case.Gender is masculine, feminine, or neuter. There are far more differentparadigms than in English, some of which include, apart from thecombination of stem and suffixes, a type of vowel change of thestem, similar to the vowel change in strong verbs in Dutch (section2.3 of chapter 3). In German, the vowel change in nouns is writtenwith special @Index{umlaut}umlaut characters, a, o, u, and aubecoming ä, ö, ü, and äu, respectively. A further peculiarity of Germanspelling is that every noun is written with a capital letter.In wordformation, some of these complications have furtherconsequences. The following are examples of suffixation:  @Verbatim Wissenschaft   fem            ('science')  Wissenschaftler               masc    ('scientist')  Sport          masc           ('sport')  Sportler       masc           ('sportsman')  Pforte         fem            ('gate')  Pförtner       masc           ('porter')  Student        masc           ('student')  Studentin      fem            ('female student')  Schrift        fem            ('writing')  Schrifttum     neut           ('literature')  Heide          masc           ('pagan')  Heidentum      neut           ('paganism')@End-Verbatim As indicated by these examples, the gender of a suffixed noun dependson the suffix. Derived nouns with the suffix -ler are masculine, likethose with -ner, the ones with -in are feminine, and with -tumneuter. In the same way, the inflectional paradigm is determined bythe suffix. The only inflectional irregularity associated with thesuffixes in the above examples is the n-doubling in the plural ofnouns derived by the suffix -in, e.g. Studentinnen. Some of the othersuffixes bring about particular changes to the stem. Thus, -nercauses the stem to be umlauted, and before -tum the stem isaugmented by a linking element in some cases, e.g. -n in Heidentum.All these properties are determined by the suffixes. Only the form ofthe linking element depends on the base noun (cf. the discussion onlinking elements in compounding below). In the case of Heidentum, itis interesting to note that there is a feminine word Heide ('heath'),which is completely unrelated etymologically, but homonymous to themasculine Heide ('pagan'), which is input to the derivation.In compounding, the situation is only slightly different, as illustratedby the following examples: @Verbatim  Kultur         fem            ('culture')  Geschichte     fem            ('history')  Kulturgeschichte              fem     ('cultural history')  Hund           masc           ('dog')  Leben          neut           ('life')  Hundeleben     neut           ('dog's life')  Huhn           neut           ('chicken')  Hof            masc           ('farm')  Hühnerhof      masc           ('poultry yard')  Sonne          fem            ('sun')  Brille         fem            ('glasses')  Sonnenbrille   fem            ('sun glasses')  Ordnung        fem            ('order')  Prinzip        neut           ('principle')  Ordnungsprinzip               neut    ('organizing principle')@End-Verbatim In the same way that gender and inflectional paradigm depend on thesuffix in suffixation, so too do they depend on the righthand elementin compounding, as illustrated for gender above. As to the linkingelement, these five examples illustrate the five common forms it cantake: ∆, -e-, -er-, -(e)n-, and -(e)s-. The choice between themdepends entirely on the first element in the examples above, but thisis not always the case, cf. the following examples:   @Verbatim  Gast        ('guest')    Gasthof      ('inn')  Hof         ('farm')     Gästebuch    ('visitor's  book')  Buch        ('book')    Buch        ('book')     Buchhandlung ('bookshop')  Handlung    ('shop')     Bücherbrett  ('bookshelf')  Brett       ('shelf')    Tag         ('day')      Tageblatt    ('daily  newspaper')  Blatt       ('leaf')     Tageszeitung ('daily  newspaper')  Zeitung     ('newspaper')    Staat       ('state')    Staatenbund  ('confederacy')  Bund        ('union')    Staatsanwalt ('public  Anwalt      ('lawyer')                prosecutor')@End-Verbatim In these examples, the first noun determines a set of possible linkingelements, and for each individual compound one of them is chosen.Whether the first element is umlauted depends on the linkingelement, it must be -e- or -er-, and the plural, which must have anumlaut as well.Although it is not possible to predict the linking element from theform or the inflectional paradigm of the first element, somegeneralizations can be made in the form of conditions. The linkingelements -e- and -er- require a plural in -e- and -er-, respectively.For masculine and neuter nouns, the linking element -(e)s- onlyoccurs when the genitive singular ending is the same. For femininenouns, this linking element requires one of a particular set ofendings, including -ung.@SubSection{The Treatment}The problems involved in treating derivation and compounding ofnouns in German can be summarized as follows: @ItemChoosing the correct gender and IRule for the result.@End-Item @ItemDetermining whether umlaut should take place, and, if  so, where.@End-Item @ItemFinding the correct linking element.@End-Item @ItemSelecting the correct reading.@End-Item The problem of @Index{capitalization}capitalization has not beenincluded in this list, because we do not consider it a task of WordManager. Capitalization is first of all a sentential phenomenon, and assuch outside the scope of WM. In exceptional cases like German,where capitalization interacts with morpho-syntactic information,the interaction is such that there is a direct dependency betweenmorphosyntactic information and capitalization. This means forGerman nouns, for instance, that a client application can derive therelevant information from the distribution of the feature nounrepresented in the WM dictionary, and sentence boundaries.The complexity of the solution to the other problems depends largelyon to what extent @Index{morphologicalgeneralizations}morphological generalizations are expressed. Themore generalizations expressed, the more complex the rule systemwill be. The motivation for encoding generalizations in the rules ismainly theoretical. Since the explicative power of a theory isinversely proportional to its descriptive power, it is to be preferredto limit the possibilities allowed by the theory if validgeneralizations can be found. Whether a generalization is valid can betested easily by encoding it in WM. If the lexicographer comes acrossan exception, he will not be able to enter it without the linguist'sintervention. At the same time, each valid generalization protects thelexicographer from making errors violating it. In our treatment, wewill proceed from a simple database, including more and moregeneralizations until we touch the limits of WM's possibilities.The choice of gender and IRule depends on the suffix in suffixation, sothat it can be encoded in the target of the rule. For compounding, theymust be taken from the second noun. Solutions where the dependencybetween the gender and IRule of the compound and the gender andIRule of its second element are not expressed are linguisticallyunsatisfactory. They include specifying gender and IRule for eachindividual compound in the entry-constraint, or splitting up thecompounding rule into separate rules for each combination of genderand IRule that occurs. In order to express the dependency, WMprovides the possibility of @Index{propagation}propagation offeatures and rules. In the source part they may be marked with a signthat causes them to be transferred to the target.For generalizations on the distribution of @Index{umlaut}umlaut, wecan choose between two alternative strategies. The first ischaracterized by the use of special characters. The second consists insplitting up rule windows. In the first strategy, umlautable vowelsare marked by @Index{special character}special characters, e.g. A, O,and U, which cover the umlauted and non-umlauted a, o, and u.Spelling rules will rewrite A, O, and U either with or without umlaut,depending on the specific environment they occur in. Thus, gAst + e +buch becomes gästebuch, but gasthof will be generated from gAst +hof without umlaut, because the zero linking element is not anumlauting environment, and tageblatt from tag + e + blatt, becausetag does not contain an umlautable vowel. In the second strategy, theWFRule for compounding is split up in two WFRules, one with and onewithout umlaut. In the window with umlaut, WFRule- specificspelling rules will say: 'If the last vowel of the first element of acompound formed by this rule is a, o, u, or au, change it to ä, ö, ü, oräu, respectively'. This command summarizes three spelling rules, fora, o, and u. In each of them, it should be checked that the vowel ispreceded by a consonant, in order to prevent e.g. au and eu to beturned into *aü and *eü. The vowels to be umlauted can only befollowed by consonants, except a, that can also be immediatelyfollowed by u. In this approach, gästebuch originates in a differentWFRule from tageblatt and gasthof, and there is no need for specialcharacters for a, o, and u which can be umlauted.35To what extent the choice of a @Index{linking element }linkingelement complicates the rules, depends again on how much of thelinguistic constraints and generalizations are encoded. If nothing ofthe kind is expressed, one or two rules, depending on the treatment ofumlaut, are sufficient. In this approach, the linking element isspecified for each individual compound in the entry constraint. Asillustrated by lists like Ordnungsprinzip, Ordnungssinn('orderlyness'), Ordnungszahl ('ordinal number'), etc., an obviousgeneralization is missed, however.A first step towards integrating constraints on the linking element isproviding a feature indicating what linking element follows a givennoun. Thus, Ordnung would have an @Index{individually added feature}individually added feature in the IRule window where it appears,telling that it selects -s- as a linking element. In order to use thesefeatures in wordformation, rules involving a linking element have tobe split up according to its form. Each of the five linking elementsyields a separate compounding rule, with a fully specified linkingelement, and an entry feature condition on the first element of thesource. Now, there are five or seven rules for compounding: fivedifferent linking elements, two of which sometimes have umlaut. Forwords like Staat, allowing several linking elements, it is possible toassign them the feature indicating the linking element twice, withdifferent values, if @Index{ICat}ICat or @Index{WFCat }WFCat ischosen as attribute. Since any individually added feature ispercolated to become visible on the surface, however, and ICat andWFCat have been introduced especially for non-percolating features,this is not an elegant solution. As an alternative, a catch-all rule,without conditions on the linking element can be added.In a further step, the system as described above can be taken as abasis, which individual constraints and generalizations can be addedto. For umlaut, there are quite strong conditions. That it only occurswith the linking elements -e- and -er- has already been taken intoaccount. But the correlation with umlaut in the plural can also beadded. How this is to be achieved depends on how umlaut has beendealt with in inflection. If special characters are used, thiscorrelation has already been taken into account implicitly. Thedistribution of special characters is valid for both plural forms andforms appearing as lefthand elements of a compound with -e- or -er-as linking element. If no special characters have been introduced, andinflection spelling rules take a feature as a condition for umlaut inplural, the same feature can be used as a condition in the WFRules forcompounds with umlaut.In order to render a condition like '-e- as linking element requires-e- as plural ending', we should incorporate an element in the rulethat is not used in the target. It occurs in the source, but does nothave an  because it is only a condition. In this way, conditions on-e- and -er- can be formulated easily. For -(e)s-, the correspondingcondition only applies to masculine and neuter nouns. Consequently,the condition can only be formulated at the cost of splitting up therule for -(e)s- in one for masculine and neuter, and one for femininenouns as first elements.For feminine nouns taking -(e)s-, there is no general rule. Still thereare a number of endings that are always followed by this linkingelement. They include suffixes like -ung and -schaft, as well asnon-morphological strings like -at. Since at least some of them arequite frequent, it makes sense to incorporate the generalizations,relieving the lexicographer from the task of introducingrule-governed, hence redundant, information. It is not possible,however, to characterize exhaustively the set of feminine nounstaking -(e)s- in terms of endings. As a consequence, the inclusion ofthis generalization means that a rule should be added as a catch-allof other cases.In order to maintain perspicuity with a larger set of WFRules,@Index{branching wordformation unit}branching in the wordformationtree is allowed to continue beyond the level of the wordformationunit, in the same way as branching IRule nodes inside an inflectionunit is possible.The preceding discussion centred on compounding, rather than onsuffixation. Most of the properties relevant to WFRules can be derivedfrom the suffix, and as such @Index{suffixation}suffixation does notseem to pose major problems. Adding up everything, however, thenumber of rules is quite high. If we (conservatively) estimate 10-15IRules for nouns, 3 genders, yes/no umlaut, and yes/no linkingelement, we end up with 120 to 180 possible WFRules for suffixesproducing nouns from nouns, much more than the number of relevantsuffixes. If there are two suffixes coinciding in all these respects, itis rather accidental. Therefore, ways of combining severalpossibilities by abstracting away from the specification in theWFRule proper should be envisaged.Suffixes with and without umlaut on the stem they attach to can becombined in a single WFRule, if the scope of the spelling rule bringingabout umlaut is restricted to these suffixes only. In the spelling rule,the string of the suffix can be specified as -ner, in our example, andsuffixes behaving similarly can be added in a disjunction. The samestrategy can be applied to the spelling rule deleting a stem-finalschwa.Suffixes producing nouns with different genders can be combined in asingle WFRule, if gender is specified in the entry constraints, insteadof in the target of the rule. This is not a satisfactory solution,however, because the dependency relation holding between the suffixand the gender is not expressed.WM offers an alternative, where the target of the rule isunderspecified, and the features of the result are specified asproperties of the suffix. In this case, the WFRule is reduced to amodel, and additional information is given in the @Index{WFFormativewindow}formative window where the suffixes occur. The entryconstraints must also move to the formative window.There are two restrictions to this strategy. First, all information onthe target and the entry constraints must be specified either in theWFRule, or in the formative window. This restriction guarantees thatone of the two is simple: either the WFRule is a model, and allinformation accompanying the resulting strings is specified in theformative window, or the formative has only information restrictingits applicability in WFRules, and all information on the result isspecified in the WFRule. Secondly, the choice between specificationin the WFRule window or in the formative window has to be the samethroughout the wordformation unit. A single formative window cannotcontain suffixes with and without information on the output of theirapplication.Combining rules for suffixes with and without a @Index{linkingelement}linking element is not possible. These two classes ofsuffixes have a different number of source elements in their rules,and it would go too far to abstract away from this information in theWFRule.@SubSection{The Implementation}Compared to the implementation of English wordformation, whenimplementing German nominal compounds and derivations along thelines sketched in the previous section, we need the followingadditional types of WM- properties: @ItemBranching WFRules.@End-Item @ItemRestrictions on the source of WFRules.@End-Item  @ItemSpecification of information in the target of WFRules.@End-Item @Item Generalizations over WFRules by specialization inWFFormative windows.@End-Item The idea of branching WFRule nodes is best illustrated byan example of a tree in the wordformation window:                @Figure{ "Wordformation window with branching WFRule nodes." | "158" | 317 | 241 }@Index{wordformation window }@Index{branching WFRule node}As soon as a node has become non-terminal, its contents is taken tobe@Index{comment windows} comments. This allows experimenting with subdivisions of a rulewithout erasing the original one, and copying the original one into thevarious subdivisions to facilitate adaptation.In the discussion of compounding, we have seen how three new typesof constraints can be imposed on the source elements as conditionsto be fulfilled for the rule to apply. The first type is the presence ofa specific @Index{entry feature}entry feature, indicating whichlinking element the noun takes when it is the first element in acompound. If (link e) is used to indicate -e- is the linking element,the characterization of the first element in the source of thecorresponding rule will be:@Verbatim (?IRule ?) »   entry-features (link e)»   1 »   (cat noun)(ICat stem)@End-Verbatim A second type of constraint is used when the linking element -e- isconnected to the plural -e. In order to express this correlation,non-indexed formatives, called @Index{IFormativeconstraint}IFormative constraints, can be added to the sourcedescription. They always precede the indexed formatives, as in thefollowing example:@Verbatim source(?IRule ?)»   "e" »   (number plural)»   1 »   (cat noun)(ICat stem)2 »   "e" »   (WFCat linking-element)(?IRule ?)»   3 »   (cat noun)(ICat stem)@End-Verbatim Both the string and the feature set in the IFormative constraint areobligatory. Finally, for cases like feminine nouns ending in -ung,-schaft, -at etc., the generalization that they always take the linkingelement -s- can be expressed by a string match in the@Index{IFormative number association}IFormative numberassociation as in the following example:@Verbatim source(?IRule ?)»   1 »   ".*(ung|schaft|at)" »   (ICat stem)2 »   "s" »   (WFCat linking-element)(?IRule ?)»   3 »   (cat noun)(ICat stem)@End-Verbatim Information on the properties of the result of a WFRule can deriveeither from elements in the source, or it may be added as a generalproperty of all resulting words produced by this WFRule. In theformer case, the value of a source element is@Index{propagation}propagated to the target by the sign >. This signcan be applied to both IRules and entry features, as in the followingexample for compounds:@Verbatim source(?IRule ?)»    1 »    (cat noun)(ICat stem)2 »    (WFCat linking-element)(?IRule ?) > »    entry-features (gender >)»    3 »    (cat noun)(ICat stem)@End-Verbatim No special provisions have to be taken in the target, but of course thetarget must be unspecified for propagated information. In the lattercase, information is carried by @Index{individually addedfeature}individually added features in the @Index{target}target, asin the following example, in the suffixation rule for -ler:@Verbatim target »   added-features (gender masc)(RIRule plural-zero)1 2@End-Verbatim An alternative to specifying these features generally within the ruleis to specify them for individual entries. In that case, they occur inthe @Index{entry constraint}entry constraints, as in the followingexample:@Verbatim source-constraint(?IRule ?)»   1 »   "Wissenschaft"entry »   (gender masc)»   "Wissenschaftler"@End-Verbatim A more attractive solution to the problem of proliferation ofdistinctions in the target is to use the WFRule as a model, with anunderspecified target, and move the specifications and entryconstraints to the @Index{WFFormative specialization}WFFormativewindow. A model WFRule, combining the rules for -ler and -in is Fig.4.8:                @Figure{ "WFRule serving as a model only." | "159" | 348 | 168 } @Index{WFRule}The specification of the target in a model WFRule can only consist ofa wildcard IRule, the order of the source elements, and features ofthe resulting stem. The gender and IRule associated with individualsuffixes are specified in the WFFormative window, as illustrated inFig. 4.9:                @Figure{ "WFFormative window with target specialization." | "160" |341 | 410 } @Index{WFFormative window}@Index{targetspecialization}The first line for each formative specifies the lexical and surfaceforms as usual. The next line indicates the WFRule applicable to theformative. The next two lines specify IRule and gender of the targetin the same way as they can be specified in a WFRule. The keywordentries signals the end of the formative specification and thebeginning of the entry-constraints. The entry-constraints here havethe same syntax as entry-constraints in a WFRule window.36The suffix -tum cannot be combined with -ler and -in, because itrequires an additional element in source and target, the@Index{linking element}linking element. If for -ler and -in a solutionwith target specialization in the WFFormative window is chosen, thefollowing options are available for including in the database aseparate rule governing -tum. If target specialization in theWFFormative window is chosen for -tum as well, the two rules forsuffixation with and without linking element can be combined in asingle wordformation unit. If it is preferred, however, to specify thegender and IRule of the target in the WFRule for -tum, the suffix -tummust be defined in a separate WFFormative window, because it is notallowed to declare specialized and non-specialized WFFormatives in asingle window.The entry constraint for Heidentum will have to select the correctHeide. One way of doing this is gender specification in the sourceconstraint. This leads to an @Index{entry constraint}entry constraintlike the following:@Verbatim source-constraint(?IRule ?) »   (gender masc)»   1 »   "Heide"entry»   "Heidentum"@End-Verbatim Spelling rules for the German database do not present many newproblems. The following is an example of a WFRule-specific spellingrule for @Index{umlaut}umlaut of a in compounding. It is assumedthat the distinction between +/- umlaut is made by including thecompounds in different WFRules, and that Cons has been defined as acharacter subset containing the consonants.@Verbatim "(.*{Cons})a({Cons}{Cons}*)/\1ä\2" »   Æ          (WFCat linking-element) »   (ICat stem)@End-Verbatim The n-doubling in the plural of Studentin has to be covered by anISRule. The @Index{ISRule}ISRule cannot access -in as a WFFormative.One approach is to write an ISRule doubling the final n after any i:@Verbatim "(.*in)/\1n" »   (number plural)@End-Verbatim This rule will also apply to Vitamin, the correct plural of which is,however, Vitamine. An alternative, where the doubling is restrictedto -in as a formative, is the following: first, a@Index{WFSRule}WFSRule changes the suffix -in into -IN:@Verbatim "in/IN" (WFCat suffix)@End-Verbatim Then two ISRules rewrite IN as in in the singular and inn in the plural:@Verbatim "(.*)IN)/\1in" »   (number singular)"(.*)IN)/\1inn" »   (number plural)@End-Verbatim These three spelling rules governing n-doubling can easily beformulated as WFRule and IRule-specific spelling rules.@Chapter{Linguistic Theories}@Section{Theories of the Lexicon}In this section, some lexicological issues and their reflection in WMwill be discussed. Section 1.1 treats the status of the WM-lexeme inrelation to other units of description. Section 1.2 deals with anumber of coverage questions, both from a lexicographic and a WMperspective. Finally, in section 1.3, a few points relating to therepresentation have been collected.@SubSection{Units of Description}The basic unit of description in WM is the @Index{lexeme}lexeme. Theconcept of lexeme in WM is very similar to the one proposed byMatthews (1974). A lexeme is an inflectional paradigm with its name.The name of a WM-lexeme is the @Index{lexeme identifier}lexemeidentifier. The lexeme identifier should be thought of as a mnemonicsubstitute for an arbitrary, unique number. Since for each pair oflexemes, the identifiers must be different, WM composes theseidentifiers from different entities in such a way that, wherever it isreasonable for a linguist to distinguish two lexemes, the lexemeidentifiers will automatically be different. A lexeme identifier thusconsists of the following elements: @ItemThe (surface) string of the first citation form.@End-Item @ItemThe features qualifying the inflection unit.@End-Item @ItemThe individually added features.@End-Item @ItemThe intersection of paradigmatic features of all wordforms.@End-Item Usually, for two lexemes either the string is different (e.g. house andflat), or the inflection unit (e.g. care as a verb and a noun), or theindividually added features (e.g. masculine and feminine livre inFrench, meaning 'book' and 'pound', respectively). Since it is importantto understand the difference between lexeme identifiers and@Index{citation forms}citation forms, we will present two cases where thedifference emerges clearly.In section 1.3 of chapter 4, an analysis of items like activity hasbeen presented where the noun with a plural is derived from the nounwithout a plural. If the @Index{lexeme browser}lexeme browser isasked to give a view on activity, part of its answer will be Fig. 5.1.                @Figure{ "Two lexemes activity." | "161" | 402 | 166 }There are two lexemes for activity, one of them with (numbersingular) in the lexeme identifier, because this feature is shared byall its wordforms (there is only one wordform). For both lexemes, thecitation form only contains the feature (cat noun), because (numbersingular) is a paradigmatic feature. Since for any pair of lexemes thelexeme identifiers must be different, features sometimes have to beadded to differentiate the lexemes. If, for instance, the two verbsring, having different past tenses, are entries in the inflection unitscharacterized by (cat verb)(ICat regular) and (cat verb)(ICat ablaut),they would normally get the same lexeme identifier, "ring" (cat verb).Therefore, in such cases the lexicographer is prompted by the systemto add a feature to distinguish them. This will be an@Index{individually added feature}individually added feature, e.g.(diff regular) and (diff ablaut).In section 2.2. of chapter 3, Dutch verbs with two alternativespellings have been discussed, e.g. controleren/kontroleren. Thevariants belong to a single lexeme. This lexeme has one lexemeidentifier, but two citation forms, as illustrated in Fig. 5.2.                @Figure{ "Two citation forms for one lexeme." | "162" | 403 | 165 }The string of the first citation form is chosen as the string of thelexeme identifier. The order of the citation forms is determined bythe order of spelling rules generating the strings from the lexicalstring. The string not affected by a spelling rule containing@Index{value}value will be the first.In some dictionaries, the unit of description corresponds very closelyto the WM-lexeme. Thus, van Sterkenburg & Pijnenburg (1984)distinguish entries on the basis of the string, the syntactic category,and major differences in pronunciation. Within an entry, the firstorder division is based on gender and inflectional paradigm.In other dictionaries, however, items belonging to different syntacticcategories but having the same string, are described in one entry.Thus, Sinclair (1987) groups together the verb care and the noun carein a single entry. This way of partitioning lexical space comes closeto one based on the @Index{lexical unit}lexical unit. A lexical unit isdefined in the following way: @ItemNo two lexical units have the same string.@End-Item @ItemA lexical unit cannot be compositionally decomposed into smaller units.@End-Item Obviously, the choice of the string for a lexical unit has a largeinfluence on the extent to which the partitioning makes sense. If inDutch the infinitive is chosen as the string for verbs, the verb kussen('kiss') belongs to the same lexical unit as the noun kussen ('pillow').If the stem is chosen, however, it is grouped together with the nounkus ('kiss'). The second defining condition of lexical unit presupposesfor its application a set of definitions of rule-based phenomena, withtests derived from the definitions, to determine whether an itembelongs to any of these phenomena. Such a system of definitions iscurrently under development. Part of it is presented in ten Hacken(1992).For the representation of lexical units, WM offers a position in eachentry specification (including entry- constraints in wordformationrules), where it is optionally37 specified, as in the followingexamples:@Verbatim entry »   (gender masc) »   LU "kus"»   "kus" "kus" "kuss"source-constraint(?IRule ?)»   1 »   "care"2 »   "less"entry »   LU "careless"»   "careless"@End-Verbatim The string @Index{LU (lexical unit}LU is a predefined keyword. It canbe followed by any string of surface characters. It is to be noted thatLU does not count as an entry-feature. Thus, it is not possible todifferentiate lexemes by assigning different strings for LU tootherwise equal lexeme specifications. In future, it will be possibleto define the string of the lexical unit as a function of (one of thewordforms of) the lexeme. For the moment, the present solutionyields maximal freedom to use this option for the purpose it wasintended for, or for other purposes.A third way of dividing lexical space in entries is exemplified byDubois et al. (1971), presented in chapter 2, section 1. They grouptogether items that are morphologically related, even when theirstring is different, and describe them in one entry. One could call thisunit of description a @Index{derivational unit}derivational unit, forwhich the following is a plausible definition: @ItemA derivational unit consists of all lexemes related by a morphologicalrule.@End-Item A problem with this notion is that it does not partition lexical space,because compounds will belong to two derivational units at once.Therefore, it is not possible to use the LU, as introduced above, torepresent derivational units consistently in the case of compounds. InWM, however, there is no reason why we should want to use LU forrepresenting derivational units, because derivational relationsbetween lexemes can be represented in WFRules, and retrieved via theinterface, as illustrated in Chapter 4.Most traditional dictionaries do not take lexical or derivational units,nor formal criteria related to the definition of lexeme as their onlybasis for the division of lexical space into entries. A typical exampleis Hanks (1986). Here, a division in lexical units is taken as a basis,since the noun and verb care are in a single entry, but, contrary toSinclair (1987), there are two entries for the noun match. The basisfor the division is a classification of pairs of senses as either@Index{homonymy}homonymy or @Index{polysemy}polysemy In theinterpretation of Geeraerts (1986), homonymy is "the phenomenonthat several meanings are represented by the same form", andpolysemy "the phenomenon that a form has several meanings".Unsurprisingly, Geeaerts does not support the distinction, and arguesthat it cannot be made precise enough. In lexicographical practice,the distinguishing criterion is usually described as whether twosenses of a word are connected for the speaker or not. Connectedsense pairs are polysemy, and unconnected ones homonymy (e.g.Zgusta (1971)). Often, the 'connection' required for polysemy is takento be etymological, or based on criteria similar to the ones forWM-lexeme distinction.In WM, etymological criteria are judged as irrelevant, and unaided,crude intuitions, too vague to motivate a distinction of WM-lexemesin homonymic entries. This does not imply that semanticconsiderations are considered irrelevant altogether. In section 1.2 ofchapter 1, the examples of kneel and ring were presented, both ofwhich have two past tenses. The most plausible representations ofthese alternative past tenses in a WM-dictionary will be different forkneel and ring. Kneel will be a single lexeme, in the IRule for regularverbs, with an entry- specific spelling rule adding the extra pasttense form. For ring, on the other hand, two entries will be given, onein the IRule for regular verbs, and one in an IRule for strong verbs.The reason for this dissimilar treatment is that for ring, but not forkneel, the difference in past tense corresponds to a readingdistinction.Whether intersubjective motivation for decisions on @Index{readingdistinction}reading distinction is possible, is open to debate. Someresearchers assume that each lexical unit has a specific number ofdiscrete readings, that can be discovered. This point of view isdefended for instance by Cruse (1986). A rather complete set of testsfor reading distinction, determining whether two senses belong tothe same reading or not, is proposed in ten Hacken (1990). There, thefollowing definition of 'reading' is given:  A reading of an lu is a coherent group of senses, the boundaries ofwhich cannot be crossed by a single occurrence of the lu withoutlosing semantic normality.Other researchers, however, claim that the number of readings of alexical unit, and the boundaries between them, cannot be determinedprecisely, e.g. Geeraerts (1986). Their cognitive framework forlexical semantics is difficult to formalize, and for this reason alsodifficult to use in an NLP-environment. Boguraev & Pustejovsky(1990) try to fit in the cognitive view on reading distinction with aformal environment, by developing the notion of coercion.In WM, reading distinction can at present only be represented as faras it coincides with WM-lexeme distinction. With the alternationmechanism, a one-to- many mapping from lexeme to readings can beguaranteed. @Index{alternation in paaradigm}Alternation can beapplied to strings and most features in a straightforward way. Aproblem arises only for features used in the organization ofinflection units. If we want to represent the noun kiss and the verbkiss as a single reading, hence a single lexeme, we have to includethe nominal and verbal wordforms into a single paradigm. Kisses willbe both the plural noun form of kiss and its third person singular verbform. This is a quite counterintuitive representation, but it resultsfrom an assumption that on closer inspection is not very naturaleither. The relation between the noun and the verb kiss is moreadequately rendered by a conversion rule, a WFRule changing onlyfeatures and IRule, not string. In fact, this is exactly what makessyntactic category a good choice as a feature organizing theinflection units.The optimal representation of reading distinction within a singlelexeme is currently subject to discussion. The question is relevantfor WM-dictionaries, because individual readings, rather thanlexemes, participate in wordformation. A characterization ofreadings in terms of @Index{semantic feature}semantic features isnot envisaged. It would pre-empt the semantic theory in a wayseriously jeopardizing usability of the dictionary by a broad range ofclient applications. Furthermore, any characterization in terms ofentry features should be avoided, in order to maintain therepresentation of the lexeme. Rather, a lexeme will be accompaniedby a list of readings, having indexes to which entry-constraints inWFRules can refer. We expect to extend the WM-formalism as soon asthe requirements of such a representation have emerged.@SubSection{Coverage Issues}@Index{coverage}In the construction of a dictionary, there are two possible reasonsfor not listing an item. First, it can be considered not to belong to thepart of the language covered by the dictionary, for instance becauseit is rare or obsolete. Secondly, it can be judged not to be a lexicalunit, but instead to be the result of the application of a rule. Formany dictionaries, their publication as a book imposes constraints ontheir size, influencing coverage decisions. Considerations of this kindare much less important in a WM-dictionary. The available manpowerremains a possible bottleneck, of course, but it is alleviated by thepossibility of importing data from machine-readable dictionaries.Moreover, the effort spent on constructing a WM- dictionary is anefficient investment in view of the reusability of the result.Therefore, WM has been designed for the management of dictionarieswith a fairly complete coverage of the language.The decision whether to list an item in the dictionary or suppose it tobe generated by rules is a linguistic one. Three distinct classes canbe represented in a WM- dictionary: @ItemSimple  entries,  associated with an  inflection  rule only.@End-Item @Item @Index{lexicalization}Lexicalized products of wordformation,connected to a wordformation rule and the entry or entries theyoriginated from. @End-Item @ItemRegular products of wordformation, represented by the WFRules andthe component parts only.@End-Item A theory supporting the decisions on the classification of individualitems is currently under development. Part of it is presented in tenHacken (1992).The WM-formalism is based on coverage of @Index{word}words, i.e.strings of characters enclosed in spaces or punctuation marks. Since<space> is included in the character sets of any WM-database bydefault, the WM-coverage extends into the domain of multi-wordunits as well. We have shown, in section 1.3 of chapter 4, how Englishcompounds like colour blind can be treated, and in the same waymulti- word units, e.g. by and large, can be entered, provided theyconstitute non-separable strings.A problem that has not yet been discussed arises when@Index{inflection, stem-internal}inflectional affixes occur withinthe stem, as in the following examples from French:38@Verbatim singular         pluraltimbre-poste     timbres-poste      ('stamp')mouvement syndical                  mouvements syndicaux('trade union movement')@End-Verbatim A first point to note here is that if timbre-poste is the stemresulting from a @Index{compounding} rule, i.e. the target of the entryconstraint, it will no longer be possible to add the plural ending -s inthe correct position by means of an inflection rule. Aftertimbre-poste has become a formative, its string can only beinternally modified by spelling rules. The alternative is to haveinflection rules perform the concatenation of the elements, and letthe wordformation rule produce a list of formatives instead of asingle stem. This is a rather complex procedure, driving theexpressiveness of WM-syntax to its very limits. The WFRule involvedis given in Fig. 5.3.                @Figure{ "WFRule for timbre-poste." | "163" | 401 | 382 }@Index{WFRule}In the source section of the rule, stems may be taken from theinflection part of the database, and other elements are WFFormatives.The IFormatives involved are further specified in the source sectionof the entry constraint. In the target section of the rule, the fiveelements are specified as IFormatives, input to a special IRule forcompounds. Although the string of each of the five elements is thesame in source and target, each source element is distinct from itscorresponding target element. This means that in the inflection partof the database, an underspecified IFormative will have to bedeclared for each of these elements. The target section of the entryconstraint, rather than concatenating the elements into a string,lists them for further processing by the IRule. The IRule forcompounds will contain formulae like the following:word-forms@Verbatim (ICat head) »   (ICat bound-element)(number singular) »(ICat linking-element) »   (ICat modifier)(ICat head) »    (ICat bound-element)(number plural) »(ICat linking-element) »   (ICat modifier)@End-Verbatim Even with the extension mentioned above, the coverage of WM issmaller than desirable for a complete dictionary for NLP. Currently,@Index{Phrase Manager}Phrase Manager (PM) is under development,that is meant to cover additional discrepancies between lexical unitsand text words. One component of PM covers discontinuousmulti-word units. The elements of a @Index{discontinuousmulti-word unit}discontinuous multi-word unit can be separated byitems not belonging to it, but they have to be described together,because they have a different meaning, or no meaning at all, inisolation. Examples are look up and take for granted, as in thefollowing sentences:   @Item If you do not know a word, you can look it up in a  dictionary. @End-Item     @Item Many people in Switzerland take their prosperity for granted. @End-Item A second PM component can be used to recognize @Index{periphrasticinflection}periphrastic inflection, such as the@Index{auxiliaries}auxiliaries in the following sentences:    @ItemThey have always taken their prosperity for granted.  @End-Item  @Item It will hardly have been discussed by the turn of the  century. @End-Item An English PM-database will analyze the italicized verbs as theperfect of take and the future perfect of the passive of discuss. Thisanalysis precedes the recognition of discontinuous multi-word units,to yield the perfect of take for granted as the result of analysis ofthe verbal expression in the first example.A third component will cover cases where a text word is composed ofmore than one wordform. Examples are Italian andarsene ('go away'),consisting of andar(e) ('go'), and the @Index{clitic}clitic pronouns se('oneself') and ne ('of it'); Latin virumque39, where -que ('and') isclitically attached to virum ('manaccusative'); and Danish huset ('thehouse'), where, at least in some analyses, the definite article -et isclitically attached to hus ('house').PM is intended to cooperate with WM. After breaking up text wordswhere necessary, PM will pass the wordforms to WM, and receive ananalysis, used in the recognition of periphrastic inflection anddiscontinuous multi-word units.@SubSection{Some Representational Issues}In this section, two properties of WM, bearing on the representationof information and not discussed in the preceding chapters, will bepresented. The first concerns the relation between features, thesecond the sort order of lexemes.To a limited extent, implication relations between @Index{featuredependencies}features can be expressed in WM. They can be used toprevent incomplete specifications in the dictionary. At the moment,the only type of implication that can be stated is the following: @ItemIf attribute A1 has the value V1, A2 the value V2, … and An the valueVn, then the attributes X2, X3, … Xn must be specified.@End-Item Dependency statements apply to lexemes. As a consequence, allattributes and values in the statements are entry features. Thus, it isnot possible to express generalizations like the following: @ItemIf the category of an item is noun, then it must have a numberspecification.@End-Item @ItemIf the mode of a verb is indicative, it must have a tense specification.@End-Item Since number, tense, and mode are inflectional categories, ratherthan entry features, these statements are not correct as featuredependency statements. The item in the first statement is a lexeme,which is not specified for number. Similarly, a verb in the secondstatement is to be read as 'a lexeme with (cat verb)' so that theproblem is clear. The problem is not so serious, however, since theabove generalizations concern the task of the linguist writing arestricted number of rules, rather than the task of the lexicographer,encoding large numbers of entries.A second consequence of the application to lexemes is that whetherindividual formatives with A1 = V1 are marked for A2 etc. isirrelevant. Thus, it is possible to make the following generalizationfor a language like French: @Item If the category of an item is noun, then it must have a@Index{gender}gender specification.@End-Item Unlike in Italian, the two genders in French have no influence on theinflectional endings of the nouns. Independent of gender, the singularending is zero, and the plural ending -s (with a few spelling rules). Itis quite natural to include these endings in an inflection unit markedby (cat noun), without assigning them a gender. Such a representationdoes not violate the above condition, because it is not applied atformative level, but only to lexemes. The condition will influence thedescription only in the following sense. Nouns designating animatebeings have a gender based on natural gender. Many of these nouns donot have distinct forms for the two genders:@Verbatim masculine        femininechien            chienne        ('dog')enfant           enfant         ('child')élève            élève          ('pupil')@End-Verbatim Enfant and élève cannot be represented as single lexemes,underspecified for gender if the gender dependency has been stated.Instead, they can be assigned a special value, e.g. (gender animate), orone can be derived from the other by a WFRule. Thus, the supportoffered to the lexicographer by dependency constraints has a price inthat it influences linguistic analysis.Feature dependencies are expressed in the @Index{feature dependencieswindow}feature dependency window. Their syntax is simple. Thecondition that nouns be specified for gender can be formulated asfollows:@Verbatim (cat noun) »   demands »   gender@End-Verbatim The issue of @Index{alphabetic order }alphabetical order has beendiscussed to some extent in section 1.2.3 of chapter 3, where theconcepts of primary and secondary sort order have been introduced. Inthe general entity browser, lexemes are represented by their lexemeidentifier, and presented in alphabetic order as defined in the surfacecharacter set window. Separate functions could be added to representcitation forms instead of lexeme identifiers (especially relevant ifthere are more than one citation forms for a single lexeme), orlexical forms in alphabetic order. As shown in section 1.1, citationforms are accessible via the lexeme browser. There, however,alphabetic order is irrelevant.As mentioned in section 1.3 of chapter 4, <space> belongs to bothcharacter sets by default. In the sort order, it is ignored, so thatcolour blind is ordered between colourable and coloured, followingcommon practice. In future, it will be possible to assign a similarstatus to user-defined characters, e.g. the hyphen in colour-blind.In some languages, tradition has imposed a number of peculiarities inthe sort order. In German, the @Index{umlaut}umlauted characters ä,ö, and ü have also been written as ae, oe, and ue, respectively. In thecomputer age, this habit has gained some new popularity, for obviousreasons. In some lists, the umlauted characters are also interpretedas ae, oe, and ue in alphabetic order. Thus, in the German yellowpages, the following order appears:   @Verbatim  Adressenverlage  Ärzte  Agenturen@End-Verbatim In dictionaries, and the Swiss telephone directory, however, adifferent sort order is used, as in the following:   @Verbatim  Grumbt  Grun  Grün  Grunauer@End-Verbatim A similar situation exists in Dutch for ij. In encyclopaedias, it isordered as equivalent to y, but in dictionaries as the combination i j,yielding the ordering illustrated in the left and right columns below,respectively:  @Verbatim  Yellowstone                iguanodon  IJsselmeer                 IJsselmeer  Yucatan                    ik@End-Verbatim In Spanish dictionaries, yet another variant of sort orderidiosyncrasies occurs. The ch and ll are ordered between c and d, andbetween l and m, respectively. They are not considered asalternatives of an existing character, but as characters of their own.If nothing special is undertaken, Dutch ij will be ordered as in theright column above, and Spanish ch and ll as sequences of twocharacters. For German umlauted characters to be ordered as indictionaries, they have to be declared as variants of theirnon-umlauted counterparts. The example given above, from the Baseltelephone directory, shows how ü is treated as an equivalent of u(primary sort order), unless the u/ü- difference constitutes the onlydifference between two strings. In those cases, ü follows u(secondary sort order).To achieve the alternative order in each of these three cases of sortorder idiosyncracy, the @Index{sequence sort order}sequence sortorder section of the @Index{surface character set window}surfacecharacter set window can be used. It contains statements meaningthe following: @ItemThe string <string1> is ordered as if it were <string 2>.@End-Item Each of these statements appears on a new line, and the two stringsare separated by a space. At present, only for the cases where<string1> is a single character, the feature has been implemented.Thus, for our German examples the following statements can be made:@Verbatim sequence-sort-order ; Germanä aeö oeü ue@End-Verbatim These statements define ä as a variant of ae, having the sameprimary sort order. At the same time they determine secondary sortorder such that Ärzte precedes Aerzte. It is to be noted that thecharacter sort order section also has the function of defining allcharacters that may appear in the strings of the database. Therefore,the umlauted characters ä, ö, and ü have to be declared in this sectionas well. The place in the character sort order where they are declaredis irrelevant, because their alphabetic position is determined in thesequence sort order. A perspicuous way of representing this is toinclude them on a line like the following, at the end of the charactersort order section:@Verbatim ä ö ü ; only declaration, sort order as sequence@End-Verbatim In future it will also be possible to define Dutch ij as a variantspelling of y, as far as sort order is concerned, by the followingstatement:@Verbatim sequence-sort-order ; Dutchij y@End-Verbatim At present, the syntax allows these statements to be made, but theyare ignored in compilation. The ordering of ch and ll in Spanish can beachieved as well when the above type of statements will beinterpreted, by including a dummy character in their correct position,and defining ch and ll as their sequence sort order variants, as in thefollowing:40@Verbatim character-sort-order ; Spanishabc@d…l#m…sequence-sort-orderch @ll #@End-Verbatim @Section{Morphological Theories}In this section, the WM-model of morphology is compared with anumber of morphological theories. In section 2.1, two additionalfeatures of WM are introduced, which permit a theoreticallywell-founded account of items that play a role in wordformation,even though they do not exist as lexemes themselves. In section 2.2, anumber of generalizations that have played a role in recentmorphological discussions are considered.@SubSection{Possible Words and Bound Stems}Inflection rules in WM concatenate formatives into strings andcombine the features associated with the formatives. A wordformproduced by an inflection rule generally consists of one stem, withany number of prefixes and / or suffixes. Wordformation rules in WMcombine one or more stems, with any number of prefixes and / orsuffixes, to produce an inflection stem. Any change in the string of aformative must be taken care of by spelling rules.Considered in these terms, the 'WM-model of morphology' resembles@Index{word-based morphology}word-based morphology, as presentedby Aronoff (1976), quite closely. According to Aronoff, affixation isbasically the concatenation of affixes to an existing word. Anydeviance in form is accounted for by adjustment rules. In view of thisresemblance, we will discuss in this section a number of phenomenathat have been raised in the literature as problems for this approach,and show how various solutions to these problems can beimplemented in WM.@Index{possible word}First, there are 'families' of words that seemto be related by derivational rules, but for which the common baseform is missing. Thus, besides the noun retribution and the adjectivesretributive and retributory, we would expect a verb *retribute,which, however, does not exist. Aronoff (1976) treats these cases asfollows. One of the existing forms is the basis. For the case at hand,he argues that it is the noun in -ion that should be taken as such,because for stems like retribut-, adjectives and verbs may bemissing, but the noun is virtually always there. Retributive is derivedfrom retribution by first truncating -ion, then attaching the suffix-ive. In WM, the @Index{truncation}truncation can be reflected by aspelling rule like the following, applying to the WFRule forsuffixation:@Verbatim "(.*)ion/\1" »   "ive|ory"@End-Verbatim A solution by truncation is not very elegant, but it definitely solvesthe problem of the status of *retribute: it has no status at all. Inearly lexicalist approaches, e.g. Halle (1973), a feature[±@Index{lexical insertion}lexical insertion] is used to distinguishnon-existing words like *retribute from actually occurring words. Byits presence in the lexicon, it can be a base for the derivation ofretribution, retributive, and retributory. In order to implement such asolution in WM, retribute can be added in an inflection window as a@Index{fictional entry}fictional entry. Fictional entries have thesame status as normal entries, except that they are marked.Interfaces can be equiped with functions differentiating fictionalentries from normal ones, e.g. suppressing them. The following is aspecification of retribute as a fictional entry:@Verbatim fictional-entry»   "retribute" "retribute" "retribut"@End-Verbatim The use of the feature [-lexical insertion] in the lexicon has beenseverely criticized. Aronoff's word- based theory of morphology is areaction against this aspect of Halle's model. Jackendoff (1975)proposes @Index{full entry theory }full entry theory as a solution. Asa consequence of the use of [-lexical insertion], the appearance of theword retribute would be a simplification, rather than an extension ofthe lexicon. In order to avoid this, Jackendoff proposes to fullyspecify all entries in the lexicon, and adapt the measure of the sizeof the lexicon so that redundant information is not counted. Thistreatment of redundant information seems to correspond with whathappens in the compilation step in WM, to some extent. However, forthe entry for retribution it implies a reference to the rule for-ion-insertion, without a reference to the base the suffix is attachedto. This cannot be reflected in WM directly. Similarly, the notion of@Index{constellation}constellation, introduced by Williams (1981) torepresent links between two words without entailing that one isderived from the other cannot be mirrored directly in WM.41A second type of problem for word-based morphology is illustrated byItalian immancabile ('certain'). This word is composed of the negativeprefix in-, the stem of the verb mancare ('fail'), and the suffix -abile(cf. able). Since neither mancabile, nor immancare are Italian words,a strictly word-based analysis is forced to assume@Index{parasynthetic affixation}parasynthetic affixation, where bothaffixes are added to the stem at the same time. As argued by Scalise(1984), among others, such an analysis has the disadvantage ofviolating an otherwise unchallenged generalization overmorphological rules, the @Index{binary branching hypothesis}binarybranching hypothesis. Furthermore, the two affixes have to occur inother rules already, where -abile is suffixed to a verb to form anadjective, and in- is prefixed to an adjective and changed into im- infront of an initial m of the stem. Adding a rule where both affixes areattached at the same time creates redundancy. The solution proposedby Scalise is to allow affixation to possible, non-existing words, aswell as to existing words. Mancabile is a @Index{possibleword}possible word, but immancare is not, because in- in therelevant sense does not attach to verbs. In WM, this can be renderedby assigning the intermediate form mancabile the status of a@Index{fictional entry }fictional entry in the entry constraint where-abile is attached to mancare, as in the following example:@Verbatim source-constraint(?IRule ?)»   1 »   "manc"fictional-entry»   "mancabile"@End-Verbatim @Index{neoclassical compounding}A third class of problems containsitems like anthropomorphic and morphological. The element morphodoes not occur independently as a word. Therefore, elements likemorpho have sometimes been labeled affixes. Thus, Williams (1981)calls hydro in hydroelectricity a prefix. Hanks (1986) has separateentries for morpho-, and -morph. Since it is not possible to assignthese elements a single label prefix or suffix, an affixal analysis isnot very attractive. Furthermore, such an analysis entails that itemslike morpheme or dehydration consist of affixes only. Because of thelatter, a WM- analysis where morpho and hydro are derivationalaffixes, i.e. fully specified WFFormatives, is impossible. Each WFRuleshould contain at least one slot for an underspecified formative.Scalise (1984) argues that francophile is a compound, and calls itscomponents @Index{bound stems}bound stems. The notion of boundstem goes back to Bloomfield (1933), who introduced it as a label forelements that do not occur as independent words, but are stemsrather than affixes. Bloomfield distinguishes two layers of lexicalelements, learned and native morphemes. In English, learnedmorphemes have a Latin or Greek origin. They may be words, e.g.mature, affixes, e.g. -ity, or bound stems. The only way to determinewhether an element belongs to the learned or the native stock ofmorphemes is by considering its distribution. Bound stems have tocombine with affixes or other bound stems to form words. Learnedbound stems like morpho and hydro can only combine with otherlearned morphemes.In WM, this analysis can be encoded when bound stems are@Index{underspecified WFFormatives}underspecified WFFormatives.The specification and use of underspecified WFFormatives isillustrated in Fig. 5.4 - 5.5. Fig. 5.4 gives the underspecifiedWFFormative window, and Fig. 5.5 the WFRule for morphology, in ananalysis where it consists of two bound stems and an affix.                @Figure{ "Underspecified WFFormative window." | "164" | 376 | 103 }@Index{underspecified WFFormative window}                @Figure{"WFRule for morphology." | "165" | 382 | 274 }"@Index{WFRule}The underspecified WFFormative window is very similar to anunderspecified IFormative window. Both of them permit featurespecification of the formatives, but here this possibility has not beenused. In the WFRule window, underspecified WFFormatives behave asstems, but without an IRule specification. Since individual stems areonly introduced in the entry constraints, their lexical and surfacestrings have to be specified there.There are several disadvantages connected to a treatment asillustrated in the figures. If all lexemes consisting of two stems anda suffix are formed by WFRules of this type, there will be a largenumber of WFRules, because the target IRule has to be specified inthe rule. Anthropomorphic will require a separate RWFRule, becauseit is an adjective. In general, the number of WFRules of this type willbe the number of relevant IRules, multiplied by the number ofcombinations of the labels stem and affix that occur.A second disadvantage of this treatment is that morphology andmorphological cannot be related directly. Their common basemorpholog(o) has no status at all. One way of relating the two wordsis to derive one from the other, e.g. by removing the suffix -y whenattaching -ical.42 This corresponds to Aronoff's treatment ofretribution and retributive, sketched above. A more attractivesolution is to generate morphologo as a @Index{fictionalentry}fictional entry, resulting from compounding of bound stems.This is similar to the use of fictional entries to represent theintermediate stage in the derivation of immancabile. Either solutionhas the additional advantage of restoring binary branching.A treatment where morphologo is a fictional entry, produced by aWFRule from two underspecified WFFormatives could proceed asfollows. In the inflection tree, a category-free node, e.g. (catneutral), is created as an inflection unit, containing a separate IRulefor items like morphologo. It has a single wordform, consisting of thestem only, and no entries, because they will be provided by WFRules.Besides this IRule, the inflection unit contains an underspecifiedIFormative window for stems. In wordformation, neoclassicalcompounding uses this IRule as a target, and produces fictionalentries only. In this way, the specification of the target for an IRulethat is actually linked to the suffix, can be avoided. Instead, separatederivation rules will take morphologo as input, and add suffixes like-ical and -y to them.A problem for such a rule system is that for anthropic andanthropomorphic, duplicate rules for -ic-affixation will benecessary. Anthropo is a WFFormative, whereas anthropomorpho is a(fictional) IFormative. This problem can be solved by defininganthropo as a fictional entry itself, i.e. as an entry of the IRule for(cat neutral). This solution has two additional advantages. First, thelexical and surface variants of bound stems can be declared once,instead of in each individual entry constraint where they occur.Secondly, cases where learned stems combine with nativemorphemes, e.g. electroshock, can be handled in a straightforwardway.@SubSection{Some Morphological Generalizations}In this section, we will discuss a number of generalizations that havebeen formulated in morphological theory. The discussion will showhow these generalizations can be expressed in the WM-formalism.It has long been known that in most English compounds, allpropagation of features is from the righthand element to theresulting compound. Bloomfield (1933) calls this element the head.Allen (1978) has extended this generalization to affixation. In her@Index{IS A Condition}IS A Condition, she states that for allmorphological structures [X Y]Z, Z IS A Y. For affixes, this impliesthat they have syntactic category and other features. Whereas forAronoff (1976), -ness is a suffix producing nouns, for Allen -ness isa noun, and at the same time a suffix. Allen's generalization has beenrenamed @Index{Righthand Head Rule}Righthand Head Rule (RHR) byWilliams (1981).In WM WFRules, features like (cat noun), and IRule specificationcannot be propagated from fully specified WFFormatives. In theWFRules of Chapter 4, they are specified in the rule, similarly toAronoff's analysis. For a WFFormative to have (cat noun), it must beunderspecified. The IRule information can only be propagated if theaffix belongs to an IRule. It would have to be a @Index{fictionalentry}fictional entry, instead of a WFFormative.The generalization that all propagation is from the righthand elementhas several counterexamples. Allen (1978) discusses headlesscompounds like redcap (not a cap, but a person). She concludes, ratherunconvincingly, that this type of compounding is not productive.Another problem arises for prefixes like en- in enrich, because alefthand element causes the change from adjective to verb. InRomance languages, compounding is left-headed, as shown by Selkirk(1982) for French, and by Scalise (1984) for Italian, but derivation ismostly right- headed. Thus, Italian nave passegeri ('passenger ship')is singular and feminine, like nave, but unlike the plural andmasculine passegeri. Nevertheless, Di Sciullo & Williams (1987)maintain the RHR as a law applying to all of morphology. Most of thecounterexamples are attributed to the domain of syntactic words, notgoverned by morphological rules.Encoding the RHR in WM does not only require all affixes to befictional entries, as we saw above, but also the WFRules have to becollapsed into a single one. In this WFRule, all target information ispropagated from the righthand element of the source, and the sourcespecification allows for any two elements to be combined. Thoughpossible from the point of view of the WM- formalism, this is not adesirable way of formulating morphological knowledge. First of all,the generalization is not correct. For counterexamples, separate ruleshave to be written. More importantly, the RHR is a generalization overrules to be written by the linguist, rather than over entries to beencoded by the lexicographer. According to the philosophy underlyingWM, this kind of information can be used by the linguist while writingrules, but should not necessarily be expressed in the rulesthemselves.A second generalization we will discuss is the @Index{Affix OrderingGeneralization}Affix Ordering Generalization (AOG) of Siegel (1974).Siegel observes that English derivational affixes can be divided intotwo classes, according to three coinciding properties of the rulesattaching them to stems. First, some affixes attract stress, whereasothers do not. Thus, there are two nominalizations of hideous:hideousness and hideosity. In hideousness, the stem is phonologicallynot affected by affixation. In hideosity, however, stress moves to thelast syllable of the stem because of affixation. Affixes like -ness arecalled neutral or @Index{Class II affixes}Class II affixes, and affixeslike -ity nonneutral or @Index{Class I affixes}Class I affixes. Asecond property is assimilation of the affix under the influence ofthe stem (sandhi). Thus, the two opposites of logical, illogical andnonlogical, enable us to label in- as a Class I and non- as a Class IIaffix. Finally, stems to which an affix has been attached can be inputto affixation again, provided that the affix is of a higher or equalclass than the one attached first. Having found that -ness is a ClassII affix, fearlessness and tendernessless allow us to classify -lessas a Class II affix as well. The Class I status of -ity is thenconfirmed by activityless and the impossibility of *fearlessity.Siegel explains these properties in terms of boundaries. Followingthe notation of Chomsky & Halle (1968), she uses + and #, where #designates a stronger boundary than +. Class I affixes only attach tostrings surrounded by + boundaries, and the exterior boundary ofClass II affixes is a # boundary. Stress assignment takes into accountthe string included between # boundaries, i.e. without Class IIaffixes. Once the boundary has been raised from + to #, Class Iaffixation is no longer possible.Selkirk (1982) replaces the boundary-based account of Siegel by onebased on bar levels. She extends the X-bar theory, as commonly usedin syntax, to morphology. In syntax, usually (e.g. by Chomsky (1981))three levels are distinguished, the lowest of which is the word, X0.Selkirk introduces the X-1 level for roots. Class I affixes attach toroots only, Class II affixes to words. A separate rewriting rule,@Verbatim Word Æ Root@End-Verbatim ensures the communication between roots and words.A problem for the AOG observed by Selkirk is the existence ofaffixes, e.g. un-, that seem to ignore the boundary or bar level of thestem they attach to. Since -ful, like -less, is a Class II affix, un- inunfearful must be a Class II affix as well. It can only attach toadjectives, not to the noun fear, so that the only possible structure is[un [fear ful]]. In ungrammaticality, however, the obligatoryattachment of un- to adjectives imposes a structure [un [grammaticality]]. Here the Class I affix -ity is attached after un- prefixation, sothat un- must be a Class I affix. Selkirk opens the way for affixes tobe class-neutral in order to account for these facts.In WM, the AOG can, in principle, be implemented either in theboundary-based account or in Selkirk's bar-level based account. Theintroduction of boundaries in the string has the disadvantage ofrequiring spelling rules to manage them, and they decrease easyreadability of strings. Therefore, we will outline here how the AOGcan be introduced by formulating it in terms of bar levels, encoded infeatures. We restrict ourselves to a minimal representation of theAOG, without adopting the rest of Selkirk's framework.As features for bar levels we will assume (level word) and (levelroot). In WFRules for affixation, these features can be used asrestrictive conditions for the selection of stems in the source, andspecified as a property of the output in the target. The only case thatshould be excluded in wordformation is that a Class I affix isattached to a (level word) entry. Class I affixes should therefore have(level root) as a condition in the source of their WFRule, and Class IIaffixes (level word) in the target. For affixes that do not belong toeither class, the features can be left out altogether. Optimal use ofthe features is ensured if each affix has its own WFRule. In this way,a side effect of the lexicographer's job of entering lexemes will bethat for each affix it is tested whether the linguist's assignment ofthese features has been correct. If it is incorrect, certain entriescannot be specified. A prerequisite for this way of rendering thedistinction between Class I and Class II affixes is that simpleentries have (level root). In the lexicographer's interface, this can beimplemented so that the user does not notice it. Of course, assigning(level root) to lexemes goes counter to Selkirk's theory, whereinflection is added to words only, after wordformation has applied.Modifying the specification so as to include this part of Selkirk'stheory, however, implies going against the spirit of the WM-model,where wordformation applies to existing lexemes.One of the basic distinctions in the WM-model of morphology is theone between inflection and wordformation. Yet, this distinction hasnot remained unchallenged. In American structuralism, e.g. Bloomfield(1933), the dictionary has generally been taken to consist ofwordforms, rather than lexemes. This point of view has been takenover by some transformational grammarians, e.g. Jackendoff (1975),whereas others, e.g. Aronoff (1976), assume that inflection is asyntactic rather than a lexical phenomenon. Most authors who assumea @Index{wordform dictionary}wordform dictionary, still maintain adistinction between inflection and wordformation. Williams (1981)and Di Sciullo & Williams (1987), however, propose to abandon thisdistinction altogether. They only distinguish affixation andcompounding. Scalise (1984) raises a number of arguments againstthis decision.The main difference between inflection and wordformation is theparadigmatic nature of inflection, absent in wordformation. InWM-syntax, this is reflected in the form of IRules as opposed toWFRules. If one were to follow Williams (1981) in rejecting thedistinction, one could either not use WFRules, or not use the paradigmin the IRules.Denying the absence of a paradigm in derivation leads to problems inthe representation in WM, because inflection cannot be performedrecursively. Even if we ignore the non-existence of many regularlyderived forms, e.g. *ungood, or treat them as deleted-forms, itremains a problem that all inflected forms of derived lexemes wouldhave to be included in the paradigm. Thus, if the paradigm of theItalian verb dormire ('sleep') included its diminutive dormicchiare('doze'), it would not be possible to refer to the -are-verbs for theinflection of dormicchiare, but its ca. 60 forms would have to beincluded in the paradigm of dormire as well.Using WFRules for inflection is much easier than the reverse, becausethe formative-combining properties of IRules constitute a subset ofthe possibilities offered by WFRules. The inflection window wouldthen contain a single IRule, having only fictional entries representinguninflected stems.43 The obvious disadvantage of such an approach isthat paradigms remain unexpressed. Therefore, the lexicographerwould have to enter each individual wordform, instead of assigninglexemes to IRules. This constitutes a waste of effort, and a source ofpossible errors, as well as an incomplete account of morphologicalknowledge.We have seen that for some generalizations and models currentlyused in linguistic research, it is difficult to implement them in WM.We trust, however, that we have shown that this is not a flaw of WM,but rather results from the fact that linguists do not always takeinto consideration the full impact of their theories on the types ofdictionaries consequently produced.ReferencesAllen,     Margaret     Reece    (1978),    Morphological  Investigations,   Unpublished  Doctoral   Dissertation,  University of Connecticut.Aronoff,   Mark  (1976),  Word  Formation  in  Generative  Grammar, MIT Press, Cambridge (Mass.).Barton  Jr., G. Edward; Berwick, Robert C. & Ristad, Eric  Sven   (1987),  Computational  Complexity  and  Natural  Language, MIT Press, Cambridge (Mass.).Bloomfield,  Leonard  (1933), Language,  George  Allen  &  Unwin, London etc. (1st ed. 1935, 14th impr. 1979).Boguraev, Bran & Briscoe, Ted (ed.) (1989), Computational  Lexicography for Natural Language Processing,  Longman,  London and New York.Boguraev,  Branimir & Pustejovsky, James (1990), 'Lexical  Ambiguity  and The Role of Knowledge Representation  in  Lexicon Design', in Karlgren (1990), Vol. 2, p. 36-41.Bopp,    Stephan   (1992),   Computerimplementation   der  italienischen  Flexions-  und  Wortbildungsmorphologie,  Olms Verlag, Hildesheim.Cahill,  Lynne  (1989),  'Arabic verbal  inflection',  in  Evans & Gazdar (1990), p. 106-108.Celex News, Centre for Lexical Information, University of  Nijmegen, from December 1986.Chomsky,  Noam & Halle, Morris (1968), The Sound  Pattern  of English, Harper & Row, New York.Chomsky,   Noam  (1981),  Lectures  on  Governement   and  Binding,  Foris, Dordrecht.Cruse,   D.A.   (1986),   Lexical  Semantics,   Cambridge  University Press.Dardano,  Maurizio  & Trifone, Pietro (1985),  La  Lingua  Italiana:   Una   grammatica   completa   e   rigorosa,  Zanichelli, Bologna.Di  Sciullo, Anna Maria & Williams, Edwin (1987), On  the  Definition of Word, MIT Press, Cambridge (Mass.) etc.Domenig,  Marc  (1989), Word Manager: A  system  for  the  Specification,  Use, and Maintenance  of  Morphological  Knowledge, Habilitationsschrift, Universität Zürich.Drosdowski,  Günther  (ed.) (1984), Duden  Grammatik  der  deutschen Gegenwartsprache, Bibliographisches Institut,  Mannheim, 4th edition.Dubois,  Jean;  Lagane, René; Niobey,  Georges;  Casalis,  Didier; Casalis, Jacqueline & Meschonnic, Henri (1971),  Dictionnaire du français contemporain, Larousse, Paris.Emele,  Martin  (1988), 'Überlegungen zu einer  Two-level  Morphologie für das Deutsche', in Trost (1988), p. 156-  163.Evans,  Roger  &  Gazdar, Gerald (ed.) (1990),  The  DATR  Papers,   Cognitive   Science   Research   Paper   139,  University of Sussex, Brighton.Geeraerts, Dirk (1986), Woordbetekenis, een overzicht van  de lexicale semantiek, Acco, Leuven/Amersfoort.ten  Hacken, Pius (1990), 'Reading Distinction in MT', in  Karlgren (1990), Vol. 2, p. 162-166.ten   Hacken,   Pius  (1992),  'On  the   Definition   of  Compounding', to appear in the proceedings of the Fifth  Euralex International Congress, Tampere.Halle,  Morris (1973), 'Prolegomena to a Theory  of  Word  Formation', Linguistic Inquiry 4, p.  3-16.Hanks,   Patrick   (ed.)  (1986),  The  Collins   English  Dictionary, second edition, Collins, London & Glasgow.Jackendoff,  Ray S. (1975), 'Morphological  and  Semantic  Regularities in the Lexicon', Language 51, pp. 639-671.Karlgren,  Hans (ed.) (1990), Coling-90: Papers Presented  to  the  13th  Conference on Computational Linguistics,  Helsinki University.Karttunen,  Lauri  (ed.)  (1983),  'KIMMO:  A  Two  Level  Morphological Analyzer', in Texas Linguistic Forum  22,  Department of Linguistics, University of Texas, Austin,  p. 163-278.Karttunen,  Lauri & Wittenburg, Kent (1983), 'A Two-Level  Morphological  Analysis  of  English',   in   Karttunen  (1983), p. 218-228.Kataja,  Laura & Koskenniemi, Kimmo (1988), 'Finite-state  Description  of  Semitic Morphology: A  Case  Study  of  Ancient Akkadian', in Vargha (1988), p. 313-315.Koskenniemi,   Kimmo  (1983),  Two-Level  Morphology:   A  General  Computational Model for Word-Form  Recognition  and  Production, University of Helsinki, Department  of  General Linguistics Publications No. 11.Koskenniemi,   Kimmo   &  Church,  Kenneth   W.   (1988),  'Complexity,  two-level  morphology  and  Finnish',  in  Vargha (1988), p. 335-340.LDOCE: Longman's Dictionary Of Contemporary English,  New  edition, Longman, Harlow (Essex), 1987.Levi,  Judith  N.  (1978), The syntax  and  semantics  of  complex nominals, Academic Press, New York.Marchand,  Hans  (1969),  The  Categories  and  Types  of  Present-Day   English  Word-formation:  A   Synchronic-  Diachronic Approach, Beck, München, 2nd edition.Matthews, Peter H. (1974), Morphology: An Introduction to  the  Theory  of  Word  Structure, Cambridge  University  Press, Cambridge.Reinhard,  Sabine  &  Gibbon,  Dafydd  (1991),  'Prosodic  Inheritance  and  Morphological  Generalisations',   in  Proceedings  of  the Fifth Conference of  the  European  Chapter    of    the   Association   of   Computational  Linguistics, p. 131-136.Scalise,  Sergio  (1984), Generative  Morphology,  Foris,  Dordrecht etc. (2nd ed. 1986).Selkirk,  Elisabeth O. (1982), The Syntax of  Words,  MIT  Press, Cambridge (Mass.) etc.Shieber,   Stuart  M.  (1985),  'Criteria  for  designing  computer   facilities  for  linguistic  analysis',   in  Linguistics 23, p. 189-211.Siegel,  Dorothy  (1974), Topics in  English  Morphology,  PhD. dissertation, MIT, published by Garland Publishing  Inc., New York & London, 1979.Sinclair,  John  (ed.)  (1987), Collins  COBUILD  English  Language Dictionary, Collins, London & Glasgow.Sterkenburg,  P.G.J.  van  &  Pijnenburg,  W.J.J.  (eds.)  (1984),  Groot  woordenboek van hedendaags  Nederlands,  Van Dale Lexicografie, Utrecht/Antwerpen.Trost, Harald (ed.) (1988), 4. Österreichische Artificial-  Intelligence-Tagung;  Wiener  Workshop  Wissensbasierte  Sprachverarbeitung;  Wien,  August  1988;  Proceedings,  Springer Verlag, Berlin etc.Vargha,  Dénes (ed.) (1988), Coling Budapest: Proceedings  of  the  12th International Conference on Computational  Linguistics,  (2  vol.), John von Neumann  Society  for  Computing Sciences.Williams, Edwin (1981), 'On the notions Lexically related  and  Head of a Word', in Linguistic Inquiry 12, p. 245-  274.Zehnder,  Carl  August  (1985),  Informationssysteme  und  Datenbanken,  Verlag  der  Fachvereine,   Zürich,   3rd  edition.Zgusta,   Ladislav   (1971),  Manual   of   Lexicography,  Academia, Praha & Mouton, Den Haag.__________________1All reference to strings starting with section are to bechecked in the end. Description, final check2Typographical convention to be decided on. Layout3In final layout, a hard page-break should be added at  aconvenient point. Layout4The  fact that German nouns are written with an  initialcapital letter is irrelevant here. It is presupposed thatthis generalization is expressed elsewhere.5In final layout, a hard page-break should be added at  aconvenient point. Layout6Font for NP and PSPACE to be decided upon. Layout7The SAT problem can be formulated as "given a clause  ofpropositional logic consisting of proposition  constants,negation, conjunction, and disjunction, is there a  truthvalue  assignment function so that the entire  clause  istrue ?".8The  problem  of FSA intersection can be  formulated  as"given  a  number of finite state automata,  is  there  astring accepted by all of them ?".9The machine used was a Macintosh Quadra 700.10The  characters  {  and  }  are  to  be  used  in   therepresentation of character subsets11Appendix to be added. Syntax description12The  notion of declaration as it is used here  divergessomewhat from common usage in computer science. We trust,however,   that   the  extension  will   be   interpretedstraightforwardly.13Two  optional  parts, paradigms and  ISRules,   can  beinserted between word-forms and entries. See section  2.1for  a  discussion of paradigms, and section  1.2  for  adiscussion of ISRules in this position.14There  may  be more than one citation form if  spellingvariants exist. An example is discussed in section 2.2.15This has to be adapted in the CMKS. Interface: spelling16Exceptional RIRule windows, without entry specification,may arise in wordformation, cf. chapter 4.17Actually,  the  situation  is  more  complicated,   andetymology  plays  a  role as well. According  to  Dardano&Trifone  (1985,  p.  111), however,  the  phonologicallybased rule as given here is an acceptable approximation.18See  Chapter  5  for  a  more  detailed  discussion  ofcharacter sort order and its function.19The  detachability shows up in main clauses, e.g.  'Janwerkt  het  plan uit', meaning litterally 'Jan works  theplan  out', i.e. 'Jan works out the plan'. Since the  twoelements  of  verbs  with  a  detachable  prefix  can  beseparated  in  this way, these verbs are not  within  thedomain  of  WM,  but are to be treated by  an  extension,currently  under development, called Phrase Manager  (cf.also section 1.2 of Chapter 5).20The doubling of e is due to a spelling strategy of Dutchdescribed in section 2.2.21The  semantics is not implemented yet. Perhaps  add  anexample for indices ? Deleted forms22The  list of suffixes is rather long. In section  2.3.3some possibilities of structuring it will be discussed.23If the statements in the paradigms section do not coverall  wordforms, or assign some of them to more  than  oneparadigm a warning message is given. To be implemented24Due to a bug (apparently in C), only the form where thelonger  string  is  put  first is interpreted  correctly.d(e|en)?  is {d, de}, whereas "d(en|e)? is {d, de,  den}.System25In verbal examples, the first person singular and pluralof  the  present  indicative are  given,  for  nouns  thesingular   and   the  plural,  and  for  adjectives   the(uninflected) positive and comparative grades.26I did not find the traditional symbol, the reversed  e,on the keyboard. Description27This remains to be implemented, and should be added  inthe syntax. System character subsets28Internally, this type of redundancy is eliminated in thecompilation process, so that it does not affect the  run-time efficiency.29Actually, it is rather the adjective stem that is takenthan  the  whole  adjective. Since the  two  coincide  inEnglish,  however, we have not bothered  too  much  aboutbeing very strict in this respect.30In future, it will be possible to specify deleted formsin the wordformation rule, so as to apply to all words itforms.31Since  this  feature interacts quite heavily  with  thefunctionality  of  Phrase  Manager,  it  has   not   beenimplemented yet.32Entry  constraints can optionally  occur  in  formativewindows instead of rule windows. This option is explainedin section 2.33The  warning message only appears under the  "extensivetesting" option of the incremental compiler.34Some more complicated cases are described in Chapter 5.35Reinhard & Gibbon (1991) show that more than two degreesof umlautability of vowels exist. In the following table,the  singular of two nouns, their form serving  as  left-hand  element of compounds, and the adjective  formed  bysuffixing -isch (cf. -ish) to them are given.     Fuchs     ('fox')   Füchse    füchsisch     Hund ('dog')   Hunde     hündischBy  a slight extension, this observation can be expressedin either of the two strategies described here.36At  the  moment, RWFRule specification  is  obligatory,contrary     to     syntax    description.    WFFormativespecialization37In the syntax description, LU specification is presentedas obligatory. Syntax Description38The  compound  status of the type of noun  +  adjectivecombination in the second example is not uncontroversial.Matthews  (1974)  rejects it, because both  elements  areinflected.  Levi  (1978) defends the compound  status  ofthese   combinations  on  the  basis  of  their  semanticproperties.  The definition of compounding  presented  byten  Hacken  (1992)  includes  them  in  the  domain   ofcompounding.39As  in  the  opening  verse of  Virgil's  Aeneis:  Armavirumque  cano.  See  Matthews (1974)  for  an  extensivediscussion of this example.40In future, it will perhaps be possible to include ch andll  directly  in the character sort order, thus  avoidingthe use of dummy characters.41The   introduction  of  constructs  grouping   togetherlexemes, similar to LU, is technically easy.42It  is  ignored  here  that -ical  is  probably  betteranalyzed  as a combination of two suffixes, -ic and  -al.This is not relevant for the points under dicussion here.43Note that, since root is not part of the inflection unitname,  and  every  IRule has to belong to  an  inflectionunit,  this  only IRule cannot depend directly  from  theroot. An ICat node has to be included in the tree betweenthe root and the IRule node.